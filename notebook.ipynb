{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30d4da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799cf81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_prompt = \"What question was asked by the user if this were the sources used \"\n",
    "\n",
    "def get_dataset(use_extract=False, min_question_len=5, verbose=True, drop_duplicates=True):\n",
    "    ds = load_dataset(\"openai/webgpt_comparisons\", revision=\"refs/convert/parquet\")\n",
    "    train = ds[\"train\"]\n",
    "\n",
    "    reason_counter = Counter()\n",
    "\n",
    "    def validate_row(row):\n",
    "        q = row[\"question\"][\"full_text\"].strip()\n",
    "        titles0 = row[\"quotes_0\"].get(\"title\", [])\n",
    "        titles1 = row[\"quotes_1\"].get(\"title\", [])\n",
    "        extracts0 = row[\"quotes_0\"].get(\"extract\", [])\n",
    "        extracts1 = row[\"quotes_1\"].get(\"extract\", [])\n",
    "\n",
    "        if not q:\n",
    "            reason_counter[\"empty_question\"] += 1; return False\n",
    "        if len(q) < min_question_len:\n",
    "            reason_counter[\"short_question\"] += 1; return False\n",
    "        if not any(titles0 + titles1):\n",
    "            reason_counter[\"no_titles\"] += 1; return False\n",
    "        if use_extract and not any(extracts0 + extracts1):\n",
    "            reason_counter[\"no_extracts\"] += 1; return False\n",
    "        return True\n",
    "\n",
    "    def build_input(titles, extracts):\n",
    "        assert titles or extracts, \"At least one of titles or extracts must be provided.\"\n",
    "        parts = []\n",
    "        # if both titles and extracts are used, put one by the other with zip()\n",
    "        if use_extract and titles:\n",
    "            parts.extend(f\"<t>{t.strip()}</t> <c>{e.strip()}</c>\" for t, e in zip(titles, extracts) if t.strip() and e.strip())\n",
    "        if titles:\n",
    "            parts.append(\"<t>\" + \" ; \".join(t.strip() for t in titles if t.strip()) + \"</t>\")\n",
    "        if use_extract:\n",
    "            clean_extracts = [e.strip() for e in extracts if e.strip()]\n",
    "            if clean_extracts:\n",
    "                parts.append(\"<c>\" + \" ; \".join(clean_extracts) + \"</c>\")\n",
    "        return input_prompt + \" \".join(parts)\n",
    "\n",
    "    def transform_row(row):\n",
    "        question = row[\"question\"][\"full_text\"].strip()\n",
    "        samples = []\n",
    "        for qset in [row[\"quotes_0\"], row[\"quotes_1\"]]:\n",
    "            titles = qset.get(\"title\", [])\n",
    "            extracts = qset.get(\"extract\", [])\n",
    "            if not any(t.strip() for t in titles):\n",
    "                continue\n",
    "            inp = build_input(titles, extracts)\n",
    "            samples.append({\"input\": inp, \"output\": question})\n",
    "        # per-row dedupe (in case quotes_0 and quotes_1 produce identical sample)\n",
    "        uniq, seen = [], set()\n",
    "        for s in samples:\n",
    "            k = (s[\"input\"], s[\"output\"])\n",
    "            if k in seen: continue\n",
    "            seen.add(k); uniq.append(s)\n",
    "        return uniq\n",
    "\n",
    "    # build\n",
    "    transformed_data = []\n",
    "    total = 0\n",
    "    for row in tqdm(train):\n",
    "        total += 1\n",
    "        if validate_row(row):\n",
    "            transformed_data.extend(transform_row(row))\n",
    "\n",
    "    # global dedupe\n",
    "    if drop_duplicates:\n",
    "        def norm(s): return \" \".join(s.split())\n",
    "        seen, deduped = set(), []\n",
    "        for ex in transformed_data:\n",
    "            key = (norm(ex[\"input\"]), norm(ex[\"output\"]))\n",
    "            if key in seen: continue\n",
    "            seen.add(key)\n",
    "            deduped.append({\"input\": key[0], \"output\": key[1]})\n",
    "        if verbose:\n",
    "            print(f\"\\nDeduped {len(transformed_data) - len(deduped)} duplicates (kept {len(deduped)}).\")\n",
    "        transformed_data = deduped\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nTotal rows: {total}\")\n",
    "        print(f\"Kept rows: {total - sum(reason_counter.values())}\")\n",
    "        print(\"Filtered counts:\")\n",
    "        for reason, count in reason_counter.items():\n",
    "            print(f\" - {reason}: {count}\")\n",
    "\n",
    "    return Dataset.from_list(transformed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bbbd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_dataset()\n",
    "print(len(train_data))\n",
    "print(f\"Loaded {len(train_data)} training samples.\")\n",
    "print(\"Sample data:\")\n",
    "print(f\"Input: {train_data[0]['input']}\")\n",
    "print(f\"Output: {train_data[0]['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38473c13",
   "metadata": {},
   "source": [
    "Keep in mind each row can be 2 samples because it has 2 \"quotes\" which are 2 sessions of the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c259147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "def tokenize(row):\n",
    "    return tokenizer(row[\"input\"], text_target=row[\"output\"], truncation=True)\n",
    "\n",
    "tokenized_data = train_data.map(tokenize, remove_columns=[\"input\", \"output\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83a69d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 30371, Eval size: 7593\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and evaluation sets\n",
    "train_ds, eval_ds = tokenized_data.train_test_split(test_size=0.2, seed=42).values()\n",
    "print(f\"Train size: {len(train_ds)}, Eval size: {len(eval_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f766115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(dataset, model, num_examples=5):\n",
    "    \"\"\"\n",
    "    Evaluate the fine-tuned model on a subset of the dataset and print results.\n",
    "    \"\"\"\n",
    "    print(f\"Evaluating on {min(num_examples, len(dataset))} examples from the dataset:\")\n",
    "    for i in range(min(num_examples, len(dataset))):\n",
    "        example = dataset[i]\n",
    "        input_text = tokenizer.decode(example[\"input_ids\"], skip_special_tokens=True)\n",
    "        expected_output = tokenizer.decode(example[\"labels\"], skip_special_tokens=True)\n",
    "\n",
    "        # Generate prediction\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "        output_tokens = model.generate(**inputs, max_new_tokens=512)\n",
    "        generated_output = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "        print(f\"\\n--- Example {i+1} ---\")\n",
    "        print(f\"Input (Titles): {input_text.split(':')[1]}\")\n",
    "        print(f\"Expected Output (Question): {expected_output}\")\n",
    "        print(f\"Generated Output (Question): {generated_output}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "784f1e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# import sys\n",
    "\n",
    "# print(\"Installing required packages...\")\n",
    "# subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"rouge-score\", \"evaluate\", \"bert_score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05ec6a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "\n",
    "def comprehensive_evaluation(dataset, model, tokenizer, num_examples=None):\n",
    "    \"\"\"\n",
    "    Evaluate the fine-tuned model with multiple metrics including BLEU, ROUGE, and perplexity.\n",
    "    \"\"\"\n",
    "    # Initialize metrics\n",
    "    bleu_metric = evaluate.load(\"bleu\")\n",
    "    rouge_metric = evaluate.load(\"rouge\")\n",
    "    bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "    predictions = []\n",
    "    references = []\n",
    "    input_texts = []\n",
    "    num_examples = len(dataset) if num_examples is None else num_examples\n",
    "    print(f\"Evaluating on {min(num_examples, len(dataset))} examples...\")\n",
    "    \n",
    "    # Generate predictions\n",
    "    for i in tqdm(range(min(num_examples, len(dataset)))):\n",
    "        example = dataset[i]\n",
    "        input_text = tokenizer.decode(example[\"input_ids\"], skip_special_tokens=True)\n",
    "        expected_output = tokenizer.decode(example[\"labels\"], skip_special_tokens=True)\n",
    "        \n",
    "        # Generate prediction\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "        with torch.no_grad():\n",
    "            output_tokens = model.generate(**inputs, max_new_tokens=512, do_sample=False)\n",
    "        generated_output = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "        \n",
    "        input_texts.append(input_text)\n",
    "        predictions.append(generated_output)\n",
    "        references.append(expected_output)\n",
    "    \n",
    "    # Calculate BLEU score\n",
    "    bleu_results = bleu_metric.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    rouge_results = rouge_metric.compute(predictions=predictions, references=references)\n",
    "    \n",
    "    # Calculate BERTScore\n",
    "    bertscore_results = bertscore.compute(predictions=predictions, references=references, lang=\"en\", rescale_with_baseline=True)\n",
    "    bertscore_f1 = np.mean(bertscore_results[\"f1\"])\n",
    "    bertscore_precision = np.mean(bertscore_results[\"precision\"])\n",
    "    bertscore_recall = np.mean(bertscore_results[\"recall\"])\n",
    "    \n",
    "    # Calculate perplexity on a subset\n",
    "    total_loss = 0\n",
    "    total_tokens = 0\n",
    "    \n",
    "    for i in tqdm(range(min(50, len(dataset)))):  # Use fewer examples for perplexity to save compute\n",
    "        example = dataset[i]\n",
    "        input_ids = example[\"input_ids\"]\n",
    "        labels = example[\"labels\"]\n",
    "        \n",
    "        # Prepare inputs\n",
    "        inputs = {\n",
    "            \"input_ids\": torch.tensor([input_ids]).to(model.device),\n",
    "            \"labels\": torch.tensor([labels]).to(model.device)\n",
    "        }\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            total_tokens += len(labels)\n",
    "    \n",
    "    perplexity = np.exp(total_loss / min(50, len(dataset)))\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n=== EVALUATION RESULTS ===\")\n",
    "    print(f\"BERTScore F1: {bertscore_f1:.4f} ↑ (higher = more semantically similar)\")\n",
    "    print(f\"BERTScore Precision: {bertscore_precision:.4f} ↑\")\n",
    "    print(f\"BERTScore Recall: {bertscore_recall:.4f} ↑\")\n",
    "    print(f\"BLEU Score: {bleu_results['bleu']:.4f} ↑ (higher = more phrase overlap)\")\n",
    "    print(f\"ROUGE-1 F1: {rouge_results['rouge1']:.4f} ↑\")\n",
    "    print(f\"ROUGE-2 F1: {rouge_results['rouge2']:.4f} ↑\")\n",
    "    print(f\"ROUGE-L F1: {rouge_results['rougeL']:.4f} ↑ (longest common subsequence)\")\n",
    "    print(f\"Perplexity: {perplexity:.4f} ↓ (lower = more confident model)\")\n",
    "\n",
    "    \n",
    "    # Show some examples\n",
    "    print(\"\\n=== SAMPLE PREDICTIONS ===\")\n",
    "    for i in range(min(5, len(predictions))):\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"Input: {input_texts[i]}\")\n",
    "        print(f\"Expected output: {references[i]}\")\n",
    "        print(f\"Generated output: {predictions[i]}\")\n",
    "    \n",
    "    return {\n",
    "        \"bleu\": bleu_results[\"bleu\"],\n",
    "        \"rouge1\": rouge_results[\"rouge1\"],\n",
    "        \"rouge2\": rouge_results[\"rouge2\"],\n",
    "        \"rougeL\": rouge_results[\"rougeL\"],\n",
    "        \"bertscore_f1\": bertscore_f1,\n",
    "        \"bertscore_precision\": bertscore_precision,\n",
    "        \"bertscore_recall\": bertscore_recall,\n",
    "        \"perplexity\": perplexity\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cb3de7",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf50712",
   "metadata": {},
   "source": [
    "### start basic, 3 epochs with T5 small. \n",
    "* Train only using title as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab37a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "model.config.use_cache = False\n",
    "if hasattr(model, \"generation_config\"):\n",
    "    model.generation_config.use_cache = False\n",
    "    \n",
    "training_args = TrainingArguments(\n",
    "    output_dir              = \"t5-question-generator\",\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size  = 8,\n",
    "    num_train_epochs        = 3,\n",
    "    learning_rate           = 3e-4,\n",
    "    weight_decay            = 0.01,\n",
    "    report_to               = \"none\",   # disable WandB/TensorBoard by default\n",
    "    save_total_limit        = 1,\n",
    "    eval_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model           = model,\n",
    "    args            = training_args,\n",
    "    train_dataset   = train_ds,\n",
    "    eval_dataset    = eval_ds,\n",
    "    tokenizer       = tokenizer,\n",
    "    data_collator   = data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5efc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on 7639 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7639/7639 [13:08<00:00,  9.69it/s]  \n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 50/50 [00:00<00:00, 82.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EVALUATION RESULTS ===\n",
      "BERTScore F1: 0.3154 ↑ (higher = more semantically similar)\n",
      "BERTScore Precision: 0.4507 ↑\n",
      "BERTScore Recall: 0.1887 ↑\n",
      "BLEU Score: 0.0049 ↑ (higher = more phrase overlap)\n",
      "ROUGE-1 F1: 0.2471 ↑\n",
      "ROUGE-2 F1: 0.0984 ↑\n",
      "ROUGE-L F1: 0.2233 ↑ (longest common subsequence)\n",
      "Perplexity: 15.4032 ↓ (lower = more confident model)\n",
      "\n",
      "=== SAMPLE PREDICTIONS ===\n",
      "\n",
      "Example 1:\n",
      "Input: What question was asked by the user if this t>Why Suicide Prevention Matters | LivingWorks (www.livingworks.net) ; Suicide Prevention - HelpGuide.org (www.helpguide.org) ; How Anyone Can Prevent Suicide (www.verywellmind.com) ; Preventing Youth Suicide | youth.gov (youth.gov)/t>\n",
      "Expected output: Why do we prevent suicides? I can't even begin to imagine why this is necessary. Explain.\n",
      "Generated output: Why do people prevent suicide?\n",
      "\n",
      "Example 2:\n",
      "Input: What question was asked by the user if this t>Why do we have to dig so deep to uncover ancient ruins? - BBC Science Focus Magazine (www.sciencefocus.com)/t>\n",
      "Expected output: Why are ancient ruins always buried, where did all the dirt covering them up come from? It seems when ancient Roman buildings (for example) are found, it's necessary that archeologists always have to dig down, sometimes meters, to get to them. Although ancient, these Roman buildings can have sophisticated/enginered foundations, so it's not like they'sunk' into the ground over millenia, right? Where did all the dirt come from that is covering them up? So, hypothetically, if I threw my dishes and stuff in the backyard and moved out of my house, and nobody touched it for 2,000 years, would all my stuff end up buried like other ruins? Would some future archeologists have to dig down through two meters of dirt in order to discover my stuff? (Think how weird it'll be when future archeologists find Furbys, Fleshligts and stuff like that)\n",
      "Generated output: Why do we need to dig deep to find ancient ruins?\n",
      "\n",
      "Example 3:\n",
      "Input: What question was asked by the user if this t>Why Does Beer Foam? Causes & Effects You Should Know (renegadebrewing.com) ; Why does beer form a head but soda doesn't? | HowStuffWorks (science.howstuffworks.com) ; Beer Science: Chemistry of the Beer Head - The Foam Factor - Buffalo Beer Biochemist (buffalobeerbiochemist.com)/t>\n",
      "Expected output: Why does pouring a beer result in more foam than pouring a soda?\n",
      "Generated output: Why does beer form a head but soda doesn't?\n",
      "\n",
      "Example 4:\n",
      "Input: What question was asked by the user if this t>Why are so many Anime called Adjective Occupation Proper Name? - Everything2.com (everything2.com) ; Why are so many Anime called Adjective Occupation Proper Name? - Everything2.com (everything2.com) ; Nerdy Jobs: Translating anime for Crunchyroll and an American audience | SYFY WIRE (www.syfy.com)/t>\n",
      "Expected output: Why are anime titles often translated into nonsense English? Examples: \"Full Metal Alchemist\", \"Attack on Titan\" For a long time, I assumed the latter was a space opera centered on one of Saturn's moons. These titles don't really mean anything, and you might assume it's a result of translating the original Japanese titles too literally, but that does not appear to be the case.\n",
      "Generated output: Why are so many anime titles called \"Adjective occupation\"?\n",
      "\n",
      "Example 5:\n",
      "Input: What question was asked by the user if this t>Berlin Wall - History, Dates & The Fall - HISTORY (www.history.com) ; Berlin Wall - Wikipedia (en.wikipedia.org) ; Berlin Wall - Wikipedia (en.wikipedia.org)/t>\n",
      "Expected output: Why did it take so long for the Berlin Wall to be knocked down?\n",
      "Generated output: What is the Berlin Wall?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run comprehensive evaluation\n",
    "results = comprehensive_evaluation(eval_ds, model, tokenizer, num_examples=3000)  # none means take all\n",
    "eval_df = pd.DataFrame([results], index=[\"t5_small_only_title\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e9392d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on 7639 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7639/7639 [2:43:09<00:00,  1.28s/it]  \n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "100%|██████████| 50/50 [00:02<00:00, 21.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EVALUATION RESULTS ===\n",
      "BERTScore F1: -0.0587 ↑ (higher = more semantically similar)\n",
      "BERTScore Precision: -0.1818 ↑\n",
      "BERTScore Recall: 0.0706 ↑\n",
      "BLEU Score: 0.0094 ↑ (higher = more phrase overlap)\n",
      "ROUGE-1 F1: 0.1602 ↑\n",
      "ROUGE-2 F1: 0.0430 ↑\n",
      "ROUGE-L F1: 0.1303 ↑ (longest common subsequence)\n",
      "Perplexity: 75.2387 ↓ (lower = more confident model)\n",
      "\n",
      "=== SAMPLE PREDICTIONS ===\n",
      "\n",
      "Example 1:\n",
      "Input: What question was asked by the user if this t>Why Suicide Prevention Matters | LivingWorks (www.livingworks.net) ; Suicide Prevention - HelpGuide.org (www.helpguide.org) ; How Anyone Can Prevent Suicide (www.verywellmind.com) ; Preventing Youth Suicide | youth.gov (youth.gov)/t>\n",
      "Expected output: Why do we prevent suicides? I can't even begin to imagine why this is necessary. Explain.\n",
      "Generated output: user asked t>Why Suicide Prevention Matters | LivingWorks (www.livingworks.net) ; Suicide Prevention - HelpGuide.org (www.helpguide.org) ; How Anyone Can Prevent Suicide (www.verywellmind.com) ; Preventing Youth Suicide | youth.gov (youth.gov)/t>\n",
      "\n",
      "Example 2:\n",
      "Input: What question was asked by the user if this t>Why do we have to dig so deep to uncover ancient ruins? - BBC Science Focus Magazine (www.sciencefocus.com)/t>\n",
      "Expected output: Why are ancient ruins always buried, where did all the dirt covering them up come from? It seems when ancient Roman buildings (for example) are found, it's necessary that archeologists always have to dig down, sometimes meters, to get to them. Although ancient, these Roman buildings can have sophisticated/enginered foundations, so it's not like they'sunk' into the ground over millenia, right? Where did all the dirt come from that is covering them up? So, hypothetically, if I threw my dishes and stuff in the backyard and moved out of my house, and nobody touched it for 2,000 years, would all my stuff end up buried like other ruins? Would some future archeologists have to dig down through two meters of dirt in order to discover my stuff? (Think how weird it'll be when future archeologists find Furbys, Fleshligts and stuff like that)\n",
      "Generated output: - BBC Science Focus Magazine (www.sciencefocus.com)/t>\n",
      "\n",
      "Example 3:\n",
      "Input: What question was asked by the user if this t>Why Does Beer Foam? Causes & Effects You Should Know (renegadebrewing.com) ; Why does beer form a head but soda doesn't? | HowStuffWorks (science.howstuffworks.com) ; Beer Science: Chemistry of the Beer Head - The Foam Factor - Buffalo Beer Biochemist (buffalobeerbiochemist.com)/t>\n",
      "Expected output: Why does pouring a beer result in more foam than pouring a soda?\n",
      "Generated output: user asked if this t>Why Does Beer Foam? Causes & Effects You Should Know (renegadebrewing.com) ; Why does beer form a head but soda doesn't? | HowStuffWorks (science.howstuffworks.com) ; Beer Science: Chemistry of the Beer Head - The Foam Factor - Buffalo Beer Biochemist (buffalobeerbiochemist.com)/t>Why Does Beer Foam?\n",
      "\n",
      "Example 4:\n",
      "Input: What question was asked by the user if this t>Why are so many Anime called Adjective Occupation Proper Name? - Everything2.com (everything2.com) ; Why are so many Anime called Adjective Occupation Proper Name? - Everything2.com (everything2.com) ; Nerdy Jobs: Translating anime for Crunchyroll and an American audience | SYFY WIRE (www.syfy.com)/t>\n",
      "Expected output: Why are anime titles often translated into nonsense English? Examples: \"Full Metal Alchemist\", \"Attack on Titan\" For a long time, I assumed the latter was a space opera centered on one of Saturn's moons. These titles don't really mean anything, and you might assume it's a result of translating the original Japanese titles too literally, but that does not appear to be the case.\n",
      "Generated output: user asked if this question was asked if this t>Why are so many Anime called Adjective Occupation Proper Name? - Everything2.com (everything2.com) ; Why are so many Anime called Adjective Occupation Proper Name? - Everything2.com (everything2.com) ; Nerdy Jobs: Translating anime for Crunchyroll and an American audience | SYFY WIRE (www.syfy\n",
      "\n",
      "Example 5:\n",
      "Input: What question was asked by the user if this t>Berlin Wall - History, Dates & The Fall - HISTORY (www.history.com) ; Berlin Wall - Wikipedia (en.wikipedia.org) ; Berlin Wall - Wikipedia (en.wikipedia.org)/t>\n",
      "Expected output: Why did it take so long for the Berlin Wall to be knocked down?\n",
      "Generated output: Was the user asked if this t>Berlin Wall - History, Dates & The Fall - HISTORY (www.history.com) ; Berlin Wall - Wikipedia (en.wikipedia.org) ; Berlin Wall - Wikipedia (en.wikipedia.org) ; Berlin Wall - Wikipedia (en.wikipedia.org) ; Berlin Wall - Wikipedia (en.wikipedia.org)/t>Berlin Wall - History, Dates & The Fall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>bertscore_precision</th>\n",
       "      <th>bertscore_recall</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t5_small_only_title</th>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.247088</td>\n",
       "      <td>0.098434</td>\n",
       "      <td>0.223263</td>\n",
       "      <td>0.315411</td>\n",
       "      <td>0.450722</td>\n",
       "      <td>0.188689</td>\n",
       "      <td>15.403170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5_small_baseline</th>\n",
       "      <td>0.009406</td>\n",
       "      <td>0.160242</td>\n",
       "      <td>0.042990</td>\n",
       "      <td>0.130303</td>\n",
       "      <td>-0.058683</td>\n",
       "      <td>-0.181792</td>\n",
       "      <td>0.070558</td>\n",
       "      <td>75.238684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         bleu    rouge1    rouge2    rougeL  bertscore_f1  \\\n",
       "t5_small_only_title  0.004914  0.247088  0.098434  0.223263      0.315411   \n",
       "t5_small_baseline    0.009406  0.160242  0.042990  0.130303     -0.058683   \n",
       "\n",
       "                     bertscore_precision  bertscore_recall  perplexity  \n",
       "t5_small_only_title             0.450722          0.188689   15.403170  \n",
       "t5_small_baseline              -0.181792          0.070558   75.238684  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate on same model without fine tuning\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "\n",
    "tokenizer_base = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "model_base = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "results_baseline = comprehensive_evaluation(eval_ds, model_base, tokenizer_base, num_examples=None)  # none means take all\n",
    "eval_df = pd.concat([eval_df, pd.DataFrame([results_baseline], index=[\"t5_small_baseline\"])])\n",
    "eval_df.to_csv(\"results_including_t5_small_baseline.csv\")\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33f12f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ask(titles: list[str]):\n",
    "    \"\"\"\n",
    "    Generate a question for a list of article titles.\n",
    "    Example:\n",
    "        ask([\"Benefits of Vitamin D\", \"Sunlight and Health\", \"Immune Response\"])\n",
    "    \"\"\"\n",
    "    prompt = input_prompt + \"; \".join(titles)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    output = model.generate(**inputs, max_new_tokens=512)\n",
    "    print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bd937fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do developers start a new project?\n"
     ]
    }
   ],
   "source": [
    "ask([\"start a new project - github.com\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37db95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ask_no_fine_tuning(titles: list[str]):\n",
    "    # Load a new tokenizer and model for the base t5-small model\n",
    "    prompt = input_prompt + \"; \".join(titles)\n",
    "    inputs = tokenizer_base(prompt, return_tensors=\"pt\")\n",
    "    output = model_base.generate(**inputs, max_new_tokens=512)\n",
    "    print(tokenizer_base.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fac8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_no_fine_tuning([\"start a new project - github.com\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d133c7a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6b60d54",
   "metadata": {},
   "source": [
    "### Train with other models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded9163f",
   "metadata": {},
   "source": [
    "#### GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f715c6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate, math\n",
    "from tqdm import tqdm\n",
    "\n",
    "def comprehensive_eval_gpt2(dataset, model, tokenizer, num_examples=300, max_new_tokens=128):\n",
    "    n = len(dataset) if (num_examples is None) else min(num_examples, len(dataset))\n",
    "    subset = dataset.select(range(n))\n",
    "\n",
    "    preds, refs, inps = [], [], []\n",
    "\n",
    "    # Generate predictions\n",
    "    for ex in tqdm(subset, desc=\"Generate\"):\n",
    "        input_text = ex[\"input\"]\n",
    "        ref_text   = ex[\"output\"]\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "        with torch.no_grad():\n",
    "            out_ids = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False,\n",
    "                                     eos_token_id=tokenizer.eos_token_id)\n",
    "        pred = tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
    "        preds.append(pred); refs.append(ref_text); inps.append(input_text)\n",
    "\n",
    "    # Semantic + surface metrics\n",
    "    bertscore = evaluate.load(\"bertscore\").compute(predictions=preds, references=refs, lang=\"en\")\n",
    "    rouge     = evaluate.load(\"rouge\").compute(predictions=preds, references=refs)\n",
    "    bleu      = evaluate.load(\"bleu\").compute(predictions=preds, references=[[r] for r in refs])\n",
    "\n",
    "    b_f1 = float(np.mean(bertscore[\"f1\"]))\n",
    "    b_p  = float(np.mean(bertscore[\"precision\"]))\n",
    "    b_r  = float(np.mean(bertscore[\"recall\"]))\n",
    "\n",
    "    # Perplexity over OUTPUT ONLY (mask prompt tokens)\n",
    "    losses = []\n",
    "    for ex in tqdm(subset, desc=\"PPL\"):\n",
    "        ids = torch.tensor(ex[\"input_ids\"]).unsqueeze(0).to(model.device)\n",
    "        labels = ids.clone()\n",
    "        labels[:, :ex[\"prompt_len\"]] = -100   # ignore the prompt\n",
    "        with torch.no_grad():\n",
    "            loss = model(input_ids=ids, labels=labels).loss.item()\n",
    "        losses.append(loss)\n",
    "    ppl = float(math.exp(np.mean(losses)))\n",
    "\n",
    "    # Pretty print\n",
    "    print(\"\\n=== EVALUATION RESULTS ===\")\n",
    "    print(f\"BERTScore F1: {b_f1:.4f} ↑ (higher = more semantically similar)\")\n",
    "    print(f\"BERTScore Precision: {b_p:.4f} ↑\")\n",
    "    print(f\"BERTScore Recall: {b_r:.4f} ↑\")\n",
    "    print(f\"BLEU Score: {bleu['bleu']:.4f} ↑\")\n",
    "    print(f\"ROUGE-1 F1: {rouge['rouge1']:.4f} ↑\")\n",
    "    print(f\"ROUGE-2 F1: {rouge['rouge2']:.4f} ↑\")\n",
    "    print(f\"ROUGE-L F1: {rouge['rougeL']:.4f} ↑\")\n",
    "    print(f\"Perplexity (output-only): {ppl:.4f} ↓\")\n",
    "\n",
    "    return {\n",
    "        \"bertscore_f1\": b_f1,\n",
    "        \"bertscore_precision\": b_p,\n",
    "        \"bertscore_recall\": b_r,\n",
    "        \"bleu\": bleu[\"bleu\"],\n",
    "        \"rouge1\": rouge[\"rouge1\"],\n",
    "        \"rouge2\": rouge[\"rouge2\"],\n",
    "        \"rougeL\": rouge[\"rougeL\"],\n",
    "        \"perplexity\": ppl,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95aa19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    GPT2LMHeadModel,\n",
    "    GPT2TokenizerFast,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling,\n",
    ")\n",
    "\n",
    "# Load GPT2 model and tokenizer\n",
    "gpt2_tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Tokenize data for GPT2 (causal language modeling)\n",
    "def tokenize_gpt2(row):\n",
    "    # For GPT2, combine input and output with a separator\n",
    "    text = row[\"input\"] + \" \" + row[\"output\"] + gpt2_tokenizer.eos_token\n",
    "    return gpt2_tokenizer(text, truncation=True, max_length=512)\n",
    "\n",
    "gpt2_tokenized_data = train_data.map(tokenize_gpt2, remove_columns=[\"input\", \"output\"])\n",
    "\n",
    "# Split the data\n",
    "gpt2_train_ds, gpt2_eval_ds = gpt2_tokenized_data.train_test_split(test_size=0.2, seed=42).values()\n",
    "\n",
    "# Training arguments for GPT2\n",
    "gpt2_training_args = TrainingArguments(\n",
    "    output_dir=\"gpt2-question-generator\",\n",
    "    per_device_train_batch_size=4,  # Smaller batch size for GPT2\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\",\n",
    "    save_total_limit=1,\n",
    "    eval_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "# Data collator for language modeling\n",
    "gpt2_data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=gpt2_tokenizer,\n",
    "    mlm=False,  # Causal language modeling, not masked\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "gpt2_trainer = Trainer(\n",
    "    model=gpt2_model,\n",
    "    args=gpt2_training_args,\n",
    "    train_dataset=gpt2_train_ds,\n",
    "    eval_dataset=gpt2_eval_ds,\n",
    "    tokenizer=gpt2_tokenizer,\n",
    "    data_collator=gpt2_data_collator,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "gpt2_trainer.train()\n",
    "\n",
    "# Run comprehensive evaluation\n",
    "results = comprehensive_evaluation(gpt2_eval_ds, gpt2_model, gpt2_tokenizer, num_examples=3000)  # none means take all\n",
    "eval_df = pd.concat([eval_df, pd.DataFrame([results_baseline], index=[\"gpt2_only_title\"])])\n",
    "eval_df.to_csv(\"results_including_gpt2.csv\")\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69221002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, math, torch\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "\n",
    "def evaluate_gpt2_on_raw(raw_dataset, model, tokenizer, num_examples=1000, max_new_tokens=128):\n",
    "    model.eval()\n",
    "    n = len(raw_dataset) if (num_examples is None) else min(num_examples, len(raw_dataset))\n",
    "    subset = raw_dataset.select(range(n))\n",
    "\n",
    "    preds, refs = [], []\n",
    "\n",
    "    # 1) Generate predictions from INPUT only\n",
    "    for ex in tqdm(subset, desc=\"Generate\"):\n",
    "        input_text = ex[\"input\"]\n",
    "        ref_text   = ex[\"output\"]\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "        with torch.no_grad():\n",
    "            out_ids = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=False,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "            )\n",
    "        pred = tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
    "        preds.append(pred)\n",
    "        refs.append(ref_text)\n",
    "\n",
    "    # 2) Semantic & surface metrics\n",
    "    bertscore = evaluate.load(\"bertscore\").compute(predictions=preds, references=refs, lang=\"en\")\n",
    "    rouge     = evaluate.load(\"rouge\").compute(predictions=preds, references=refs)\n",
    "    bleu      = evaluate.load(\"bleu\").compute(predictions=preds, references=[[r] for r in refs])\n",
    "\n",
    "    b_f1 = float(np.mean(bertscore[\"f1\"]))\n",
    "    b_p  = float(np.mean(bertscore[\"precision\"]))\n",
    "    b_r  = float(np.mean(bertscore[\"recall\"]))\n",
    "\n",
    "    # 3) Perplexity on OUTPUT ONLY (mask prompt tokens)\n",
    "    losses = []\n",
    "    for ex in tqdm(subset, desc=\"PPL\"):\n",
    "        prompt_ids = tokenizer(ex[\"input\"], add_special_tokens=False)[\"input_ids\"]\n",
    "        target_ids = tokenizer(ex[\"output\"], add_special_tokens=False)[\"input_ids\"]\n",
    "        ids = torch.tensor(prompt_ids + target_ids + [tokenizer.eos_token_id]).unsqueeze(0).to(model.device)\n",
    "        labels = ids.clone()\n",
    "        labels[:, :len(prompt_ids)] = -100  # ignore prompt\n",
    "        with torch.no_grad():\n",
    "            loss = model(input_ids=ids, labels=labels).loss.item()\n",
    "        losses.append(loss)\n",
    "    ppl = float(math.exp(np.mean(losses)))\n",
    "\n",
    "    print(\"\\n=== EVALUATION RESULTS ===\")\n",
    "    print(f\"BERTScore F1: {b_f1:.4f} ↑ (higher = more semantically similar)\")\n",
    "    print(f\"BERTScore Precision: {b_p:.4f} ↑\")\n",
    "    print(f\"BERTScore Recall: {b_r:.4f} ↑\")\n",
    "    print(f\"BLEU Score: {bleu['bleu']:.4f} ↑ (higher = more phrase overlap)\")\n",
    "    print(f\"ROUGE-1 F1: {rouge['rouge1']:.4f} ↑\")\n",
    "    print(f\"ROUGE-2 F1: {rouge['rouge2']:.4f} ↑\")\n",
    "    print(f\"ROUGE-L F1: {rouge['rougeL']:.4f} ↑ (longest common subsequence)\")\n",
    "    print(f\"Perplexity (output-only): {ppl:.4f} ↓ (lower = more confident model)\")\n",
    "\n",
    "    return {\n",
    "        \"bertscore_f1\": b_f1,\n",
    "        \"bertscore_precision\": b_p,\n",
    "        \"bertscore_recall\": b_r,\n",
    "        \"bleu\": bleu[\"bleu\"],\n",
    "        \"rouge1\": rouge[\"rouge1\"],\n",
    "        \"rouge2\": rouge[\"rouge2\"],\n",
    "        \"rougeL\": rouge[\"rougeL\"],\n",
    "        \"perplexity\": ppl,\n",
    "    }\n",
    "\n",
    "# Example call (no training changes):\n",
    "# results_gpt2 = evaluate_gpt2_on_raw(train_data, gpt2_model, gpt2_tokenizer, num_examples=3000, max_new_tokens=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab4c1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate:   0%|          | 0/2000 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   0%|          | 1/2000 [00:03<1:59:53,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   0%|          | 2/2000 [00:07<1:59:59,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   0%|          | 3/2000 [00:10<2:00:03,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   0%|          | 4/2000 [00:14<2:00:23,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   0%|          | 5/2000 [00:18<2:00:02,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   0%|          | 6/2000 [00:21<1:59:12,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   0%|          | 7/2000 [00:25<1:58:54,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   0%|          | 8/2000 [00:28<1:58:47,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   0%|          | 9/2000 [00:32<1:58:39,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   0%|          | 10/2000 [00:35<1:58:40,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   1%|          | 11/2000 [00:39<1:59:07,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   1%|          | 12/2000 [00:43<1:59:16,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   1%|          | 13/2000 [00:46<1:59:44,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   1%|          | 14/2000 [00:50<1:59:19,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   1%|          | 15/2000 [00:53<1:58:30,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   1%|          | 16/2000 [00:57<1:57:56,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   1%|          | 17/2000 [01:00<1:57:24,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   1%|          | 18/2000 [01:04<1:57:06,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   1%|          | 19/2000 [01:07<1:56:51,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   1%|          | 20/2000 [01:11<1:56:36,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   1%|          | 21/2000 [01:15<1:56:36,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   1%|          | 22/2000 [01:18<1:56:29,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   1%|          | 23/2000 [01:22<1:56:15,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   1%|          | 24/2000 [01:25<1:56:13,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   1%|▏         | 25/2000 [01:29<1:56:16,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   1%|▏         | 26/2000 [01:32<1:56:26,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   1%|▏         | 27/2000 [01:36<1:56:16,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   1%|▏         | 28/2000 [01:39<1:56:16,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   1%|▏         | 29/2000 [01:43<1:56:08,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   2%|▏         | 30/2000 [01:46<1:55:51,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   2%|▏         | 31/2000 [01:50<1:55:55,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   2%|▏         | 32/2000 [01:53<1:56:07,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   2%|▏         | 33/2000 [01:57<1:56:10,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   2%|▏         | 34/2000 [02:01<1:55:55,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   2%|▏         | 35/2000 [02:04<1:55:58,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   2%|▏         | 36/2000 [02:08<1:56:08,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   2%|▏         | 37/2000 [02:11<1:56:13,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   2%|▏         | 38/2000 [02:15<1:56:13,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   2%|▏         | 39/2000 [02:18<1:56:24,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   2%|▏         | 40/2000 [02:22<1:56:18,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   2%|▏         | 41/2000 [02:25<1:56:31,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   2%|▏         | 42/2000 [02:29<1:56:23,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   2%|▏         | 43/2000 [02:33<1:56:38,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   2%|▏         | 44/2000 [02:36<1:57:05,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   2%|▏         | 45/2000 [02:40<1:56:51,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   2%|▏         | 46/2000 [02:43<1:56:36,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   2%|▏         | 47/2000 [02:47<1:56:15,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   2%|▏         | 48/2000 [02:50<1:55:49,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   2%|▏         | 49/2000 [02:54<1:55:36,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   2%|▎         | 50/2000 [02:58<1:55:25,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   3%|▎         | 51/2000 [03:01<1:55:36,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   3%|▎         | 52/2000 [03:05<1:55:25,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   3%|▎         | 53/2000 [03:08<1:55:11,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   3%|▎         | 54/2000 [03:12<1:55:07,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   3%|▎         | 55/2000 [03:15<1:54:43,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   3%|▎         | 56/2000 [03:19<1:54:51,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   3%|▎         | 57/2000 [03:22<1:54:39,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   3%|▎         | 58/2000 [03:26<1:54:46,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   3%|▎         | 59/2000 [03:29<1:54:37,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   3%|▎         | 60/2000 [03:33<1:54:29,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   3%|▎         | 61/2000 [03:37<1:54:38,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   3%|▎         | 62/2000 [03:40<1:54:17,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   3%|▎         | 63/2000 [03:44<1:54:31,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   3%|▎         | 64/2000 [03:47<1:54:32,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   3%|▎         | 65/2000 [03:51<1:54:17,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   3%|▎         | 66/2000 [03:54<1:54:16,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   3%|▎         | 67/2000 [03:58<1:54:07,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   3%|▎         | 68/2000 [04:01<1:54:15,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   3%|▎         | 69/2000 [04:05<1:54:07,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   4%|▎         | 70/2000 [04:08<1:54:05,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   4%|▎         | 71/2000 [04:12<1:54:11,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   4%|▎         | 72/2000 [04:16<1:54:06,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   4%|▎         | 73/2000 [04:19<1:54:13,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   4%|▎         | 74/2000 [04:23<1:54:17,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   4%|▍         | 75/2000 [04:26<1:54:53,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   4%|▍         | 76/2000 [04:30<1:54:59,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   4%|▍         | 77/2000 [04:34<1:54:44,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   4%|▍         | 78/2000 [04:37<1:54:36,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   4%|▍         | 79/2000 [04:41<1:54:11,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   4%|▍         | 80/2000 [04:44<1:53:50,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   4%|▍         | 81/2000 [04:48<1:53:21,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   4%|▍         | 82/2000 [04:51<1:53:06,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   4%|▍         | 83/2000 [04:55<1:52:51,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   4%|▍         | 84/2000 [04:58<1:52:45,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   4%|▍         | 85/2000 [05:02<1:53:11,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   4%|▍         | 86/2000 [05:05<1:53:22,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   4%|▍         | 87/2000 [05:09<1:53:38,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   4%|▍         | 88/2000 [05:13<1:53:46,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   4%|▍         | 89/2000 [05:16<1:53:51,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   4%|▍         | 90/2000 [05:20<1:53:32,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   5%|▍         | 91/2000 [05:23<1:52:58,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   5%|▍         | 92/2000 [05:27<1:52:43,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   5%|▍         | 93/2000 [05:30<1:52:19,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   5%|▍         | 94/2000 [05:34<1:52:18,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   5%|▍         | 95/2000 [05:37<1:52:12,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   5%|▍         | 96/2000 [05:41<1:51:57,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   5%|▍         | 97/2000 [05:44<1:52:02,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   5%|▍         | 98/2000 [05:48<1:52:11,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   5%|▍         | 99/2000 [05:52<1:52:32,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   5%|▌         | 100/2000 [05:55<1:52:27,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   5%|▌         | 101/2000 [05:59<1:52:20,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   5%|▌         | 102/2000 [06:02<1:52:18,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   5%|▌         | 103/2000 [06:06<1:52:15,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   5%|▌         | 104/2000 [06:09<1:52:19,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   5%|▌         | 105/2000 [06:13<1:52:14,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   5%|▌         | 106/2000 [06:16<1:52:34,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   5%|▌         | 107/2000 [06:20<1:52:53,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   5%|▌         | 108/2000 [06:24<1:52:56,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   5%|▌         | 109/2000 [06:27<1:52:36,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   6%|▌         | 110/2000 [06:31<1:52:06,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   6%|▌         | 111/2000 [06:34<1:51:45,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   6%|▌         | 112/2000 [06:38<1:51:37,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   6%|▌         | 113/2000 [06:41<1:51:15,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   6%|▌         | 114/2000 [06:45<1:51:03,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   6%|▌         | 115/2000 [06:48<1:51:07,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   6%|▌         | 116/2000 [06:52<1:50:58,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   6%|▌         | 117/2000 [06:55<1:50:57,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   6%|▌         | 118/2000 [06:59<1:50:57,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   6%|▌         | 119/2000 [07:03<1:50:46,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   6%|▌         | 120/2000 [07:06<1:50:46,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   6%|▌         | 121/2000 [07:10<1:50:34,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   6%|▌         | 122/2000 [07:13<1:50:43,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   6%|▌         | 123/2000 [07:17<1:51:51,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   6%|▌         | 124/2000 [07:20<1:52:02,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   6%|▋         | 125/2000 [07:24<1:52:05,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   6%|▋         | 126/2000 [07:28<1:52:20,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   6%|▋         | 127/2000 [07:31<1:52:11,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   6%|▋         | 128/2000 [07:35<1:52:18,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   6%|▋         | 129/2000 [07:38<1:52:30,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   6%|▋         | 130/2000 [07:42<1:52:33,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   7%|▋         | 131/2000 [07:46<1:52:34,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   7%|▋         | 132/2000 [07:49<1:52:38,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   7%|▋         | 133/2000 [07:53<1:52:37,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   7%|▋         | 134/2000 [07:57<1:52:32,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   7%|▋         | 135/2000 [08:00<1:52:45,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   7%|▋         | 136/2000 [08:04<1:52:32,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   7%|▋         | 137/2000 [08:07<1:52:23,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   7%|▋         | 138/2000 [08:11<1:52:15,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   7%|▋         | 139/2000 [08:15<1:51:58,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   7%|▋         | 140/2000 [08:18<1:51:35,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   7%|▋         | 141/2000 [08:22<1:52:00,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   7%|▋         | 142/2000 [08:25<1:51:39,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   7%|▋         | 143/2000 [08:29<1:51:48,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   7%|▋         | 144/2000 [08:33<1:51:02,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   7%|▋         | 145/2000 [08:36<1:51:48,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   7%|▋         | 146/2000 [08:40<1:51:47,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   7%|▋         | 147/2000 [08:43<1:51:32,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   7%|▋         | 148/2000 [08:47<1:50:49,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   7%|▋         | 149/2000 [08:51<1:50:22,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   8%|▊         | 150/2000 [08:54<1:50:13,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   8%|▊         | 151/2000 [08:58<1:49:52,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   8%|▊         | 152/2000 [09:01<1:49:42,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   8%|▊         | 153/2000 [09:05<1:49:41,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   8%|▊         | 154/2000 [09:08<1:49:22,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   8%|▊         | 155/2000 [09:12<1:49:25,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   8%|▊         | 156/2000 [09:15<1:49:32,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   8%|▊         | 157/2000 [09:19<1:48:54,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   8%|▊         | 158/2000 [09:22<1:48:20,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   8%|▊         | 159/2000 [09:26<1:48:09,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   8%|▊         | 160/2000 [09:30<1:48:05,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   8%|▊         | 161/2000 [09:33<1:48:08,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   8%|▊         | 162/2000 [09:37<1:47:56,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   8%|▊         | 163/2000 [09:40<1:47:56,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   8%|▊         | 164/2000 [09:44<1:48:06,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   8%|▊         | 165/2000 [09:47<1:47:55,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   8%|▊         | 166/2000 [09:51<1:47:46,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   8%|▊         | 167/2000 [09:54<1:47:40,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   8%|▊         | 168/2000 [09:58<1:48:25,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   8%|▊         | 169/2000 [10:01<1:48:45,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   8%|▊         | 170/2000 [10:05<1:48:48,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   9%|▊         | 171/2000 [10:09<1:49:05,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   9%|▊         | 172/2000 [10:12<1:49:12,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   9%|▊         | 173/2000 [10:16<1:49:10,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   9%|▊         | 174/2000 [10:19<1:49:46,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   9%|▉         | 175/2000 [10:23<1:49:18,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   9%|▉         | 176/2000 [10:27<1:48:50,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   9%|▉         | 177/2000 [10:30<1:48:30,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   9%|▉         | 178/2000 [10:34<1:48:23,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   9%|▉         | 179/2000 [10:37<1:48:48,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   9%|▉         | 180/2000 [10:41<1:48:37,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   9%|▉         | 181/2000 [10:44<1:48:29,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   9%|▉         | 182/2000 [10:48<1:48:39,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   9%|▉         | 183/2000 [10:52<1:48:33,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   9%|▉         | 184/2000 [10:55<1:48:32,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   9%|▉         | 185/2000 [10:59<1:48:38,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   9%|▉         | 186/2000 [11:02<1:48:33,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   9%|▉         | 187/2000 [11:06<1:48:23,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   9%|▉         | 188/2000 [11:10<1:48:31,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   9%|▉         | 189/2000 [11:13<1:48:26,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  10%|▉         | 190/2000 [11:17<1:48:20,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  10%|▉         | 191/2000 [11:20<1:48:08,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  10%|▉         | 192/2000 [11:24<1:48:26,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  10%|▉         | 193/2000 [11:28<1:48:17,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  10%|▉         | 194/2000 [11:31<1:48:19,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  10%|▉         | 195/2000 [11:35<1:48:35,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  10%|▉         | 196/2000 [11:38<1:48:45,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  10%|▉         | 197/2000 [11:42<1:48:39,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  10%|▉         | 198/2000 [11:46<1:48:35,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  10%|▉         | 199/2000 [11:49<1:48:38,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  10%|█         | 200/2000 [11:53<1:48:45,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  10%|█         | 201/2000 [11:57<1:48:45,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  10%|█         | 202/2000 [12:00<1:48:58,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  10%|█         | 203/2000 [12:04<1:48:20,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  10%|█         | 204/2000 [12:07<1:47:23,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  10%|█         | 205/2000 [12:11<1:47:30,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  10%|█         | 206/2000 [12:15<1:48:01,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  10%|█         | 207/2000 [12:18<1:46:40,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  10%|█         | 208/2000 [12:22<1:45:41,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  10%|█         | 209/2000 [12:25<1:46:00,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  10%|█         | 210/2000 [12:29<1:45:40,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  11%|█         | 211/2000 [12:32<1:45:26,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  11%|█         | 212/2000 [12:36<1:45:32,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  11%|█         | 213/2000 [12:39<1:45:24,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  11%|█         | 214/2000 [12:43<1:45:04,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  11%|█         | 215/2000 [12:46<1:45:08,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  11%|█         | 216/2000 [12:50<1:45:02,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  11%|█         | 217/2000 [12:53<1:45:02,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  11%|█         | 218/2000 [12:57<1:45:06,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  11%|█         | 219/2000 [13:00<1:44:58,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  11%|█         | 220/2000 [13:04<1:45:13,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  11%|█         | 221/2000 [13:08<1:45:04,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  11%|█         | 222/2000 [13:11<1:45:55,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  11%|█         | 223/2000 [13:15<1:45:40,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  11%|█         | 224/2000 [13:18<1:45:41,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  11%|█▏        | 225/2000 [13:22<1:45:05,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  11%|█▏        | 226/2000 [13:25<1:44:53,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  11%|█▏        | 227/2000 [13:29<1:44:43,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  11%|█▏        | 228/2000 [13:32<1:44:35,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  11%|█▏        | 229/2000 [13:36<1:44:37,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  12%|█▏        | 230/2000 [13:40<1:44:32,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  12%|█▏        | 231/2000 [13:43<1:44:46,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  12%|█▏        | 232/2000 [13:47<1:44:44,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  12%|█▏        | 233/2000 [13:50<1:44:46,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  12%|█▏        | 234/2000 [13:54<1:44:47,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  12%|█▏        | 235/2000 [13:57<1:45:01,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  12%|█▏        | 236/2000 [14:01<1:44:39,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  12%|█▏        | 237/2000 [14:04<1:44:44,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  12%|█▏        | 238/2000 [14:08<1:44:22,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  12%|█▏        | 239/2000 [14:11<1:43:27,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  12%|█▏        | 240/2000 [14:15<1:42:43,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  12%|█▏        | 241/2000 [14:18<1:42:12,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  12%|█▏        | 242/2000 [14:22<1:41:46,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  12%|█▏        | 243/2000 [14:25<1:41:32,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  12%|█▏        | 244/2000 [14:29<1:41:19,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  12%|█▏        | 245/2000 [14:32<1:41:09,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  12%|█▏        | 246/2000 [14:36<1:41:07,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  12%|█▏        | 247/2000 [14:39<1:41:05,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  12%|█▏        | 248/2000 [14:43<1:40:48,  3.45s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  12%|█▏        | 249/2000 [14:46<1:40:51,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  12%|█▎        | 250/2000 [14:49<1:40:47,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  13%|█▎        | 251/2000 [14:53<1:40:42,  3.45s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  13%|█▎        | 252/2000 [14:56<1:40:38,  3.45s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  13%|█▎        | 253/2000 [15:00<1:40:46,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  13%|█▎        | 254/2000 [15:03<1:41:01,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  13%|█▎        | 255/2000 [15:07<1:41:15,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  13%|█▎        | 256/2000 [15:10<1:41:46,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  13%|█▎        | 257/2000 [15:14<1:41:35,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  13%|█▎        | 258/2000 [15:17<1:41:45,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  13%|█▎        | 259/2000 [15:21<1:41:32,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  13%|█▎        | 260/2000 [15:24<1:41:24,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  13%|█▎        | 261/2000 [15:28<1:41:03,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  13%|█▎        | 262/2000 [15:31<1:40:56,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  13%|█▎        | 263/2000 [15:35<1:40:45,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  13%|█▎        | 264/2000 [15:38<1:40:26,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  13%|█▎        | 265/2000 [15:42<1:40:09,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  13%|█▎        | 266/2000 [15:45<1:40:29,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  13%|█▎        | 267/2000 [15:49<1:40:48,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  13%|█▎        | 268/2000 [15:52<1:40:52,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  13%|█▎        | 269/2000 [15:56<1:41:01,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  14%|█▎        | 270/2000 [15:59<1:41:31,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  14%|█▎        | 271/2000 [16:03<1:41:17,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  14%|█▎        | 272/2000 [16:06<1:41:36,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  14%|█▎        | 273/2000 [16:10<1:41:54,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  14%|█▎        | 274/2000 [16:13<1:42:02,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  14%|█▍        | 275/2000 [16:17<1:42:52,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  14%|█▍        | 276/2000 [16:21<1:44:43,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  14%|█▍        | 277/2000 [16:25<1:44:27,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  14%|█▍        | 278/2000 [16:28<1:43:37,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  14%|█▍        | 279/2000 [16:32<1:43:07,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  14%|█▍        | 280/2000 [16:35<1:44:25,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  14%|█▍        | 281/2000 [16:39<1:44:17,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  14%|█▍        | 282/2000 [16:43<1:44:11,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  14%|█▍        | 283/2000 [16:46<1:44:04,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  14%|█▍        | 284/2000 [16:50<1:43:36,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  14%|█▍        | 285/2000 [16:54<1:43:22,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  14%|█▍        | 286/2000 [16:57<1:43:11,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  14%|█▍        | 287/2000 [17:01<1:43:06,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  14%|█▍        | 288/2000 [17:04<1:43:59,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  14%|█▍        | 289/2000 [17:08<1:43:44,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  14%|█▍        | 290/2000 [17:12<1:43:33,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  15%|█▍        | 291/2000 [17:15<1:43:03,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  15%|█▍        | 292/2000 [17:19<1:42:17,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  15%|█▍        | 293/2000 [17:22<1:41:45,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  15%|█▍        | 294/2000 [17:26<1:41:25,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  15%|█▍        | 295/2000 [17:29<1:41:06,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  15%|█▍        | 296/2000 [17:33<1:40:58,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  15%|█▍        | 297/2000 [17:37<1:40:55,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  15%|█▍        | 298/2000 [17:40<1:41:00,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  15%|█▍        | 299/2000 [17:44<1:40:53,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  15%|█▌        | 300/2000 [17:47<1:40:52,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  15%|█▌        | 301/2000 [17:51<1:40:58,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  15%|█▌        | 302/2000 [17:54<1:40:39,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  15%|█▌        | 303/2000 [17:58<1:40:12,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  15%|█▌        | 304/2000 [18:01<1:40:26,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  15%|█▌        | 305/2000 [18:05<1:39:55,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  15%|█▌        | 306/2000 [18:08<1:39:06,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  15%|█▌        | 307/2000 [18:12<1:38:39,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  15%|█▌        | 308/2000 [18:15<1:38:16,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  15%|█▌        | 309/2000 [18:19<1:37:51,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  16%|█▌        | 310/2000 [18:22<1:37:31,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  16%|█▌        | 311/2000 [18:26<1:37:10,  3.45s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  16%|█▌        | 312/2000 [18:29<1:37:06,  3.45s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  16%|█▌        | 313/2000 [18:33<1:36:58,  3.45s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  16%|█▌        | 314/2000 [18:36<1:36:48,  3.45s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  16%|█▌        | 315/2000 [18:39<1:36:52,  3.45s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  16%|█▌        | 316/2000 [18:43<1:36:56,  3.45s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  16%|█▌        | 317/2000 [18:46<1:36:49,  3.45s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  16%|█▌        | 318/2000 [18:50<1:36:52,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  16%|█▌        | 319/2000 [18:53<1:36:36,  3.45s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  16%|█▌        | 320/2000 [18:57<1:36:31,  3.45s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  16%|█▌        | 321/2000 [19:00<1:36:19,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  16%|█▌        | 322/2000 [19:04<1:36:13,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  16%|█▌        | 323/2000 [19:07<1:36:08,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  16%|█▌        | 324/2000 [19:10<1:36:06,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  16%|█▋        | 325/2000 [19:14<1:36:13,  3.45s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  16%|█▋        | 326/2000 [19:17<1:36:01,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  16%|█▋        | 327/2000 [19:21<1:35:51,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  16%|█▋        | 328/2000 [19:24<1:36:32,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  16%|█▋        | 329/2000 [19:28<1:36:37,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  16%|█▋        | 330/2000 [19:31<1:36:33,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  17%|█▋        | 331/2000 [19:35<1:36:59,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  17%|█▋        | 332/2000 [19:38<1:36:54,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  17%|█▋        | 333/2000 [19:42<1:36:45,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  17%|█▋        | 334/2000 [19:45<1:36:43,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  17%|█▋        | 335/2000 [19:49<1:36:53,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  17%|█▋        | 336/2000 [19:52<1:36:50,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  17%|█▋        | 337/2000 [19:56<1:36:53,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  17%|█▋        | 338/2000 [19:59<1:37:49,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  17%|█▋        | 339/2000 [20:03<1:38:32,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  17%|█▋        | 340/2000 [20:07<1:38:53,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  17%|█▋        | 341/2000 [20:10<1:39:08,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  17%|█▋        | 342/2000 [20:14<1:39:22,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  17%|█▋        | 343/2000 [20:17<1:39:24,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  17%|█▋        | 344/2000 [20:21<1:38:41,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  17%|█▋        | 345/2000 [20:24<1:38:20,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  17%|█▋        | 346/2000 [20:28<1:39:19,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  17%|█▋        | 347/2000 [20:32<1:38:49,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  17%|█▋        | 348/2000 [20:35<1:38:31,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  17%|█▋        | 349/2000 [20:39<1:38:20,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  18%|█▊        | 350/2000 [20:43<1:40:15,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  18%|█▊        | 351/2000 [20:46<1:40:15,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  18%|█▊        | 352/2000 [20:50<1:40:05,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  18%|█▊        | 353/2000 [20:53<1:39:23,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  18%|█▊        | 354/2000 [20:57<1:38:54,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  18%|█▊        | 355/2000 [21:01<1:38:31,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  18%|█▊        | 356/2000 [21:04<1:38:12,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  18%|█▊        | 357/2000 [21:08<1:38:06,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  18%|█▊        | 358/2000 [21:11<1:37:55,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  18%|█▊        | 359/2000 [21:15<1:37:56,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  18%|█▊        | 360/2000 [21:19<1:38:44,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  18%|█▊        | 361/2000 [21:22<1:38:01,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  18%|█▊        | 362/2000 [21:26<1:37:33,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  18%|█▊        | 363/2000 [21:29<1:37:52,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  18%|█▊        | 364/2000 [21:33<1:37:42,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  18%|█▊        | 365/2000 [21:36<1:37:24,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  18%|█▊        | 366/2000 [21:40<1:37:10,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  18%|█▊        | 367/2000 [21:44<1:37:25,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  18%|█▊        | 368/2000 [21:47<1:37:36,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  18%|█▊        | 369/2000 [21:51<1:37:57,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  18%|█▊        | 370/2000 [21:54<1:37:20,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  19%|█▊        | 371/2000 [21:58<1:36:59,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  19%|█▊        | 372/2000 [22:01<1:36:35,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  19%|█▊        | 373/2000 [22:05<1:36:12,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  19%|█▊        | 374/2000 [22:08<1:36:09,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  19%|█▉        | 375/2000 [22:12<1:36:04,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  19%|█▉        | 376/2000 [22:16<1:35:52,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  19%|█▉        | 377/2000 [22:19<1:35:51,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  19%|█▉        | 378/2000 [22:23<1:35:45,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  19%|█▉        | 379/2000 [22:26<1:35:37,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  19%|█▉        | 380/2000 [22:30<1:35:24,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  19%|█▉        | 381/2000 [22:33<1:35:28,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  19%|█▉        | 382/2000 [22:37<1:35:22,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  19%|█▉        | 383/2000 [22:40<1:35:22,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  19%|█▉        | 384/2000 [22:44<1:35:08,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  19%|█▉        | 385/2000 [22:47<1:35:13,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  19%|█▉        | 386/2000 [22:51<1:35:06,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  19%|█▉        | 387/2000 [22:54<1:35:13,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  19%|█▉        | 388/2000 [22:58<1:35:03,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  19%|█▉        | 389/2000 [23:02<1:35:13,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  20%|█▉        | 390/2000 [23:05<1:35:07,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  20%|█▉        | 391/2000 [23:09<1:35:11,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  20%|█▉        | 392/2000 [23:12<1:35:11,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  20%|█▉        | 393/2000 [23:16<1:35:56,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  20%|█▉        | 394/2000 [23:19<1:35:19,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  20%|█▉        | 395/2000 [23:23<1:34:59,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  20%|█▉        | 396/2000 [23:27<1:35:09,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  20%|█▉        | 397/2000 [23:30<1:35:15,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  20%|█▉        | 398/2000 [23:34<1:35:28,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  20%|█▉        | 399/2000 [23:37<1:35:42,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  20%|██        | 400/2000 [23:41<1:35:50,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  20%|██        | 401/2000 [23:44<1:35:24,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  20%|██        | 402/2000 [23:48<1:34:56,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  20%|██        | 403/2000 [23:52<1:34:32,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  20%|██        | 404/2000 [23:55<1:35:03,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  20%|██        | 405/2000 [23:59<1:34:55,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  20%|██        | 406/2000 [24:02<1:34:48,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  20%|██        | 407/2000 [24:06<1:34:44,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  20%|██        | 408/2000 [24:09<1:34:35,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  20%|██        | 409/2000 [24:13<1:34:32,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  20%|██        | 410/2000 [24:17<1:34:28,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  21%|██        | 411/2000 [24:20<1:34:36,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  21%|██        | 412/2000 [24:24<1:34:30,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  21%|██        | 413/2000 [24:27<1:34:33,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  21%|██        | 414/2000 [24:31<1:34:27,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  21%|██        | 415/2000 [24:34<1:34:30,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  21%|██        | 416/2000 [24:38<1:34:17,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  21%|██        | 417/2000 [24:42<1:34:23,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  21%|██        | 418/2000 [24:45<1:34:20,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  21%|██        | 419/2000 [24:49<1:34:20,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  21%|██        | 420/2000 [24:52<1:34:27,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  21%|██        | 421/2000 [24:56<1:33:42,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  21%|██        | 422/2000 [24:59<1:33:34,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  21%|██        | 423/2000 [25:03<1:34:09,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  21%|██        | 424/2000 [25:07<1:34:04,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  21%|██▏       | 425/2000 [25:10<1:34:00,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  21%|██▏       | 426/2000 [25:14<1:34:31,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  21%|██▏       | 427/2000 [25:17<1:34:44,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  21%|██▏       | 428/2000 [25:21<1:34:49,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  21%|██▏       | 429/2000 [25:25<1:34:39,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  22%|██▏       | 430/2000 [25:28<1:35:04,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  22%|██▏       | 431/2000 [25:32<1:34:44,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  22%|██▏       | 432/2000 [25:36<1:35:01,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  22%|██▏       | 433/2000 [25:39<1:34:25,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  22%|██▏       | 434/2000 [25:43<1:33:47,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  22%|██▏       | 435/2000 [25:46<1:33:17,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  22%|██▏       | 436/2000 [25:50<1:32:50,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  22%|██▏       | 437/2000 [25:53<1:32:35,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  22%|██▏       | 438/2000 [25:57<1:32:25,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  22%|██▏       | 439/2000 [26:00<1:32:16,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  22%|██▏       | 440/2000 [26:04<1:31:59,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  22%|██▏       | 441/2000 [26:08<1:32:01,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  22%|██▏       | 442/2000 [26:11<1:31:55,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  22%|██▏       | 443/2000 [26:15<1:31:43,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  22%|██▏       | 444/2000 [26:18<1:31:42,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  22%|██▏       | 445/2000 [26:22<1:31:43,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  22%|██▏       | 446/2000 [26:25<1:31:44,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  22%|██▏       | 447/2000 [26:29<1:31:38,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  22%|██▏       | 448/2000 [26:32<1:31:36,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  22%|██▏       | 449/2000 [26:36<1:31:33,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  22%|██▎       | 450/2000 [26:39<1:31:38,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  23%|██▎       | 451/2000 [26:43<1:31:32,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  23%|██▎       | 452/2000 [26:46<1:31:23,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  23%|██▎       | 453/2000 [26:50<1:31:29,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  23%|██▎       | 454/2000 [26:54<1:31:26,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  23%|██▎       | 455/2000 [26:57<1:31:19,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  23%|██▎       | 456/2000 [27:01<1:31:23,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  23%|██▎       | 457/2000 [27:04<1:31:30,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  23%|██▎       | 458/2000 [27:08<1:31:30,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  23%|██▎       | 459/2000 [27:11<1:31:23,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  23%|██▎       | 460/2000 [27:15<1:31:24,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  23%|██▎       | 461/2000 [27:19<1:31:23,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  23%|██▎       | 462/2000 [27:22<1:30:57,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  23%|██▎       | 463/2000 [27:26<1:31:24,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  23%|██▎       | 464/2000 [27:29<1:31:11,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  23%|██▎       | 465/2000 [27:33<1:30:50,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  23%|██▎       | 466/2000 [27:36<1:30:36,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  23%|██▎       | 467/2000 [27:40<1:30:26,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  23%|██▎       | 468/2000 [27:43<1:30:10,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  23%|██▎       | 469/2000 [27:47<1:30:17,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  24%|██▎       | 470/2000 [27:50<1:29:59,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  24%|██▎       | 471/2000 [27:54<1:29:54,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  24%|██▎       | 472/2000 [27:57<1:29:55,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  24%|██▎       | 473/2000 [28:01<1:29:49,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  24%|██▎       | 474/2000 [28:04<1:29:50,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  24%|██▍       | 475/2000 [28:08<1:29:40,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  24%|██▍       | 476/2000 [28:12<1:29:37,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  24%|██▍       | 477/2000 [28:15<1:29:31,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  24%|██▍       | 478/2000 [28:19<1:29:34,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  24%|██▍       | 479/2000 [28:22<1:29:46,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  24%|██▍       | 480/2000 [28:26<1:29:42,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  24%|██▍       | 481/2000 [28:29<1:29:25,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  24%|██▍       | 482/2000 [28:33<1:29:24,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  24%|██▍       | 483/2000 [28:36<1:29:26,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  24%|██▍       | 484/2000 [28:40<1:29:13,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  24%|██▍       | 485/2000 [28:43<1:29:18,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  24%|██▍       | 486/2000 [28:47<1:29:17,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  24%|██▍       | 487/2000 [28:50<1:29:15,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  24%|██▍       | 488/2000 [28:54<1:29:23,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  24%|██▍       | 489/2000 [28:58<1:29:25,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  24%|██▍       | 490/2000 [29:01<1:29:20,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  25%|██▍       | 491/2000 [29:05<1:29:26,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  25%|██▍       | 492/2000 [29:08<1:29:27,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  25%|██▍       | 493/2000 [29:12<1:29:04,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  25%|██▍       | 494/2000 [29:15<1:28:37,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  25%|██▍       | 495/2000 [29:19<1:28:28,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  25%|██▍       | 496/2000 [29:22<1:29:01,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  25%|██▍       | 497/2000 [29:26<1:28:35,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  25%|██▍       | 498/2000 [29:29<1:28:10,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  25%|██▍       | 499/2000 [29:33<1:27:56,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  25%|██▌       | 500/2000 [29:36<1:27:39,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  25%|██▌       | 501/2000 [29:40<1:27:27,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  25%|██▌       | 502/2000 [29:43<1:27:18,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  25%|██▌       | 503/2000 [29:47<1:27:26,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  25%|██▌       | 504/2000 [29:50<1:27:13,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  25%|██▌       | 505/2000 [29:54<1:27:14,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  25%|██▌       | 506/2000 [29:57<1:27:03,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  25%|██▌       | 507/2000 [30:01<1:27:28,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  25%|██▌       | 508/2000 [30:04<1:27:39,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  25%|██▌       | 509/2000 [30:08<1:27:49,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  26%|██▌       | 510/2000 [30:12<1:27:52,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  26%|██▌       | 511/2000 [30:15<1:27:52,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  26%|██▌       | 512/2000 [30:19<1:27:47,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  26%|██▌       | 513/2000 [30:22<1:27:37,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  26%|██▌       | 514/2000 [30:26<1:27:14,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  26%|██▌       | 515/2000 [30:29<1:27:10,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  26%|██▌       | 516/2000 [30:33<1:26:54,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  26%|██▌       | 517/2000 [30:36<1:26:51,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  26%|██▌       | 518/2000 [30:40<1:26:44,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  26%|██▌       | 519/2000 [30:43<1:26:49,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  26%|██▌       | 520/2000 [30:47<1:26:52,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  26%|██▌       | 521/2000 [30:50<1:26:54,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  26%|██▌       | 522/2000 [30:54<1:26:45,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  26%|██▌       | 523/2000 [30:57<1:26:48,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  26%|██▌       | 524/2000 [31:01<1:26:46,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  26%|██▋       | 525/2000 [31:04<1:26:53,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  26%|██▋       | 526/2000 [31:08<1:27:08,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  26%|██▋       | 527/2000 [31:12<1:27:28,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  26%|██▋       | 528/2000 [31:15<1:27:32,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  26%|██▋       | 529/2000 [31:19<1:26:51,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  26%|██▋       | 530/2000 [31:22<1:26:29,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  27%|██▋       | 531/2000 [31:26<1:26:13,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  27%|██▋       | 532/2000 [31:29<1:25:59,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  27%|██▋       | 533/2000 [31:33<1:25:52,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  27%|██▋       | 534/2000 [31:36<1:25:35,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  27%|██▋       | 535/2000 [31:40<1:25:29,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  27%|██▋       | 536/2000 [31:43<1:25:25,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  27%|██▋       | 537/2000 [31:47<1:25:12,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  27%|██▋       | 538/2000 [31:50<1:25:15,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  27%|██▋       | 539/2000 [31:54<1:25:11,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  27%|██▋       | 540/2000 [31:57<1:25:12,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  27%|██▋       | 541/2000 [32:01<1:24:59,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  27%|██▋       | 542/2000 [32:04<1:25:03,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  27%|██▋       | 543/2000 [32:08<1:25:04,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  27%|██▋       | 544/2000 [32:11<1:25:13,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  27%|██▋       | 545/2000 [32:15<1:24:59,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  27%|██▋       | 546/2000 [32:18<1:25:05,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  27%|██▋       | 547/2000 [32:22<1:24:59,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  27%|██▋       | 548/2000 [32:25<1:24:45,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  27%|██▋       | 549/2000 [32:29<1:24:51,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  28%|██▊       | 550/2000 [32:32<1:24:53,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  28%|██▊       | 551/2000 [32:36<1:24:52,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  28%|██▊       | 552/2000 [32:39<1:24:52,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  28%|██▊       | 553/2000 [32:43<1:24:49,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  28%|██▊       | 554/2000 [32:46<1:24:43,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  28%|██▊       | 555/2000 [32:50<1:24:51,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  28%|██▊       | 556/2000 [32:53<1:24:54,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  28%|██▊       | 557/2000 [32:57<1:24:56,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  28%|██▊       | 558/2000 [33:00<1:24:57,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  28%|██▊       | 559/2000 [33:04<1:24:35,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  28%|██▊       | 560/2000 [33:08<1:25:05,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  28%|██▊       | 561/2000 [33:11<1:24:42,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  28%|██▊       | 562/2000 [33:15<1:24:22,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  28%|██▊       | 563/2000 [33:18<1:24:09,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  28%|██▊       | 564/2000 [33:22<1:24:00,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  28%|██▊       | 565/2000 [33:25<1:23:51,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  28%|██▊       | 566/2000 [33:29<1:23:38,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  28%|██▊       | 567/2000 [33:32<1:23:37,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  28%|██▊       | 568/2000 [33:36<1:23:37,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  28%|██▊       | 569/2000 [33:39<1:23:30,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  28%|██▊       | 570/2000 [33:43<1:23:32,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  29%|██▊       | 571/2000 [33:46<1:23:26,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  29%|██▊       | 572/2000 [33:50<1:23:25,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  29%|██▊       | 573/2000 [33:53<1:23:11,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  29%|██▊       | 574/2000 [33:57<1:23:44,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  29%|██▉       | 575/2000 [34:00<1:23:40,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  29%|██▉       | 576/2000 [34:04<1:23:42,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  29%|██▉       | 577/2000 [34:07<1:23:33,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  29%|██▉       | 578/2000 [34:11<1:23:38,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  29%|██▉       | 579/2000 [34:14<1:23:35,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  29%|██▉       | 580/2000 [34:18<1:23:40,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  29%|██▉       | 581/2000 [34:21<1:23:41,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  29%|██▉       | 582/2000 [34:25<1:23:42,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  29%|██▉       | 583/2000 [34:28<1:23:45,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  29%|██▉       | 584/2000 [34:32<1:23:43,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  29%|██▉       | 585/2000 [34:36<1:23:40,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  29%|██▉       | 586/2000 [34:39<1:23:45,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  29%|██▉       | 587/2000 [34:43<1:23:40,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  29%|██▉       | 588/2000 [34:46<1:23:44,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  29%|██▉       | 589/2000 [34:50<1:23:58,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  30%|██▉       | 590/2000 [34:53<1:23:34,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  30%|██▉       | 591/2000 [34:57<1:23:29,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  30%|██▉       | 592/2000 [35:01<1:24:49,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  30%|██▉       | 593/2000 [35:04<1:24:34,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  30%|██▉       | 594/2000 [35:08<1:24:10,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  30%|██▉       | 595/2000 [35:11<1:24:03,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  30%|██▉       | 596/2000 [35:15<1:23:57,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  30%|██▉       | 597/2000 [35:19<1:23:41,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  30%|██▉       | 598/2000 [35:22<1:23:14,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  30%|██▉       | 599/2000 [35:26<1:22:55,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  30%|███       | 600/2000 [35:29<1:22:36,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  30%|███       | 601/2000 [35:33<1:22:27,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  30%|███       | 602/2000 [35:36<1:22:15,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  30%|███       | 603/2000 [35:40<1:22:09,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  30%|███       | 604/2000 [35:43<1:22:10,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  30%|███       | 605/2000 [35:47<1:22:03,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  30%|███       | 606/2000 [35:50<1:22:00,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  30%|███       | 607/2000 [35:54<1:21:51,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  30%|███       | 608/2000 [35:57<1:21:53,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  30%|███       | 609/2000 [36:01<1:21:46,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  30%|███       | 610/2000 [36:04<1:21:52,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  31%|███       | 611/2000 [36:08<1:21:42,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  31%|███       | 612/2000 [36:11<1:21:29,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  31%|███       | 613/2000 [36:15<1:21:34,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  31%|███       | 614/2000 [36:19<1:21:35,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  31%|███       | 615/2000 [36:22<1:21:45,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  31%|███       | 616/2000 [36:26<1:21:51,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  31%|███       | 617/2000 [36:29<1:21:56,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  31%|███       | 618/2000 [36:33<1:22:00,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  31%|███       | 619/2000 [36:36<1:22:02,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  31%|███       | 620/2000 [36:40<1:22:05,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  31%|███       | 621/2000 [36:44<1:22:21,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  31%|███       | 622/2000 [36:47<1:22:13,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  31%|███       | 623/2000 [36:51<1:22:11,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  31%|███       | 624/2000 [36:54<1:22:29,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  31%|███▏      | 625/2000 [36:58<1:22:06,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  31%|███▏      | 626/2000 [37:01<1:21:50,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  31%|███▏      | 627/2000 [37:05<1:21:48,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  31%|███▏      | 628/2000 [37:09<1:21:47,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  31%|███▏      | 629/2000 [37:12<1:21:44,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  32%|███▏      | 630/2000 [37:16<1:21:29,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  32%|███▏      | 631/2000 [37:19<1:21:21,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  32%|███▏      | 632/2000 [37:23<1:21:14,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  32%|███▏      | 633/2000 [37:26<1:21:02,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  32%|███▏      | 634/2000 [37:30<1:20:57,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  32%|███▏      | 635/2000 [37:33<1:20:47,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  32%|███▏      | 636/2000 [37:37<1:20:41,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  32%|███▏      | 637/2000 [37:41<1:20:36,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  32%|███▏      | 638/2000 [37:44<1:20:48,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  32%|███▏      | 639/2000 [37:48<1:20:46,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  32%|███▏      | 640/2000 [37:51<1:20:43,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  32%|███▏      | 641/2000 [37:55<1:20:38,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  32%|███▏      | 642/2000 [37:58<1:20:47,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  32%|███▏      | 643/2000 [38:02<1:20:34,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  32%|███▏      | 644/2000 [38:06<1:20:29,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  32%|███▏      | 645/2000 [38:09<1:20:43,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  32%|███▏      | 646/2000 [38:13<1:20:40,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  32%|███▏      | 647/2000 [38:16<1:20:34,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  32%|███▏      | 648/2000 [38:20<1:20:30,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  32%|███▏      | 649/2000 [38:23<1:20:31,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  32%|███▎      | 650/2000 [38:27<1:20:32,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  33%|███▎      | 651/2000 [38:31<1:20:41,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  33%|███▎      | 652/2000 [38:34<1:20:42,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  33%|███▎      | 653/2000 [38:38<1:20:50,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  33%|███▎      | 654/2000 [38:41<1:20:25,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  33%|███▎      | 655/2000 [38:45<1:20:42,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  33%|███▎      | 656/2000 [38:49<1:21:05,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  33%|███▎      | 657/2000 [38:52<1:20:35,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  33%|███▎      | 658/2000 [38:56<1:20:13,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  33%|███▎      | 659/2000 [38:59<1:19:52,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  33%|███▎      | 660/2000 [39:03<1:19:38,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  33%|███▎      | 661/2000 [39:06<1:19:28,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  33%|███▎      | 662/2000 [39:10<1:19:18,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  33%|███▎      | 663/2000 [39:14<1:19:20,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  33%|███▎      | 664/2000 [39:17<1:19:20,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  33%|███▎      | 665/2000 [39:21<1:19:15,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  33%|███▎      | 666/2000 [39:24<1:19:14,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  33%|███▎      | 667/2000 [39:28<1:19:06,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  33%|███▎      | 668/2000 [39:31<1:19:08,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  33%|███▎      | 669/2000 [39:35<1:19:00,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  34%|███▎      | 670/2000 [39:39<1:18:57,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  34%|███▎      | 671/2000 [39:42<1:18:51,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  34%|███▎      | 672/2000 [39:46<1:18:57,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  34%|███▎      | 673/2000 [39:49<1:18:48,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  34%|███▎      | 674/2000 [39:53<1:18:47,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  34%|███▍      | 675/2000 [39:56<1:18:48,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  34%|███▍      | 676/2000 [40:00<1:18:56,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  34%|███▍      | 677/2000 [40:04<1:19:18,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  34%|███▍      | 678/2000 [40:07<1:19:21,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  34%|███▍      | 679/2000 [40:11<1:19:28,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  34%|███▍      | 680/2000 [40:14<1:19:30,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  34%|███▍      | 681/2000 [40:18<1:19:29,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  34%|███▍      | 682/2000 [40:22<1:19:12,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  34%|███▍      | 683/2000 [40:25<1:19:01,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  34%|███▍      | 684/2000 [40:29<1:18:40,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  34%|███▍      | 685/2000 [40:32<1:18:07,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  34%|███▍      | 686/2000 [40:36<1:17:43,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  34%|███▍      | 687/2000 [40:39<1:17:59,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  34%|███▍      | 688/2000 [40:43<1:17:54,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  34%|███▍      | 689/2000 [40:47<1:17:23,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  34%|███▍      | 690/2000 [40:50<1:17:07,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  35%|███▍      | 691/2000 [40:54<1:16:56,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  35%|███▍      | 692/2000 [40:57<1:16:46,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  35%|███▍      | 693/2000 [41:01<1:16:38,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  35%|███▍      | 694/2000 [41:04<1:16:34,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  35%|███▍      | 695/2000 [41:08<1:16:33,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  35%|███▍      | 696/2000 [41:11<1:16:24,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  35%|███▍      | 697/2000 [41:15<1:16:17,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  35%|███▍      | 698/2000 [41:18<1:16:21,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  35%|███▍      | 699/2000 [41:22<1:16:28,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  35%|███▌      | 700/2000 [41:25<1:16:20,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  35%|███▌      | 701/2000 [41:29<1:16:14,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  35%|███▌      | 702/2000 [41:32<1:16:16,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  35%|███▌      | 703/2000 [41:36<1:16:05,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  35%|███▌      | 704/2000 [41:39<1:15:59,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  35%|███▌      | 705/2000 [41:43<1:16:22,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  35%|███▌      | 706/2000 [41:46<1:16:13,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  35%|███▌      | 707/2000 [41:50<1:16:06,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  35%|███▌      | 708/2000 [41:53<1:15:52,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  35%|███▌      | 709/2000 [41:57<1:16:25,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  36%|███▌      | 710/2000 [42:01<1:17:25,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  36%|███▌      | 711/2000 [42:04<1:17:08,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  36%|███▌      | 712/2000 [42:08<1:16:58,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  36%|███▌      | 713/2000 [42:11<1:16:44,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  36%|███▌      | 714/2000 [42:15<1:16:29,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  36%|███▌      | 715/2000 [42:19<1:16:31,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  36%|███▌      | 716/2000 [42:22<1:16:29,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  36%|███▌      | 717/2000 [42:26<1:16:12,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  36%|███▌      | 718/2000 [42:29<1:16:31,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  36%|███▌      | 719/2000 [42:33<1:16:58,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  36%|███▌      | 720/2000 [42:37<1:16:35,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  36%|███▌      | 721/2000 [42:40<1:16:26,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  36%|███▌      | 722/2000 [42:44<1:16:14,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  36%|███▌      | 723/2000 [42:47<1:16:14,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  36%|███▌      | 724/2000 [42:51<1:15:42,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  36%|███▋      | 725/2000 [42:54<1:15:19,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  36%|███▋      | 726/2000 [42:58<1:15:07,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  36%|███▋      | 727/2000 [43:01<1:14:54,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  36%|███▋      | 728/2000 [43:05<1:14:37,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  36%|███▋      | 729/2000 [43:08<1:14:26,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  36%|███▋      | 730/2000 [43:12<1:14:29,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  37%|███▋      | 731/2000 [43:15<1:14:17,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  37%|███▋      | 732/2000 [43:19<1:14:19,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  37%|███▋      | 733/2000 [43:22<1:14:13,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  37%|███▋      | 734/2000 [43:26<1:14:17,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  37%|███▋      | 735/2000 [43:29<1:14:07,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  37%|███▋      | 736/2000 [43:33<1:14:03,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  37%|███▋      | 737/2000 [43:36<1:13:52,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  37%|███▋      | 738/2000 [43:40<1:13:56,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  37%|███▋      | 739/2000 [43:43<1:13:55,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  37%|███▋      | 740/2000 [43:47<1:13:44,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  37%|███▋      | 741/2000 [43:51<1:13:48,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  37%|███▋      | 742/2000 [43:54<1:13:48,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  37%|███▋      | 743/2000 [43:58<1:13:46,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  37%|███▋      | 744/2000 [44:01<1:13:41,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  37%|███▋      | 745/2000 [44:05<1:13:41,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  37%|███▋      | 746/2000 [44:08<1:13:48,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  37%|███▋      | 747/2000 [44:12<1:13:51,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  37%|███▋      | 748/2000 [44:15<1:13:31,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  37%|███▋      | 749/2000 [44:19<1:13:51,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  38%|███▊      | 750/2000 [44:22<1:13:32,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  38%|███▊      | 751/2000 [44:26<1:13:47,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  38%|███▊      | 752/2000 [44:30<1:14:41,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  38%|███▊      | 753/2000 [44:33<1:14:35,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  38%|███▊      | 754/2000 [44:37<1:14:22,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  38%|███▊      | 755/2000 [44:40<1:14:11,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  38%|███▊      | 756/2000 [44:44<1:14:12,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  38%|███▊      | 757/2000 [44:47<1:14:12,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  38%|███▊      | 758/2000 [44:51<1:14:05,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  38%|███▊      | 759/2000 [44:55<1:14:03,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  38%|███▊      | 760/2000 [44:58<1:13:56,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  38%|███▊      | 761/2000 [45:02<1:14:03,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  38%|███▊      | 762/2000 [45:05<1:14:12,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  38%|███▊      | 763/2000 [45:09<1:14:16,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  38%|███▊      | 764/2000 [45:13<1:14:11,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  38%|███▊      | 765/2000 [45:16<1:14:13,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  38%|███▊      | 766/2000 [45:20<1:14:08,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  38%|███▊      | 767/2000 [45:23<1:13:48,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  38%|███▊      | 768/2000 [45:27<1:13:42,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  38%|███▊      | 769/2000 [45:31<1:13:30,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  38%|███▊      | 770/2000 [45:34<1:13:28,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  39%|███▊      | 771/2000 [45:38<1:13:25,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  39%|███▊      | 772/2000 [45:41<1:13:16,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  39%|███▊      | 773/2000 [45:45<1:13:38,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  39%|███▊      | 774/2000 [45:49<1:13:28,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  39%|███▉      | 775/2000 [45:52<1:13:20,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  39%|███▉      | 776/2000 [45:56<1:13:19,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  39%|███▉      | 777/2000 [45:59<1:13:06,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  39%|███▉      | 778/2000 [46:03<1:12:58,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  39%|███▉      | 779/2000 [46:06<1:12:59,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  39%|███▉      | 780/2000 [46:10<1:12:59,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  39%|███▉      | 781/2000 [46:14<1:13:12,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  39%|███▉      | 782/2000 [46:17<1:13:22,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  39%|███▉      | 783/2000 [46:21<1:14:03,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  39%|███▉      | 784/2000 [46:25<1:13:27,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  39%|███▉      | 785/2000 [46:28<1:12:55,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  39%|███▉      | 786/2000 [46:32<1:12:37,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  39%|███▉      | 787/2000 [46:35<1:12:21,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  39%|███▉      | 788/2000 [46:39<1:12:09,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  39%|███▉      | 789/2000 [46:42<1:11:59,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  40%|███▉      | 790/2000 [46:46<1:11:49,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  40%|███▉      | 791/2000 [46:50<1:11:44,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  40%|███▉      | 792/2000 [46:53<1:11:37,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  40%|███▉      | 793/2000 [46:57<1:11:40,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  40%|███▉      | 794/2000 [47:00<1:11:31,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  40%|███▉      | 795/2000 [47:04<1:11:35,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  40%|███▉      | 796/2000 [47:07<1:11:26,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  40%|███▉      | 797/2000 [47:11<1:11:27,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  40%|███▉      | 798/2000 [47:14<1:11:17,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  40%|███▉      | 799/2000 [47:18<1:11:19,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  40%|████      | 800/2000 [47:22<1:11:11,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  40%|████      | 801/2000 [47:25<1:11:11,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  40%|████      | 802/2000 [47:29<1:11:06,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  40%|████      | 803/2000 [47:32<1:11:04,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  40%|████      | 804/2000 [47:36<1:11:05,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  40%|████      | 805/2000 [47:39<1:11:03,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  40%|████      | 806/2000 [47:43<1:11:04,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  40%|████      | 807/2000 [47:47<1:11:06,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  40%|████      | 808/2000 [47:50<1:11:04,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  40%|████      | 809/2000 [47:54<1:11:06,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  40%|████      | 810/2000 [47:57<1:11:03,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  41%|████      | 811/2000 [48:01<1:11:03,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  41%|████      | 812/2000 [48:05<1:11:10,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  41%|████      | 813/2000 [48:08<1:11:26,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  41%|████      | 814/2000 [48:12<1:11:00,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  41%|████      | 815/2000 [48:15<1:11:21,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  41%|████      | 816/2000 [48:19<1:10:58,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  41%|████      | 817/2000 [48:23<1:10:42,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  41%|████      | 818/2000 [48:26<1:10:27,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  41%|████      | 819/2000 [48:30<1:10:18,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  41%|████      | 820/2000 [48:33<1:10:12,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  41%|████      | 821/2000 [48:37<1:10:01,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  41%|████      | 822/2000 [48:40<1:09:49,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  41%|████      | 823/2000 [48:44<1:09:47,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  41%|████      | 824/2000 [48:47<1:09:36,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  41%|████▏     | 825/2000 [48:51<1:09:33,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  41%|████▏     | 826/2000 [48:54<1:09:24,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  41%|████▏     | 827/2000 [48:58<1:09:26,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  41%|████▏     | 828/2000 [49:02<1:09:20,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  41%|████▏     | 829/2000 [49:05<1:09:18,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  42%|████▏     | 830/2000 [49:09<1:09:15,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  42%|████▏     | 831/2000 [49:12<1:09:20,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  42%|████▏     | 832/2000 [49:16<1:09:13,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  42%|████▏     | 833/2000 [49:19<1:09:14,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  42%|████▏     | 834/2000 [49:23<1:09:16,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  42%|████▏     | 835/2000 [49:26<1:09:09,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  42%|████▏     | 836/2000 [49:30<1:09:16,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  42%|████▏     | 837/2000 [49:34<1:09:15,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  42%|████▏     | 838/2000 [49:37<1:09:14,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  42%|████▏     | 839/2000 [49:41<1:09:14,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  42%|████▏     | 840/2000 [49:44<1:09:13,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  42%|████▏     | 841/2000 [49:48<1:09:09,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  42%|████▏     | 842/2000 [49:52<1:09:13,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  42%|████▏     | 843/2000 [49:55<1:09:18,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  42%|████▏     | 844/2000 [49:59<1:09:32,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  42%|████▏     | 845/2000 [50:02<1:09:32,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  42%|████▏     | 846/2000 [50:06<1:10:01,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  42%|████▏     | 847/2000 [50:10<1:10:10,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  42%|████▏     | 848/2000 [50:13<1:09:53,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  42%|████▏     | 849/2000 [50:17<1:09:37,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  42%|████▎     | 850/2000 [50:21<1:09:14,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  43%|████▎     | 851/2000 [50:24<1:08:51,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  43%|████▎     | 852/2000 [50:28<1:10:01,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  43%|████▎     | 853/2000 [50:32<1:09:10,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  43%|████▎     | 854/2000 [50:35<1:08:41,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  43%|████▎     | 855/2000 [50:39<1:08:09,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  43%|████▎     | 856/2000 [50:42<1:07:45,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  43%|████▎     | 857/2000 [50:46<1:07:33,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  43%|████▎     | 858/2000 [50:49<1:07:19,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  43%|████▎     | 859/2000 [50:53<1:07:18,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  43%|████▎     | 860/2000 [50:56<1:07:06,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  43%|████▎     | 861/2000 [51:00<1:06:58,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  43%|████▎     | 862/2000 [51:03<1:06:50,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  43%|████▎     | 863/2000 [51:07<1:06:49,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  43%|████▎     | 864/2000 [51:10<1:06:41,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  43%|████▎     | 865/2000 [51:14<1:06:39,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  43%|████▎     | 866/2000 [51:17<1:06:36,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  43%|████▎     | 867/2000 [51:21<1:06:34,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  43%|████▎     | 868/2000 [51:24<1:06:38,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  43%|████▎     | 869/2000 [51:28<1:06:33,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  44%|████▎     | 870/2000 [51:32<1:06:40,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  44%|████▎     | 871/2000 [51:35<1:06:36,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  44%|████▎     | 872/2000 [51:39<1:06:30,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  44%|████▎     | 873/2000 [51:42<1:06:28,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  44%|████▎     | 874/2000 [51:46<1:06:29,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  44%|████▍     | 875/2000 [51:49<1:07:18,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  44%|████▍     | 876/2000 [51:53<1:06:46,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  44%|████▍     | 877/2000 [51:57<1:07:52,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  44%|████▍     | 878/2000 [52:00<1:07:58,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  44%|████▍     | 879/2000 [52:04<1:07:29,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  44%|████▍     | 880/2000 [52:07<1:07:06,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  44%|████▍     | 881/2000 [52:11<1:06:57,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  44%|████▍     | 882/2000 [52:15<1:06:48,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  44%|████▍     | 883/2000 [52:18<1:06:43,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  44%|████▍     | 884/2000 [52:22<1:06:44,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  44%|████▍     | 885/2000 [52:25<1:06:42,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  44%|████▍     | 886/2000 [52:29<1:06:32,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  44%|████▍     | 887/2000 [52:33<1:06:33,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  44%|████▍     | 888/2000 [52:36<1:06:33,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  44%|████▍     | 889/2000 [52:40<1:06:28,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  44%|████▍     | 890/2000 [52:43<1:06:32,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  45%|████▍     | 891/2000 [52:47<1:06:28,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  45%|████▍     | 892/2000 [52:51<1:06:33,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  45%|████▍     | 893/2000 [52:54<1:06:27,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  45%|████▍     | 894/2000 [52:58<1:06:55,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  45%|████▍     | 895/2000 [53:01<1:06:15,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  45%|████▍     | 896/2000 [53:05<1:05:48,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  45%|████▍     | 897/2000 [53:08<1:05:33,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  45%|████▍     | 898/2000 [53:12<1:05:19,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  45%|████▍     | 899/2000 [53:15<1:05:01,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  45%|████▌     | 900/2000 [53:19<1:05:32,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  45%|████▌     | 901/2000 [53:23<1:05:37,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  45%|████▌     | 902/2000 [53:26<1:05:42,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  45%|████▌     | 903/2000 [53:30<1:05:41,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  45%|████▌     | 904/2000 [53:34<1:05:43,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  45%|████▌     | 905/2000 [53:37<1:05:37,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  45%|████▌     | 906/2000 [53:41<1:05:32,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  45%|████▌     | 907/2000 [53:44<1:05:35,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  45%|████▌     | 908/2000 [53:48<1:05:53,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  45%|████▌     | 909/2000 [53:52<1:05:23,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  46%|████▌     | 910/2000 [53:55<1:05:00,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  46%|████▌     | 911/2000 [53:59<1:05:08,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  46%|████▌     | 912/2000 [54:02<1:04:53,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  46%|████▌     | 913/2000 [54:06<1:04:59,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  46%|████▌     | 914/2000 [54:09<1:04:39,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  46%|████▌     | 915/2000 [54:13<1:04:24,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  46%|████▌     | 916/2000 [54:16<1:04:13,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  46%|████▌     | 917/2000 [54:20<1:04:00,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  46%|████▌     | 918/2000 [54:24<1:03:52,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  46%|████▌     | 919/2000 [54:27<1:04:44,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  46%|████▌     | 920/2000 [54:31<1:05:04,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  46%|████▌     | 921/2000 [54:34<1:04:37,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  46%|████▌     | 922/2000 [54:38<1:04:16,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  46%|████▌     | 923/2000 [54:42<1:03:57,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  46%|████▌     | 924/2000 [54:45<1:04:03,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  46%|████▋     | 925/2000 [54:49<1:03:49,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  46%|████▋     | 926/2000 [54:52<1:03:40,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  46%|████▋     | 927/2000 [54:56<1:03:27,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  46%|████▋     | 928/2000 [54:59<1:03:30,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  46%|████▋     | 929/2000 [55:03<1:03:59,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  46%|████▋     | 930/2000 [55:07<1:04:02,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  47%|████▋     | 931/2000 [55:10<1:04:05,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  47%|████▋     | 932/2000 [55:14<1:04:09,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  47%|████▋     | 933/2000 [55:17<1:04:05,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  47%|████▋     | 934/2000 [55:21<1:03:59,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  47%|████▋     | 935/2000 [55:25<1:03:45,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  47%|████▋     | 936/2000 [55:28<1:03:42,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  47%|████▋     | 937/2000 [55:32<1:03:36,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  47%|████▋     | 938/2000 [55:35<1:03:25,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  47%|████▋     | 939/2000 [55:39<1:03:28,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  47%|████▋     | 940/2000 [55:43<1:03:28,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  47%|████▋     | 941/2000 [55:46<1:03:24,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  47%|████▋     | 942/2000 [55:50<1:03:28,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  47%|████▋     | 943/2000 [55:54<1:04:53,  3.68s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  47%|████▋     | 944/2000 [55:57<1:04:21,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  47%|████▋     | 945/2000 [56:01<1:04:21,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  47%|████▋     | 946/2000 [56:05<1:04:29,  3.67s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  47%|████▋     | 947/2000 [56:08<1:04:03,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  47%|████▋     | 948/2000 [56:12<1:03:43,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  47%|████▋     | 949/2000 [56:15<1:03:25,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  48%|████▊     | 950/2000 [56:19<1:03:10,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  48%|████▊     | 951/2000 [56:23<1:02:59,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  48%|████▊     | 952/2000 [56:26<1:02:51,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  48%|████▊     | 953/2000 [56:30<1:02:50,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  48%|████▊     | 954/2000 [56:33<1:02:41,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  48%|████▊     | 955/2000 [56:37<1:02:34,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  48%|████▊     | 956/2000 [56:40<1:02:33,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  48%|████▊     | 957/2000 [56:44<1:02:24,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  48%|████▊     | 958/2000 [56:48<1:02:27,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  48%|████▊     | 959/2000 [56:51<1:02:27,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  48%|████▊     | 960/2000 [56:55<1:02:26,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  48%|████▊     | 961/2000 [56:58<1:02:17,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  48%|████▊     | 962/2000 [57:02<1:02:21,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  48%|████▊     | 963/2000 [57:06<1:02:17,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  48%|████▊     | 964/2000 [57:09<1:02:09,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  48%|████▊     | 965/2000 [57:13<1:02:13,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  48%|████▊     | 966/2000 [57:16<1:01:49,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  48%|████▊     | 967/2000 [57:20<1:02:03,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  48%|████▊     | 968/2000 [57:24<1:01:37,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  48%|████▊     | 969/2000 [57:27<1:01:42,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  48%|████▊     | 970/2000 [57:31<1:01:22,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  49%|████▊     | 971/2000 [57:34<1:01:07,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  49%|████▊     | 972/2000 [57:38<1:00:56,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  49%|████▊     | 973/2000 [57:41<1:00:51,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  49%|████▊     | 974/2000 [57:45<1:00:50,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  49%|████▉     | 975/2000 [57:49<1:01:00,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  49%|████▉     | 976/2000 [57:52<1:00:45,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  49%|████▉     | 977/2000 [57:56<1:00:55,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  49%|████▉     | 978/2000 [57:59<1:00:48,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  49%|████▉     | 979/2000 [58:03<1:00:20,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  49%|████▉     | 980/2000 [58:06<1:01:14,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  49%|████▉     | 981/2000 [58:10<1:01:06,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  49%|████▉     | 982/2000 [58:14<1:01:00,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  49%|████▉     | 983/2000 [58:17<1:01:25,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  49%|████▉     | 984/2000 [58:21<1:00:52,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  49%|████▉     | 985/2000 [58:24<1:00:32,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  49%|████▉     | 986/2000 [58:28<1:00:10,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  49%|████▉     | 987/2000 [58:31<59:57,  3.55s/it]  Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  49%|████▉     | 988/2000 [58:35<59:48,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  49%|████▉     | 989/2000 [58:39<59:37,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  50%|████▉     | 990/2000 [58:42<59:37,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  50%|████▉     | 991/2000 [58:46<59:31,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  50%|████▉     | 992/2000 [58:49<59:30,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  50%|████▉     | 993/2000 [58:53<59:22,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  50%|████▉     | 994/2000 [58:56<59:30,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  50%|████▉     | 995/2000 [59:00<59:27,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  50%|████▉     | 996/2000 [59:03<59:22,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  50%|████▉     | 997/2000 [59:07<59:21,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  50%|████▉     | 998/2000 [59:10<59:13,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  50%|████▉     | 999/2000 [59:14<59:17,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  50%|█████     | 1000/2000 [59:18<59:15,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  50%|█████     | 1001/2000 [59:21<59:21,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  50%|█████     | 1002/2000 [59:25<59:17,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  50%|█████     | 1003/2000 [59:28<59:08,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  50%|█████     | 1004/2000 [59:32<59:06,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  50%|█████     | 1005/2000 [59:35<59:07,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  50%|█████     | 1006/2000 [59:39<59:00,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  50%|█████     | 1007/2000 [59:43<58:58,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  50%|█████     | 1008/2000 [59:46<59:25,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  50%|█████     | 1009/2000 [59:50<59:59,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  50%|█████     | 1010/2000 [59:53<59:24,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  51%|█████     | 1011/2000 [59:57<59:01,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  51%|█████     | 1012/2000 [1:00:01<59:11,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  51%|█████     | 1013/2000 [1:00:04<59:04,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  51%|█████     | 1014/2000 [1:00:08<58:56,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  51%|█████     | 1015/2000 [1:00:11<58:47,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  51%|█████     | 1016/2000 [1:00:15<58:41,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  51%|█████     | 1017/2000 [1:00:18<58:28,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  51%|█████     | 1018/2000 [1:00:22<58:09,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  51%|█████     | 1019/2000 [1:00:26<57:57,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  51%|█████     | 1020/2000 [1:00:29<57:52,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  51%|█████     | 1021/2000 [1:00:33<57:44,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  51%|█████     | 1022/2000 [1:00:36<58:01,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  51%|█████     | 1023/2000 [1:00:40<58:03,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  51%|█████     | 1024/2000 [1:00:43<58:34,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  51%|█████▏    | 1025/2000 [1:00:47<58:09,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  51%|█████▏    | 1026/2000 [1:00:50<57:43,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  51%|█████▏    | 1027/2000 [1:00:54<57:19,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  51%|█████▏    | 1028/2000 [1:00:57<57:01,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  51%|█████▏    | 1029/2000 [1:01:01<56:53,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  52%|█████▏    | 1030/2000 [1:01:04<56:53,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  52%|█████▏    | 1031/2000 [1:01:08<56:49,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  52%|█████▏    | 1032/2000 [1:01:12<57:00,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  52%|█████▏    | 1033/2000 [1:01:15<57:02,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  52%|█████▏    | 1034/2000 [1:01:19<57:01,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  52%|█████▏    | 1035/2000 [1:01:22<57:07,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  52%|█████▏    | 1036/2000 [1:01:26<57:04,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  52%|█████▏    | 1037/2000 [1:01:29<57:04,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  52%|█████▏    | 1038/2000 [1:01:33<57:08,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  52%|█████▏    | 1039/2000 [1:01:36<56:55,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  52%|█████▏    | 1040/2000 [1:01:40<57:00,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  52%|█████▏    | 1041/2000 [1:01:44<58:00,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  52%|█████▏    | 1042/2000 [1:01:47<57:27,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  52%|█████▏    | 1043/2000 [1:01:51<57:05,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  52%|█████▏    | 1044/2000 [1:01:54<56:51,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  52%|█████▏    | 1045/2000 [1:01:58<56:32,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  52%|█████▏    | 1046/2000 [1:02:01<56:17,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  52%|█████▏    | 1047/2000 [1:02:05<56:13,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  52%|█████▏    | 1048/2000 [1:02:09<56:06,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  52%|█████▏    | 1049/2000 [1:02:12<56:01,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  52%|█████▎    | 1050/2000 [1:02:16<55:52,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  53%|█████▎    | 1051/2000 [1:02:19<55:52,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  53%|█████▎    | 1052/2000 [1:02:23<55:44,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  53%|█████▎    | 1053/2000 [1:02:26<55:40,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  53%|█████▎    | 1054/2000 [1:02:30<55:35,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  53%|█████▎    | 1055/2000 [1:02:33<55:37,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  53%|█████▎    | 1056/2000 [1:02:37<55:30,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  53%|█████▎    | 1057/2000 [1:02:40<55:28,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  53%|█████▎    | 1058/2000 [1:02:44<55:25,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  53%|█████▎    | 1059/2000 [1:02:47<55:29,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  53%|█████▎    | 1060/2000 [1:02:51<55:19,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  53%|█████▎    | 1061/2000 [1:02:54<55:17,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  53%|█████▎    | 1062/2000 [1:02:58<55:23,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  53%|█████▎    | 1063/2000 [1:03:02<55:21,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  53%|█████▎    | 1064/2000 [1:03:05<55:17,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  53%|█████▎    | 1065/2000 [1:03:09<55:13,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  53%|█████▎    | 1066/2000 [1:03:12<55:13,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  53%|█████▎    | 1067/2000 [1:03:16<55:13,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  53%|█████▎    | 1068/2000 [1:03:19<55:07,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  53%|█████▎    | 1069/2000 [1:03:23<55:07,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  54%|█████▎    | 1070/2000 [1:03:26<55:10,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  54%|█████▎    | 1071/2000 [1:03:30<55:22,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  54%|█████▎    | 1072/2000 [1:03:34<56:06,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  54%|█████▎    | 1073/2000 [1:03:38<56:59,  3.69s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  54%|█████▎    | 1074/2000 [1:03:41<56:28,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  54%|█████▍    | 1075/2000 [1:03:45<56:15,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  54%|█████▍    | 1076/2000 [1:03:48<55:56,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  54%|█████▍    | 1077/2000 [1:03:52<55:44,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  54%|█████▍    | 1078/2000 [1:03:56<55:30,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  54%|█████▍    | 1079/2000 [1:03:59<55:25,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  54%|█████▍    | 1080/2000 [1:04:03<55:20,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  54%|█████▍    | 1081/2000 [1:04:06<55:11,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  54%|█████▍    | 1082/2000 [1:04:10<55:08,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  54%|█████▍    | 1083/2000 [1:04:14<55:05,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  54%|█████▍    | 1084/2000 [1:04:17<55:03,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  54%|█████▍    | 1085/2000 [1:04:21<54:58,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  54%|█████▍    | 1086/2000 [1:04:24<54:58,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  54%|█████▍    | 1087/2000 [1:04:28<54:57,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  54%|█████▍    | 1088/2000 [1:04:32<54:54,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  54%|█████▍    | 1089/2000 [1:04:35<54:48,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  55%|█████▍    | 1090/2000 [1:04:39<54:38,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  55%|█████▍    | 1091/2000 [1:04:42<54:35,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  55%|█████▍    | 1092/2000 [1:04:46<54:38,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  55%|█████▍    | 1093/2000 [1:04:50<54:35,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  55%|█████▍    | 1094/2000 [1:04:53<54:30,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  55%|█████▍    | 1095/2000 [1:04:57<54:32,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  55%|█████▍    | 1096/2000 [1:05:01<54:40,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  55%|█████▍    | 1097/2000 [1:05:04<54:41,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  55%|█████▍    | 1098/2000 [1:05:08<54:45,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  55%|█████▍    | 1099/2000 [1:05:12<54:43,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  55%|█████▌    | 1100/2000 [1:05:15<54:40,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  55%|█████▌    | 1101/2000 [1:05:19<54:40,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  55%|█████▌    | 1102/2000 [1:05:22<54:22,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  55%|█████▌    | 1103/2000 [1:05:26<54:29,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  55%|█████▌    | 1104/2000 [1:05:30<54:36,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  55%|█████▌    | 1105/2000 [1:05:33<54:15,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  55%|█████▌    | 1106/2000 [1:05:37<53:58,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  55%|█████▌    | 1107/2000 [1:05:41<53:49,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  55%|█████▌    | 1108/2000 [1:05:44<53:41,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  55%|█████▌    | 1109/2000 [1:05:48<53:37,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  56%|█████▌    | 1110/2000 [1:05:51<53:33,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  56%|█████▌    | 1111/2000 [1:05:55<53:31,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  56%|█████▌    | 1112/2000 [1:05:59<53:25,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  56%|█████▌    | 1113/2000 [1:06:02<53:16,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  56%|█████▌    | 1114/2000 [1:06:06<53:08,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  56%|█████▌    | 1115/2000 [1:06:09<53:00,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  56%|█████▌    | 1116/2000 [1:06:13<52:55,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  56%|█████▌    | 1117/2000 [1:06:17<52:49,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  56%|█████▌    | 1118/2000 [1:06:20<52:40,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  56%|█████▌    | 1119/2000 [1:06:24<52:46,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  56%|█████▌    | 1120/2000 [1:06:27<52:41,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  56%|█████▌    | 1121/2000 [1:06:31<52:42,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  56%|█████▌    | 1122/2000 [1:06:35<52:41,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  56%|█████▌    | 1123/2000 [1:06:38<52:35,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  56%|█████▌    | 1124/2000 [1:06:42<52:34,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  56%|█████▋    | 1125/2000 [1:06:45<52:21,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  56%|█████▋    | 1126/2000 [1:06:49<52:04,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  56%|█████▋    | 1127/2000 [1:06:52<51:56,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  56%|█████▋    | 1128/2000 [1:06:56<51:45,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  56%|█████▋    | 1129/2000 [1:07:00<51:36,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  56%|█████▋    | 1130/2000 [1:07:03<51:51,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  57%|█████▋    | 1131/2000 [1:07:07<52:12,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  57%|█████▋    | 1132/2000 [1:07:10<52:12,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  57%|█████▋    | 1133/2000 [1:07:14<52:20,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  57%|█████▋    | 1134/2000 [1:07:18<51:57,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  57%|█████▋    | 1135/2000 [1:07:21<51:41,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  57%|█████▋    | 1136/2000 [1:07:25<51:24,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  57%|█████▋    | 1137/2000 [1:07:28<51:08,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  57%|█████▋    | 1138/2000 [1:07:32<51:23,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  57%|█████▋    | 1139/2000 [1:07:35<51:07,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  57%|█████▋    | 1140/2000 [1:07:39<51:00,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  57%|█████▋    | 1141/2000 [1:07:42<50:48,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  57%|█████▋    | 1142/2000 [1:07:46<50:38,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  57%|█████▋    | 1143/2000 [1:07:50<50:34,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  57%|█████▋    | 1144/2000 [1:07:53<50:34,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  57%|█████▋    | 1145/2000 [1:07:57<50:30,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  57%|█████▋    | 1146/2000 [1:08:00<50:27,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  57%|█████▋    | 1147/2000 [1:08:04<50:23,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  57%|█████▋    | 1148/2000 [1:08:07<50:20,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  57%|█████▋    | 1149/2000 [1:08:11<50:12,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  57%|█████▊    | 1150/2000 [1:08:14<50:07,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  58%|█████▊    | 1151/2000 [1:08:18<50:05,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  58%|█████▊    | 1152/2000 [1:08:21<50:01,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  58%|█████▊    | 1153/2000 [1:08:25<49:54,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  58%|█████▊    | 1154/2000 [1:08:29<49:55,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  58%|█████▊    | 1155/2000 [1:08:32<49:54,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  58%|█████▊    | 1156/2000 [1:08:36<49:54,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  58%|█████▊    | 1157/2000 [1:08:39<49:54,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  58%|█████▊    | 1158/2000 [1:08:43<49:57,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  58%|█████▊    | 1159/2000 [1:08:46<49:53,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  58%|█████▊    | 1160/2000 [1:08:50<49:50,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  58%|█████▊    | 1161/2000 [1:08:53<49:37,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  58%|█████▊    | 1162/2000 [1:08:57<49:42,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  58%|█████▊    | 1163/2000 [1:09:01<49:40,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  58%|█████▊    | 1164/2000 [1:09:04<49:24,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  58%|█████▊    | 1165/2000 [1:09:08<49:28,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  58%|█████▊    | 1166/2000 [1:09:11<49:25,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  58%|█████▊    | 1167/2000 [1:09:15<49:35,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  58%|█████▊    | 1168/2000 [1:09:19<50:13,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  58%|█████▊    | 1169/2000 [1:09:22<49:58,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  58%|█████▊    | 1170/2000 [1:09:26<49:44,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  59%|█████▊    | 1171/2000 [1:09:29<49:34,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  59%|█████▊    | 1172/2000 [1:09:33<49:26,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  59%|█████▊    | 1173/2000 [1:09:36<49:17,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  59%|█████▊    | 1174/2000 [1:09:40<49:05,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  59%|█████▉    | 1175/2000 [1:09:43<49:01,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  59%|█████▉    | 1176/2000 [1:09:47<48:59,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  59%|█████▉    | 1177/2000 [1:09:51<48:48,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  59%|█████▉    | 1178/2000 [1:09:54<48:45,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  59%|█████▉    | 1179/2000 [1:09:58<48:44,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  59%|█████▉    | 1180/2000 [1:10:01<49:01,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  59%|█████▉    | 1181/2000 [1:10:05<48:58,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  59%|█████▉    | 1182/2000 [1:10:09<48:56,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  59%|█████▉    | 1183/2000 [1:10:12<48:55,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  59%|█████▉    | 1184/2000 [1:10:16<49:10,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  59%|█████▉    | 1185/2000 [1:10:19<48:54,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  59%|█████▉    | 1186/2000 [1:10:23<48:49,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  59%|█████▉    | 1187/2000 [1:10:27<48:45,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  59%|█████▉    | 1188/2000 [1:10:30<48:33,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  59%|█████▉    | 1189/2000 [1:10:34<48:26,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  60%|█████▉    | 1190/2000 [1:10:37<48:20,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  60%|█████▉    | 1191/2000 [1:10:41<48:35,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  60%|█████▉    | 1192/2000 [1:10:45<48:44,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  60%|█████▉    | 1193/2000 [1:10:48<48:42,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  60%|█████▉    | 1194/2000 [1:10:52<48:35,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  60%|█████▉    | 1195/2000 [1:10:55<48:35,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  60%|█████▉    | 1196/2000 [1:10:59<48:34,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  60%|█████▉    | 1197/2000 [1:11:03<48:23,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  60%|█████▉    | 1198/2000 [1:11:06<48:09,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  60%|█████▉    | 1199/2000 [1:11:10<47:44,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  60%|██████    | 1200/2000 [1:11:13<47:37,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  60%|██████    | 1201/2000 [1:11:17<47:02,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  60%|██████    | 1202/2000 [1:11:20<46:46,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  60%|██████    | 1203/2000 [1:11:24<47:04,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  60%|██████    | 1204/2000 [1:11:27<46:54,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  60%|██████    | 1205/2000 [1:11:31<46:43,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  60%|██████    | 1206/2000 [1:11:34<46:38,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  60%|██████    | 1207/2000 [1:11:38<46:24,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  60%|██████    | 1208/2000 [1:11:41<46:11,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  60%|██████    | 1209/2000 [1:11:45<46:17,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  60%|██████    | 1210/2000 [1:11:48<46:09,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  61%|██████    | 1211/2000 [1:11:52<46:05,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  61%|██████    | 1212/2000 [1:11:55<46:09,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  61%|██████    | 1213/2000 [1:11:59<46:13,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  61%|██████    | 1214/2000 [1:12:03<46:12,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  61%|██████    | 1215/2000 [1:12:06<46:10,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  61%|██████    | 1216/2000 [1:12:10<46:17,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  61%|██████    | 1217/2000 [1:12:13<46:17,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  61%|██████    | 1218/2000 [1:12:17<46:19,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  61%|██████    | 1219/2000 [1:12:20<46:25,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  61%|██████    | 1220/2000 [1:12:24<46:39,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  61%|██████    | 1221/2000 [1:12:28<46:28,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  61%|██████    | 1222/2000 [1:12:31<46:45,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  61%|██████    | 1223/2000 [1:12:35<46:49,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  61%|██████    | 1224/2000 [1:12:38<46:12,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  61%|██████▏   | 1225/2000 [1:12:42<45:44,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  61%|██████▏   | 1226/2000 [1:12:45<45:59,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  61%|██████▏   | 1227/2000 [1:12:49<45:53,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  61%|██████▏   | 1228/2000 [1:12:53<45:52,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  61%|██████▏   | 1229/2000 [1:12:56<45:44,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  62%|██████▏   | 1230/2000 [1:13:00<45:52,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  62%|██████▏   | 1231/2000 [1:13:03<45:37,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  62%|██████▏   | 1232/2000 [1:13:07<45:30,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  62%|██████▏   | 1233/2000 [1:13:10<45:46,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  62%|██████▏   | 1234/2000 [1:13:14<45:38,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  62%|██████▏   | 1235/2000 [1:13:18<45:32,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  62%|██████▏   | 1236/2000 [1:13:21<45:38,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  62%|██████▏   | 1237/2000 [1:13:25<45:31,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  62%|██████▏   | 1238/2000 [1:13:28<45:24,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  62%|██████▏   | 1239/2000 [1:13:32<45:22,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  62%|██████▏   | 1240/2000 [1:13:35<45:17,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  62%|██████▏   | 1241/2000 [1:13:39<45:13,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  62%|██████▏   | 1242/2000 [1:13:43<45:11,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  62%|██████▏   | 1243/2000 [1:13:46<45:09,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  62%|██████▏   | 1244/2000 [1:13:50<45:04,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  62%|██████▏   | 1245/2000 [1:13:53<45:01,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  62%|██████▏   | 1246/2000 [1:13:57<44:58,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  62%|██████▏   | 1247/2000 [1:14:00<44:52,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  62%|██████▏   | 1248/2000 [1:14:04<44:44,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  62%|██████▏   | 1249/2000 [1:14:08<44:42,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  62%|██████▎   | 1250/2000 [1:14:11<44:33,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  63%|██████▎   | 1251/2000 [1:14:15<44:20,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  63%|██████▎   | 1252/2000 [1:14:18<44:11,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  63%|██████▎   | 1253/2000 [1:14:22<44:07,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  63%|██████▎   | 1254/2000 [1:14:25<43:56,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  63%|██████▎   | 1255/2000 [1:14:29<43:46,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  63%|██████▎   | 1256/2000 [1:14:32<43:42,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  63%|██████▎   | 1257/2000 [1:14:36<43:43,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  63%|██████▎   | 1258/2000 [1:14:39<43:37,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  63%|██████▎   | 1259/2000 [1:14:43<43:34,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  63%|██████▎   | 1260/2000 [1:14:46<43:32,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  63%|██████▎   | 1261/2000 [1:14:50<43:29,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  63%|██████▎   | 1262/2000 [1:14:54<43:30,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  63%|██████▎   | 1263/2000 [1:14:57<43:32,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  63%|██████▎   | 1264/2000 [1:15:01<43:39,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  63%|██████▎   | 1265/2000 [1:15:04<43:44,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  63%|██████▎   | 1266/2000 [1:15:08<43:55,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  63%|██████▎   | 1267/2000 [1:15:12<44:20,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  63%|██████▎   | 1268/2000 [1:15:15<44:05,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  63%|██████▎   | 1269/2000 [1:15:19<43:56,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  64%|██████▎   | 1270/2000 [1:15:22<43:39,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  64%|██████▎   | 1271/2000 [1:15:26<43:21,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  64%|██████▎   | 1272/2000 [1:15:29<43:05,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  64%|██████▎   | 1273/2000 [1:15:33<42:51,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  64%|██████▎   | 1274/2000 [1:15:36<42:40,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  64%|██████▍   | 1275/2000 [1:15:40<42:39,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  64%|██████▍   | 1276/2000 [1:15:43<42:35,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  64%|██████▍   | 1277/2000 [1:15:47<42:36,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  64%|██████▍   | 1278/2000 [1:15:51<42:30,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  64%|██████▍   | 1279/2000 [1:15:54<42:23,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  64%|██████▍   | 1280/2000 [1:15:58<42:24,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  64%|██████▍   | 1281/2000 [1:16:01<42:20,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  64%|██████▍   | 1282/2000 [1:16:05<42:22,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  64%|██████▍   | 1283/2000 [1:16:08<42:14,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  64%|██████▍   | 1284/2000 [1:16:12<42:14,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  64%|██████▍   | 1285/2000 [1:16:15<42:05,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  64%|██████▍   | 1286/2000 [1:16:19<42:05,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  64%|██████▍   | 1287/2000 [1:16:22<42:00,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  64%|██████▍   | 1288/2000 [1:16:26<41:53,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  64%|██████▍   | 1289/2000 [1:16:29<41:52,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  64%|██████▍   | 1290/2000 [1:16:33<41:46,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  65%|██████▍   | 1291/2000 [1:16:36<41:49,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  65%|██████▍   | 1292/2000 [1:16:40<41:51,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  65%|██████▍   | 1293/2000 [1:16:44<41:50,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  65%|██████▍   | 1294/2000 [1:16:47<41:47,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  65%|██████▍   | 1295/2000 [1:16:51<41:43,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  65%|██████▍   | 1296/2000 [1:16:54<41:41,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  65%|██████▍   | 1297/2000 [1:16:58<41:40,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  65%|██████▍   | 1298/2000 [1:17:01<41:37,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  65%|██████▍   | 1299/2000 [1:17:05<41:46,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  65%|██████▌   | 1300/2000 [1:17:09<41:57,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  65%|██████▌   | 1301/2000 [1:17:12<41:47,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  65%|██████▌   | 1302/2000 [1:17:16<41:48,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  65%|██████▌   | 1303/2000 [1:17:19<41:26,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  65%|██████▌   | 1304/2000 [1:17:23<41:07,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  65%|██████▌   | 1305/2000 [1:17:26<40:47,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  65%|██████▌   | 1306/2000 [1:17:30<40:31,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  65%|██████▌   | 1307/2000 [1:17:33<40:21,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  65%|██████▌   | 1308/2000 [1:17:37<40:13,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  65%|██████▌   | 1309/2000 [1:17:40<40:01,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  66%|██████▌   | 1310/2000 [1:17:44<40:00,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  66%|██████▌   | 1311/2000 [1:17:47<40:03,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  66%|██████▌   | 1312/2000 [1:17:51<39:59,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  66%|██████▌   | 1313/2000 [1:17:54<39:53,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  66%|██████▌   | 1314/2000 [1:17:58<39:56,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  66%|██████▌   | 1315/2000 [1:18:01<39:59,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  66%|██████▌   | 1316/2000 [1:18:05<39:59,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  66%|██████▌   | 1317/2000 [1:18:08<39:57,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  66%|██████▌   | 1318/2000 [1:18:12<39:54,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  66%|██████▌   | 1319/2000 [1:18:15<40:03,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  66%|██████▌   | 1320/2000 [1:18:19<40:09,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  66%|██████▌   | 1321/2000 [1:18:22<40:12,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  66%|██████▌   | 1322/2000 [1:18:26<40:09,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  66%|██████▌   | 1323/2000 [1:18:30<40:13,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  66%|██████▌   | 1324/2000 [1:18:33<40:10,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  66%|██████▋   | 1325/2000 [1:18:37<40:08,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  66%|██████▋   | 1326/2000 [1:18:40<40:08,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  66%|██████▋   | 1327/2000 [1:18:44<40:06,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  66%|██████▋   | 1328/2000 [1:18:47<39:56,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  66%|██████▋   | 1329/2000 [1:18:51<39:41,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  66%|██████▋   | 1330/2000 [1:18:54<39:32,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  67%|██████▋   | 1331/2000 [1:18:58<39:26,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  67%|██████▋   | 1332/2000 [1:19:01<39:14,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  67%|██████▋   | 1333/2000 [1:19:05<39:12,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  67%|██████▋   | 1334/2000 [1:19:09<39:02,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  67%|██████▋   | 1335/2000 [1:19:12<39:03,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  67%|██████▋   | 1336/2000 [1:19:16<39:14,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  67%|██████▋   | 1337/2000 [1:19:19<39:11,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  67%|██████▋   | 1338/2000 [1:19:23<39:09,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  67%|██████▋   | 1339/2000 [1:19:26<39:05,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  67%|██████▋   | 1340/2000 [1:19:30<39:02,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  67%|██████▋   | 1341/2000 [1:19:33<38:59,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  67%|██████▋   | 1342/2000 [1:19:37<38:52,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  67%|██████▋   | 1343/2000 [1:19:40<38:51,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  67%|██████▋   | 1344/2000 [1:19:44<38:44,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  67%|██████▋   | 1345/2000 [1:19:48<38:38,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  67%|██████▋   | 1346/2000 [1:19:51<38:35,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  67%|██████▋   | 1347/2000 [1:19:55<38:38,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  67%|██████▋   | 1348/2000 [1:19:58<38:38,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  67%|██████▋   | 1349/2000 [1:20:02<38:42,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  68%|██████▊   | 1350/2000 [1:20:05<38:45,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  68%|██████▊   | 1351/2000 [1:20:09<38:44,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  68%|██████▊   | 1352/2000 [1:20:13<38:55,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  68%|██████▊   | 1353/2000 [1:20:16<39:18,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  68%|██████▊   | 1354/2000 [1:20:20<38:58,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  68%|██████▊   | 1355/2000 [1:20:24<38:44,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  68%|██████▊   | 1356/2000 [1:20:27<38:34,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  68%|██████▊   | 1357/2000 [1:20:31<38:28,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  68%|██████▊   | 1358/2000 [1:20:34<38:22,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  68%|██████▊   | 1359/2000 [1:20:38<38:15,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  68%|██████▊   | 1360/2000 [1:20:41<38:11,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  68%|██████▊   | 1361/2000 [1:20:45<38:09,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  68%|██████▊   | 1362/2000 [1:20:49<38:02,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  68%|██████▊   | 1363/2000 [1:20:52<38:15,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  68%|██████▊   | 1364/2000 [1:20:56<38:08,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  68%|██████▊   | 1365/2000 [1:20:59<38:04,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  68%|██████▊   | 1366/2000 [1:21:03<37:56,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  68%|██████▊   | 1367/2000 [1:21:07<38:03,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  68%|██████▊   | 1368/2000 [1:21:10<37:45,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  68%|██████▊   | 1369/2000 [1:21:14<37:19,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  68%|██████▊   | 1370/2000 [1:21:17<36:59,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  69%|██████▊   | 1371/2000 [1:21:21<36:56,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  69%|██████▊   | 1372/2000 [1:21:24<36:36,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  69%|██████▊   | 1373/2000 [1:21:28<36:33,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  69%|██████▊   | 1374/2000 [1:21:31<36:18,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  69%|██████▉   | 1375/2000 [1:21:35<36:17,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  69%|██████▉   | 1376/2000 [1:21:38<36:17,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  69%|██████▉   | 1377/2000 [1:21:41<36:06,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  69%|██████▉   | 1378/2000 [1:21:45<35:56,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  69%|██████▉   | 1379/2000 [1:21:48<35:53,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  69%|██████▉   | 1380/2000 [1:21:52<35:43,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  69%|██████▉   | 1381/2000 [1:21:55<35:35,  3.45s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  69%|██████▉   | 1382/2000 [1:21:59<35:44,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  69%|██████▉   | 1383/2000 [1:22:02<35:42,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  69%|██████▉   | 1384/2000 [1:22:06<35:42,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  69%|██████▉   | 1385/2000 [1:22:09<35:58,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  69%|██████▉   | 1386/2000 [1:22:13<36:01,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  69%|██████▉   | 1387/2000 [1:22:16<35:53,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  69%|██████▉   | 1388/2000 [1:22:20<35:51,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  69%|██████▉   | 1389/2000 [1:22:23<35:47,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  70%|██████▉   | 1390/2000 [1:22:27<35:55,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  70%|██████▉   | 1391/2000 [1:22:31<35:54,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  70%|██████▉   | 1392/2000 [1:22:34<35:52,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  70%|██████▉   | 1393/2000 [1:22:38<35:51,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  70%|██████▉   | 1394/2000 [1:22:41<35:54,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  70%|██████▉   | 1395/2000 [1:22:45<35:52,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  70%|██████▉   | 1396/2000 [1:22:48<35:52,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  70%|██████▉   | 1397/2000 [1:22:52<35:49,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  70%|██████▉   | 1398/2000 [1:22:55<35:50,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  70%|██████▉   | 1399/2000 [1:22:59<35:47,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  70%|███████   | 1400/2000 [1:23:03<35:42,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  70%|███████   | 1401/2000 [1:23:06<35:44,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  70%|███████   | 1402/2000 [1:23:10<35:44,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  70%|███████   | 1403/2000 [1:23:13<35:39,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  70%|███████   | 1404/2000 [1:23:17<35:38,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  70%|███████   | 1405/2000 [1:23:21<35:34,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  70%|███████   | 1406/2000 [1:23:24<35:25,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  70%|███████   | 1407/2000 [1:23:28<35:23,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  70%|███████   | 1408/2000 [1:23:31<35:18,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  70%|███████   | 1409/2000 [1:23:35<35:12,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  70%|███████   | 1410/2000 [1:23:38<35:08,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  71%|███████   | 1411/2000 [1:23:42<35:04,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  71%|███████   | 1412/2000 [1:23:46<34:59,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  71%|███████   | 1413/2000 [1:23:49<34:57,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  71%|███████   | 1414/2000 [1:23:53<34:52,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  71%|███████   | 1415/2000 [1:23:56<34:50,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  71%|███████   | 1416/2000 [1:24:00<34:43,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  71%|███████   | 1417/2000 [1:24:03<34:42,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  71%|███████   | 1418/2000 [1:24:07<34:40,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  71%|███████   | 1419/2000 [1:24:11<34:38,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  71%|███████   | 1420/2000 [1:24:14<34:31,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  71%|███████   | 1421/2000 [1:24:18<34:26,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  71%|███████   | 1422/2000 [1:24:21<34:23,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  71%|███████   | 1423/2000 [1:24:25<34:19,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  71%|███████   | 1424/2000 [1:24:28<34:10,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  71%|███████▏  | 1425/2000 [1:24:32<34:16,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  71%|███████▏  | 1426/2000 [1:24:36<34:07,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  71%|███████▏  | 1427/2000 [1:24:39<33:57,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  71%|███████▏  | 1428/2000 [1:24:43<33:48,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  71%|███████▏  | 1429/2000 [1:24:46<34:00,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  72%|███████▏  | 1430/2000 [1:24:50<34:00,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  72%|███████▏  | 1431/2000 [1:24:53<34:03,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  72%|███████▏  | 1432/2000 [1:24:57<34:03,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  72%|███████▏  | 1433/2000 [1:25:01<34:05,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  72%|███████▏  | 1434/2000 [1:25:04<34:06,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  72%|███████▏  | 1435/2000 [1:25:08<34:13,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  72%|███████▏  | 1436/2000 [1:25:12<34:08,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  72%|███████▏  | 1437/2000 [1:25:15<33:57,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  72%|███████▏  | 1438/2000 [1:25:19<33:42,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  72%|███████▏  | 1439/2000 [1:25:22<33:35,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  72%|███████▏  | 1440/2000 [1:25:26<33:28,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  72%|███████▏  | 1441/2000 [1:25:29<33:11,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  72%|███████▏  | 1442/2000 [1:25:33<33:00,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  72%|███████▏  | 1443/2000 [1:25:36<32:53,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  72%|███████▏  | 1444/2000 [1:25:40<32:49,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  72%|███████▏  | 1445/2000 [1:25:44<32:44,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  72%|███████▏  | 1446/2000 [1:25:47<32:47,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  72%|███████▏  | 1447/2000 [1:25:51<32:43,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  72%|███████▏  | 1448/2000 [1:25:54<32:33,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  72%|███████▏  | 1449/2000 [1:25:58<32:29,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  72%|███████▎  | 1450/2000 [1:26:01<32:24,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  73%|███████▎  | 1451/2000 [1:26:05<32:22,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  73%|███████▎  | 1452/2000 [1:26:08<32:21,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  73%|███████▎  | 1453/2000 [1:26:12<32:15,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  73%|███████▎  | 1454/2000 [1:26:15<32:09,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  73%|███████▎  | 1455/2000 [1:26:19<32:07,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  73%|███████▎  | 1456/2000 [1:26:22<32:01,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  73%|███████▎  | 1457/2000 [1:26:26<31:59,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  73%|███████▎  | 1458/2000 [1:26:30<31:57,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  73%|███████▎  | 1459/2000 [1:26:33<32:01,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  73%|███████▎  | 1460/2000 [1:26:37<31:58,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  73%|███████▎  | 1461/2000 [1:26:40<32:27,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  73%|███████▎  | 1462/2000 [1:26:44<32:23,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  73%|███████▎  | 1463/2000 [1:26:48<32:26,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  73%|███████▎  | 1464/2000 [1:26:51<32:15,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  73%|███████▎  | 1465/2000 [1:26:55<32:13,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  73%|███████▎  | 1466/2000 [1:26:59<32:05,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  73%|███████▎  | 1467/2000 [1:27:02<32:03,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  73%|███████▎  | 1468/2000 [1:27:06<32:04,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  73%|███████▎  | 1469/2000 [1:27:09<31:39,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  74%|███████▎  | 1470/2000 [1:27:13<31:22,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  74%|███████▎  | 1471/2000 [1:27:16<31:15,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  74%|███████▎  | 1472/2000 [1:27:20<31:07,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  74%|███████▎  | 1473/2000 [1:27:23<31:02,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  74%|███████▎  | 1474/2000 [1:27:27<30:55,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  74%|███████▍  | 1475/2000 [1:27:30<30:51,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  74%|███████▍  | 1476/2000 [1:27:34<30:45,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  74%|███████▍  | 1477/2000 [1:27:37<30:42,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  74%|███████▍  | 1478/2000 [1:27:41<30:37,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  74%|███████▍  | 1479/2000 [1:27:44<30:41,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  74%|███████▍  | 1480/2000 [1:27:48<30:37,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  74%|███████▍  | 1481/2000 [1:27:52<30:29,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  74%|███████▍  | 1482/2000 [1:27:55<30:25,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  74%|███████▍  | 1483/2000 [1:27:59<30:23,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  74%|███████▍  | 1484/2000 [1:28:02<30:17,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  74%|███████▍  | 1485/2000 [1:28:06<30:09,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  74%|███████▍  | 1486/2000 [1:28:09<30:14,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  74%|███████▍  | 1487/2000 [1:28:13<30:08,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  74%|███████▍  | 1488/2000 [1:28:16<30:00,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  74%|███████▍  | 1489/2000 [1:28:20<29:54,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  74%|███████▍  | 1490/2000 [1:28:23<29:54,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  75%|███████▍  | 1491/2000 [1:28:27<29:50,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  75%|███████▍  | 1492/2000 [1:28:30<29:44,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  75%|███████▍  | 1493/2000 [1:28:34<29:51,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  75%|███████▍  | 1494/2000 [1:28:37<29:48,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  75%|███████▍  | 1495/2000 [1:28:41<29:38,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  75%|███████▍  | 1496/2000 [1:28:44<29:30,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  75%|███████▍  | 1497/2000 [1:28:48<29:26,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  75%|███████▍  | 1498/2000 [1:28:51<29:19,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  75%|███████▍  | 1499/2000 [1:28:55<29:15,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  75%|███████▌  | 1500/2000 [1:28:58<29:20,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  75%|███████▌  | 1501/2000 [1:29:02<29:16,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  75%|███████▌  | 1502/2000 [1:29:05<29:17,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  75%|███████▌  | 1503/2000 [1:29:09<29:14,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  75%|███████▌  | 1504/2000 [1:29:13<29:13,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  75%|███████▌  | 1505/2000 [1:29:16<29:10,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  75%|███████▌  | 1506/2000 [1:29:20<29:10,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  75%|███████▌  | 1507/2000 [1:29:23<29:10,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  75%|███████▌  | 1508/2000 [1:29:27<29:08,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  75%|███████▌  | 1509/2000 [1:29:30<29:02,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  76%|███████▌  | 1510/2000 [1:29:34<28:56,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  76%|███████▌  | 1511/2000 [1:29:37<28:49,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  76%|███████▌  | 1512/2000 [1:29:41<29:01,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  76%|███████▌  | 1513/2000 [1:29:45<28:55,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  76%|███████▌  | 1514/2000 [1:29:48<28:48,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  76%|███████▌  | 1515/2000 [1:29:52<28:49,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  76%|███████▌  | 1516/2000 [1:29:55<28:44,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  76%|███████▌  | 1517/2000 [1:29:59<28:45,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  76%|███████▌  | 1518/2000 [1:30:02<28:45,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  76%|███████▌  | 1519/2000 [1:30:06<28:47,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  76%|███████▌  | 1520/2000 [1:30:10<28:46,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  76%|███████▌  | 1521/2000 [1:30:13<28:44,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  76%|███████▌  | 1522/2000 [1:30:17<28:39,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  76%|███████▌  | 1523/2000 [1:30:20<28:30,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  76%|███████▌  | 1524/2000 [1:30:24<28:26,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  76%|███████▋  | 1525/2000 [1:30:28<28:23,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  76%|███████▋  | 1526/2000 [1:30:31<28:17,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  76%|███████▋  | 1527/2000 [1:30:35<28:13,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  76%|███████▋  | 1528/2000 [1:30:38<28:07,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  76%|███████▋  | 1529/2000 [1:30:42<28:05,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  76%|███████▋  | 1530/2000 [1:30:45<28:01,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  77%|███████▋  | 1531/2000 [1:30:49<28:01,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  77%|███████▋  | 1532/2000 [1:30:53<27:59,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  77%|███████▋  | 1533/2000 [1:30:56<27:49,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  77%|███████▋  | 1534/2000 [1:31:00<27:44,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  77%|███████▋  | 1535/2000 [1:31:03<27:32,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  77%|███████▋  | 1536/2000 [1:31:07<27:29,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  77%|███████▋  | 1537/2000 [1:31:10<27:25,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  77%|███████▋  | 1538/2000 [1:31:14<27:26,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  77%|███████▋  | 1539/2000 [1:31:18<27:23,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  77%|███████▋  | 1540/2000 [1:31:21<27:28,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  77%|███████▋  | 1541/2000 [1:31:25<27:24,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  77%|███████▋  | 1542/2000 [1:31:28<27:17,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  77%|███████▋  | 1543/2000 [1:31:32<27:11,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  77%|███████▋  | 1544/2000 [1:31:35<27:08,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  77%|███████▋  | 1545/2000 [1:31:39<27:01,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  77%|███████▋  | 1546/2000 [1:31:43<27:00,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  77%|███████▋  | 1547/2000 [1:31:46<27:00,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  77%|███████▋  | 1548/2000 [1:31:50<26:54,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  77%|███████▋  | 1549/2000 [1:31:53<26:49,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  78%|███████▊  | 1550/2000 [1:31:57<26:45,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  78%|███████▊  | 1551/2000 [1:32:00<26:40,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  78%|███████▊  | 1552/2000 [1:32:04<26:35,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  78%|███████▊  | 1553/2000 [1:32:08<26:36,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  78%|███████▊  | 1554/2000 [1:32:11<26:34,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  78%|███████▊  | 1555/2000 [1:32:15<26:30,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  78%|███████▊  | 1556/2000 [1:32:18<26:28,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  78%|███████▊  | 1557/2000 [1:32:22<26:27,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  78%|███████▊  | 1558/2000 [1:32:25<26:25,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  78%|███████▊  | 1559/2000 [1:32:29<26:23,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  78%|███████▊  | 1560/2000 [1:32:33<26:20,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  78%|███████▊  | 1561/2000 [1:32:36<26:16,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  78%|███████▊  | 1562/2000 [1:32:40<26:14,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  78%|███████▊  | 1563/2000 [1:32:43<26:12,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  78%|███████▊  | 1564/2000 [1:32:47<26:12,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  78%|███████▊  | 1565/2000 [1:32:51<26:06,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  78%|███████▊  | 1566/2000 [1:32:54<26:00,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  78%|███████▊  | 1567/2000 [1:32:58<26:01,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  78%|███████▊  | 1568/2000 [1:33:01<25:55,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  78%|███████▊  | 1569/2000 [1:33:05<25:47,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  78%|███████▊  | 1570/2000 [1:33:09<25:40,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  79%|███████▊  | 1571/2000 [1:33:12<25:34,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  79%|███████▊  | 1572/2000 [1:33:16<25:27,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  79%|███████▊  | 1573/2000 [1:33:19<25:27,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  79%|███████▊  | 1574/2000 [1:33:23<25:28,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  79%|███████▉  | 1575/2000 [1:33:27<25:29,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  79%|███████▉  | 1576/2000 [1:33:30<25:29,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  79%|███████▉  | 1577/2000 [1:33:34<25:26,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  79%|███████▉  | 1578/2000 [1:33:37<25:26,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  79%|███████▉  | 1579/2000 [1:33:41<25:24,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  79%|███████▉  | 1580/2000 [1:33:45<25:24,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  79%|███████▉  | 1581/2000 [1:33:48<25:10,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  79%|███████▉  | 1582/2000 [1:33:52<24:58,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  79%|███████▉  | 1583/2000 [1:33:55<24:45,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  79%|███████▉  | 1584/2000 [1:33:59<24:39,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  79%|███████▉  | 1585/2000 [1:34:02<24:31,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  79%|███████▉  | 1586/2000 [1:34:06<24:26,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  79%|███████▉  | 1587/2000 [1:34:09<24:23,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  79%|███████▉  | 1588/2000 [1:34:13<24:18,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  79%|███████▉  | 1589/2000 [1:34:17<24:18,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  80%|███████▉  | 1590/2000 [1:34:20<24:16,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  80%|███████▉  | 1591/2000 [1:34:24<24:12,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  80%|███████▉  | 1592/2000 [1:34:27<24:08,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  80%|███████▉  | 1593/2000 [1:34:31<24:04,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  80%|███████▉  | 1594/2000 [1:34:34<24:03,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  80%|███████▉  | 1595/2000 [1:34:38<23:58,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  80%|███████▉  | 1596/2000 [1:34:41<23:53,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  80%|███████▉  | 1597/2000 [1:34:45<23:47,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  80%|███████▉  | 1598/2000 [1:34:48<23:42,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  80%|███████▉  | 1599/2000 [1:34:52<23:53,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  80%|████████  | 1600/2000 [1:34:56<23:52,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  80%|████████  | 1601/2000 [1:34:59<23:52,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  80%|████████  | 1602/2000 [1:35:03<23:51,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  80%|████████  | 1603/2000 [1:35:07<23:48,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  80%|████████  | 1604/2000 [1:35:10<23:45,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  80%|████████  | 1605/2000 [1:35:14<23:52,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  80%|████████  | 1606/2000 [1:35:18<24:02,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  80%|████████  | 1607/2000 [1:35:21<24:00,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  80%|████████  | 1608/2000 [1:35:25<23:55,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  80%|████████  | 1609/2000 [1:35:29<23:51,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  80%|████████  | 1610/2000 [1:35:32<23:47,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  81%|████████  | 1611/2000 [1:35:36<23:46,  3.67s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  81%|████████  | 1612/2000 [1:35:40<23:37,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  81%|████████  | 1613/2000 [1:35:43<23:31,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  81%|████████  | 1614/2000 [1:35:47<23:23,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  81%|████████  | 1615/2000 [1:35:50<23:18,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  81%|████████  | 1616/2000 [1:35:54<23:11,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  81%|████████  | 1617/2000 [1:35:58<23:06,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  81%|████████  | 1618/2000 [1:36:01<23:02,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  81%|████████  | 1619/2000 [1:36:05<22:56,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  81%|████████  | 1620/2000 [1:36:08<22:53,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  81%|████████  | 1621/2000 [1:36:12<22:47,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  81%|████████  | 1622/2000 [1:36:16<22:38,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  81%|████████  | 1623/2000 [1:36:19<22:33,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  81%|████████  | 1624/2000 [1:36:23<22:28,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  81%|████████▏ | 1625/2000 [1:36:26<22:24,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  81%|████████▏ | 1626/2000 [1:36:30<22:21,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  81%|████████▏ | 1627/2000 [1:36:34<22:23,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  81%|████████▏ | 1628/2000 [1:36:37<22:23,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  81%|████████▏ | 1629/2000 [1:36:41<22:11,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  82%|████████▏ | 1630/2000 [1:36:44<22:14,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  82%|████████▏ | 1631/2000 [1:36:48<22:16,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  82%|████████▏ | 1632/2000 [1:36:52<22:05,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  82%|████████▏ | 1633/2000 [1:36:55<21:59,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  82%|████████▏ | 1634/2000 [1:36:59<21:54,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  82%|████████▏ | 1635/2000 [1:37:02<21:46,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  82%|████████▏ | 1636/2000 [1:37:06<21:43,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  82%|████████▏ | 1637/2000 [1:37:09<21:39,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  82%|████████▏ | 1638/2000 [1:37:13<21:34,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  82%|████████▏ | 1639/2000 [1:37:17<21:28,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  82%|████████▏ | 1640/2000 [1:37:20<21:29,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  82%|████████▏ | 1641/2000 [1:37:24<21:23,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  82%|████████▏ | 1642/2000 [1:37:27<21:17,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  82%|████████▏ | 1643/2000 [1:37:31<21:13,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  82%|████████▏ | 1644/2000 [1:37:34<21:07,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  82%|████████▏ | 1645/2000 [1:37:38<21:04,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  82%|████████▏ | 1646/2000 [1:37:42<20:58,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  82%|████████▏ | 1647/2000 [1:37:45<20:58,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  82%|████████▏ | 1648/2000 [1:37:49<20:53,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  82%|████████▏ | 1649/2000 [1:37:52<20:52,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  82%|████████▎ | 1650/2000 [1:37:56<20:50,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  83%|████████▎ | 1651/2000 [1:37:59<20:45,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  83%|████████▎ | 1652/2000 [1:38:03<20:43,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  83%|████████▎ | 1653/2000 [1:38:07<20:41,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  83%|████████▎ | 1654/2000 [1:38:10<20:43,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  83%|████████▎ | 1655/2000 [1:38:14<20:41,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  83%|████████▎ | 1656/2000 [1:38:17<20:35,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  83%|████████▎ | 1657/2000 [1:38:21<20:30,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  83%|████████▎ | 1658/2000 [1:38:25<20:28,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  83%|████████▎ | 1659/2000 [1:38:28<20:26,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  83%|████████▎ | 1660/2000 [1:38:32<20:23,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  83%|████████▎ | 1661/2000 [1:38:35<20:25,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  83%|████████▎ | 1662/2000 [1:38:39<20:18,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  83%|████████▎ | 1663/2000 [1:38:43<20:10,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  83%|████████▎ | 1664/2000 [1:38:46<20:07,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  83%|████████▎ | 1665/2000 [1:38:50<20:00,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  83%|████████▎ | 1666/2000 [1:38:53<19:54,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  83%|████████▎ | 1667/2000 [1:38:57<19:51,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  83%|████████▎ | 1668/2000 [1:39:00<19:45,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  83%|████████▎ | 1669/2000 [1:39:04<19:40,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  84%|████████▎ | 1670/2000 [1:39:08<19:38,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  84%|████████▎ | 1671/2000 [1:39:11<19:26,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  84%|████████▎ | 1672/2000 [1:39:15<19:19,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  84%|████████▎ | 1673/2000 [1:39:18<19:12,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  84%|████████▎ | 1674/2000 [1:39:22<19:10,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  84%|████████▍ | 1675/2000 [1:39:25<19:05,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  84%|████████▍ | 1676/2000 [1:39:29<19:15,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  84%|████████▍ | 1677/2000 [1:39:32<19:14,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  84%|████████▍ | 1678/2000 [1:39:36<19:14,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  84%|████████▍ | 1679/2000 [1:39:40<19:11,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  84%|████████▍ | 1680/2000 [1:39:43<19:09,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  84%|████████▍ | 1681/2000 [1:39:47<19:16,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  84%|████████▍ | 1682/2000 [1:39:50<19:06,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  84%|████████▍ | 1683/2000 [1:39:54<19:00,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  84%|████████▍ | 1684/2000 [1:39:58<18:56,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  84%|████████▍ | 1685/2000 [1:40:01<18:54,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  84%|████████▍ | 1686/2000 [1:40:05<18:52,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  84%|████████▍ | 1687/2000 [1:40:08<18:50,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  84%|████████▍ | 1688/2000 [1:40:12<18:47,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  84%|████████▍ | 1689/2000 [1:40:16<18:44,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  84%|████████▍ | 1690/2000 [1:40:19<18:39,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  85%|████████▍ | 1691/2000 [1:40:23<18:29,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  85%|████████▍ | 1692/2000 [1:40:26<18:26,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  85%|████████▍ | 1693/2000 [1:40:30<18:27,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  85%|████████▍ | 1694/2000 [1:40:34<18:25,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  85%|████████▍ | 1695/2000 [1:40:37<18:16,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  85%|████████▍ | 1696/2000 [1:40:41<18:09,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  85%|████████▍ | 1697/2000 [1:40:44<18:02,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  85%|████████▍ | 1698/2000 [1:40:48<17:58,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  85%|████████▍ | 1699/2000 [1:40:51<17:52,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  85%|████████▌ | 1700/2000 [1:40:55<17:48,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  85%|████████▌ | 1701/2000 [1:40:59<17:45,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  85%|████████▌ | 1702/2000 [1:41:02<17:39,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  85%|████████▌ | 1703/2000 [1:41:06<17:35,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  85%|████████▌ | 1704/2000 [1:41:09<17:32,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  85%|████████▌ | 1705/2000 [1:41:13<17:27,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  85%|████████▌ | 1706/2000 [1:41:16<17:24,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  85%|████████▌ | 1707/2000 [1:41:20<17:23,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  85%|████████▌ | 1708/2000 [1:41:24<17:23,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  85%|████████▌ | 1709/2000 [1:41:27<17:19,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  86%|████████▌ | 1710/2000 [1:41:31<17:15,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  86%|████████▌ | 1711/2000 [1:41:34<17:14,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  86%|████████▌ | 1712/2000 [1:41:38<17:08,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  86%|████████▌ | 1713/2000 [1:41:41<17:04,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  86%|████████▌ | 1714/2000 [1:41:45<17:02,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  86%|████████▌ | 1715/2000 [1:41:49<16:59,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  86%|████████▌ | 1716/2000 [1:41:52<16:55,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  86%|████████▌ | 1717/2000 [1:41:56<16:51,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  86%|████████▌ | 1718/2000 [1:41:59<16:49,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  86%|████████▌ | 1719/2000 [1:42:03<16:47,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  86%|████████▌ | 1720/2000 [1:42:07<16:46,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  86%|████████▌ | 1721/2000 [1:42:10<16:43,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  86%|████████▌ | 1722/2000 [1:42:14<16:38,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  86%|████████▌ | 1723/2000 [1:42:17<16:35,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  86%|████████▌ | 1724/2000 [1:42:21<16:32,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  86%|████████▋ | 1725/2000 [1:42:25<16:36,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  86%|████████▋ | 1726/2000 [1:42:28<16:35,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  86%|████████▋ | 1727/2000 [1:42:32<16:27,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  86%|████████▋ | 1728/2000 [1:42:35<16:18,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  86%|████████▋ | 1729/2000 [1:42:39<16:13,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  86%|████████▋ | 1730/2000 [1:42:43<16:06,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  87%|████████▋ | 1731/2000 [1:42:46<16:01,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  87%|████████▋ | 1732/2000 [1:42:50<15:59,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  87%|████████▋ | 1733/2000 [1:42:53<15:54,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  87%|████████▋ | 1734/2000 [1:42:57<15:50,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  87%|████████▋ | 1735/2000 [1:43:00<15:45,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  87%|████████▋ | 1736/2000 [1:43:04<15:41,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  87%|████████▋ | 1737/2000 [1:43:07<15:38,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  87%|████████▋ | 1738/2000 [1:43:11<15:33,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  87%|████████▋ | 1739/2000 [1:43:15<15:30,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  87%|████████▋ | 1740/2000 [1:43:18<15:25,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  87%|████████▋ | 1741/2000 [1:43:22<15:23,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  87%|████████▋ | 1742/2000 [1:43:25<15:18,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  87%|████████▋ | 1743/2000 [1:43:29<15:17,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  87%|████████▋ | 1744/2000 [1:43:32<15:15,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  87%|████████▋ | 1745/2000 [1:43:36<15:11,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  87%|████████▋ | 1746/2000 [1:43:40<15:10,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  87%|████████▋ | 1747/2000 [1:43:43<15:07,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  87%|████████▋ | 1748/2000 [1:43:47<15:03,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  87%|████████▋ | 1749/2000 [1:43:50<14:59,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  88%|████████▊ | 1750/2000 [1:43:54<14:57,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  88%|████████▊ | 1751/2000 [1:43:58<14:54,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  88%|████████▊ | 1752/2000 [1:44:01<14:49,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  88%|████████▊ | 1753/2000 [1:44:05<14:47,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  88%|████████▊ | 1754/2000 [1:44:08<14:42,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  88%|████████▊ | 1755/2000 [1:44:12<14:31,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  88%|████████▊ | 1756/2000 [1:44:15<14:26,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  88%|████████▊ | 1757/2000 [1:44:19<14:27,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  88%|████████▊ | 1758/2000 [1:44:23<14:20,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  88%|████████▊ | 1759/2000 [1:44:26<14:11,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  88%|████████▊ | 1760/2000 [1:44:29<14:05,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  88%|████████▊ | 1761/2000 [1:44:33<13:59,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  88%|████████▊ | 1762/2000 [1:44:36<13:54,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  88%|████████▊ | 1763/2000 [1:44:40<13:50,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  88%|████████▊ | 1764/2000 [1:44:43<13:46,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  88%|████████▊ | 1765/2000 [1:44:47<13:43,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  88%|████████▊ | 1766/2000 [1:44:50<13:38,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  88%|████████▊ | 1767/2000 [1:44:54<13:35,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  88%|████████▊ | 1768/2000 [1:44:58<13:34,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  88%|████████▊ | 1769/2000 [1:45:01<13:33,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  88%|████████▊ | 1770/2000 [1:45:05<13:32,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  89%|████████▊ | 1771/2000 [1:45:08<13:29,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  89%|████████▊ | 1772/2000 [1:45:12<13:28,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  89%|████████▊ | 1773/2000 [1:45:15<13:24,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  89%|████████▊ | 1774/2000 [1:45:19<13:21,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  89%|████████▉ | 1775/2000 [1:45:22<13:14,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  89%|████████▉ | 1776/2000 [1:45:26<13:10,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  89%|████████▉ | 1777/2000 [1:45:29<13:06,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  89%|████████▉ | 1778/2000 [1:45:33<13:00,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  89%|████████▉ | 1779/2000 [1:45:36<12:59,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  89%|████████▉ | 1780/2000 [1:45:40<12:56,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  89%|████████▉ | 1781/2000 [1:45:43<12:53,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  89%|████████▉ | 1782/2000 [1:45:47<12:50,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  89%|████████▉ | 1783/2000 [1:45:51<12:47,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  89%|████████▉ | 1784/2000 [1:45:54<12:42,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  89%|████████▉ | 1785/2000 [1:45:58<12:39,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  89%|████████▉ | 1786/2000 [1:46:01<12:37,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  89%|████████▉ | 1787/2000 [1:46:05<12:31,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  89%|████████▉ | 1788/2000 [1:46:08<12:31,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  89%|████████▉ | 1789/2000 [1:46:12<12:33,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  90%|████████▉ | 1790/2000 [1:46:15<12:25,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  90%|████████▉ | 1791/2000 [1:46:19<12:19,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  90%|████████▉ | 1792/2000 [1:46:22<12:13,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  90%|████████▉ | 1793/2000 [1:46:26<12:09,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  90%|████████▉ | 1794/2000 [1:46:29<12:05,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  90%|████████▉ | 1795/2000 [1:46:33<12:01,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  90%|████████▉ | 1796/2000 [1:46:36<11:56,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  90%|████████▉ | 1797/2000 [1:46:40<11:53,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  90%|████████▉ | 1798/2000 [1:46:43<11:49,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  90%|████████▉ | 1799/2000 [1:46:47<11:43,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  90%|█████████ | 1800/2000 [1:46:50<11:40,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  90%|█████████ | 1801/2000 [1:46:54<11:35,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  90%|█████████ | 1802/2000 [1:46:57<11:36,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  90%|█████████ | 1803/2000 [1:47:01<11:32,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  90%|█████████ | 1804/2000 [1:47:05<11:28,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  90%|█████████ | 1805/2000 [1:47:08<11:24,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  90%|█████████ | 1806/2000 [1:47:12<11:21,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  90%|█████████ | 1807/2000 [1:47:15<11:16,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  90%|█████████ | 1808/2000 [1:47:19<11:13,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  90%|█████████ | 1809/2000 [1:47:22<11:09,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  90%|█████████ | 1810/2000 [1:47:26<11:04,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  91%|█████████ | 1811/2000 [1:47:29<11:01,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  91%|█████████ | 1812/2000 [1:47:33<10:58,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  91%|█████████ | 1813/2000 [1:47:36<10:56,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  91%|█████████ | 1814/2000 [1:47:40<10:59,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  91%|█████████ | 1815/2000 [1:47:43<10:59,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  91%|█████████ | 1816/2000 [1:47:47<10:56,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  91%|█████████ | 1817/2000 [1:47:50<10:50,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  91%|█████████ | 1818/2000 [1:47:54<10:46,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  91%|█████████ | 1819/2000 [1:47:58<10:44,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  91%|█████████ | 1820/2000 [1:48:01<10:40,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  91%|█████████ | 1821/2000 [1:48:05<10:38,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  91%|█████████ | 1822/2000 [1:48:08<10:40,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  91%|█████████ | 1823/2000 [1:48:12<10:31,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  91%|█████████ | 1824/2000 [1:48:15<10:23,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  91%|█████████▏| 1825/2000 [1:48:19<10:18,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  91%|█████████▏| 1826/2000 [1:48:22<10:12,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  91%|█████████▏| 1827/2000 [1:48:26<10:07,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  91%|█████████▏| 1828/2000 [1:48:29<10:03,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  91%|█████████▏| 1829/2000 [1:48:33<09:58,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  92%|█████████▏| 1830/2000 [1:48:36<09:53,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  92%|█████████▏| 1831/2000 [1:48:40<09:50,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  92%|█████████▏| 1832/2000 [1:48:43<09:45,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  92%|█████████▏| 1833/2000 [1:48:47<09:42,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  92%|█████████▏| 1834/2000 [1:48:50<09:37,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  92%|█████████▏| 1835/2000 [1:48:54<09:34,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  92%|█████████▏| 1836/2000 [1:48:57<09:30,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  92%|█████████▏| 1837/2000 [1:49:01<09:28,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  92%|█████████▏| 1838/2000 [1:49:04<09:28,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  92%|█████████▏| 1839/2000 [1:49:08<09:28,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  92%|█████████▏| 1840/2000 [1:49:11<09:25,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  92%|█████████▏| 1841/2000 [1:49:15<09:23,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  92%|█████████▏| 1842/2000 [1:49:18<09:19,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  92%|█████████▏| 1843/2000 [1:49:22<09:16,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  92%|█████████▏| 1844/2000 [1:49:26<09:14,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  92%|█████████▏| 1845/2000 [1:49:29<09:11,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  92%|█████████▏| 1846/2000 [1:49:33<09:08,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  92%|█████████▏| 1847/2000 [1:49:36<09:05,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  92%|█████████▏| 1848/2000 [1:49:40<09:02,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  92%|█████████▏| 1849/2000 [1:49:43<08:59,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  92%|█████████▎| 1850/2000 [1:49:47<08:56,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  93%|█████████▎| 1851/2000 [1:49:51<08:54,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  93%|█████████▎| 1852/2000 [1:49:54<08:53,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  93%|█████████▎| 1853/2000 [1:49:58<08:51,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  93%|█████████▎| 1854/2000 [1:50:02<08:50,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  93%|█████████▎| 1855/2000 [1:50:05<08:45,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  93%|█████████▎| 1856/2000 [1:50:09<08:40,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  93%|█████████▎| 1857/2000 [1:50:12<08:36,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  93%|█████████▎| 1858/2000 [1:50:16<08:32,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  93%|█████████▎| 1859/2000 [1:50:20<08:26,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  93%|█████████▎| 1860/2000 [1:50:23<08:21,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  93%|█████████▎| 1861/2000 [1:50:27<08:15,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  93%|█████████▎| 1862/2000 [1:50:30<08:11,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  93%|█████████▎| 1863/2000 [1:50:34<08:09,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  93%|█████████▎| 1864/2000 [1:50:37<08:05,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  93%|█████████▎| 1865/2000 [1:50:41<08:01,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  93%|█████████▎| 1866/2000 [1:50:44<07:57,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  93%|█████████▎| 1867/2000 [1:50:48<07:54,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  93%|█████████▎| 1868/2000 [1:50:52<07:49,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  93%|█████████▎| 1869/2000 [1:50:55<07:46,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  94%|█████████▎| 1870/2000 [1:50:59<07:42,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  94%|█████████▎| 1871/2000 [1:51:02<07:38,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  94%|█████████▎| 1872/2000 [1:51:06<07:35,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  94%|█████████▎| 1873/2000 [1:51:09<07:31,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  94%|█████████▎| 1874/2000 [1:51:13<07:28,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  94%|█████████▍| 1875/2000 [1:51:16<07:25,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  94%|█████████▍| 1876/2000 [1:51:20<07:22,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  94%|█████████▍| 1877/2000 [1:51:24<07:19,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  94%|█████████▍| 1878/2000 [1:51:27<07:15,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  94%|█████████▍| 1879/2000 [1:51:31<07:12,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  94%|█████████▍| 1880/2000 [1:51:34<07:10,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  94%|█████████▍| 1881/2000 [1:51:38<07:06,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  94%|█████████▍| 1882/2000 [1:51:42<07:03,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  94%|█████████▍| 1883/2000 [1:51:45<07:01,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  94%|█████████▍| 1884/2000 [1:51:49<06:59,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  94%|█████████▍| 1885/2000 [1:51:53<06:57,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  94%|█████████▍| 1886/2000 [1:51:56<06:51,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  94%|█████████▍| 1887/2000 [1:52:00<06:46,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  94%|█████████▍| 1888/2000 [1:52:03<06:42,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  94%|█████████▍| 1889/2000 [1:52:07<06:38,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  94%|█████████▍| 1890/2000 [1:52:10<06:35,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  95%|█████████▍| 1891/2000 [1:52:14<06:30,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  95%|█████████▍| 1892/2000 [1:52:18<06:25,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  95%|█████████▍| 1893/2000 [1:52:21<06:23,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  95%|█████████▍| 1894/2000 [1:52:25<06:16,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  95%|█████████▍| 1895/2000 [1:52:28<06:11,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  95%|█████████▍| 1896/2000 [1:52:32<06:05,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  95%|█████████▍| 1897/2000 [1:52:35<06:03,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  95%|█████████▍| 1898/2000 [1:52:39<05:58,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  95%|█████████▍| 1899/2000 [1:52:42<05:55,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  95%|█████████▌| 1900/2000 [1:52:46<05:51,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  95%|█████████▌| 1901/2000 [1:52:49<05:48,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  95%|█████████▌| 1902/2000 [1:52:53<05:44,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  95%|█████████▌| 1903/2000 [1:52:56<05:42,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  95%|█████████▌| 1904/2000 [1:53:00<05:38,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  95%|█████████▌| 1905/2000 [1:53:03<05:34,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  95%|█████████▌| 1906/2000 [1:53:07<05:31,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  95%|█████████▌| 1907/2000 [1:53:10<05:28,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  95%|█████████▌| 1908/2000 [1:53:14<05:24,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  95%|█████████▌| 1909/2000 [1:53:17<05:21,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  96%|█████████▌| 1910/2000 [1:53:21<05:18,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  96%|█████████▌| 1911/2000 [1:53:25<05:15,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  96%|█████████▌| 1912/2000 [1:53:28<05:11,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  96%|█████████▌| 1913/2000 [1:53:32<05:08,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  96%|█████████▌| 1914/2000 [1:53:35<05:05,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  96%|█████████▌| 1915/2000 [1:53:39<05:03,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  96%|█████████▌| 1916/2000 [1:53:42<05:01,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  96%|█████████▌| 1917/2000 [1:53:46<04:56,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  96%|█████████▌| 1918/2000 [1:53:49<04:51,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  96%|█████████▌| 1919/2000 [1:53:53<04:46,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  96%|█████████▌| 1920/2000 [1:53:56<04:41,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  96%|█████████▌| 1921/2000 [1:54:00<04:37,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  96%|█████████▌| 1922/2000 [1:54:03<04:33,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  96%|█████████▌| 1923/2000 [1:54:07<04:30,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  96%|█████████▌| 1924/2000 [1:54:11<04:27,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  96%|█████████▋| 1925/2000 [1:54:14<04:23,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  96%|█████████▋| 1926/2000 [1:54:17<04:19,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  96%|█████████▋| 1927/2000 [1:54:21<04:15,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  96%|█████████▋| 1928/2000 [1:54:24<04:12,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  96%|█████████▋| 1929/2000 [1:54:28<04:08,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  96%|█████████▋| 1930/2000 [1:54:31<04:04,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  97%|█████████▋| 1931/2000 [1:54:35<04:01,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  97%|█████████▋| 1932/2000 [1:54:39<03:58,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  97%|█████████▋| 1933/2000 [1:54:42<03:54,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  97%|█████████▋| 1934/2000 [1:54:46<03:51,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  97%|█████████▋| 1935/2000 [1:54:49<03:47,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  97%|█████████▋| 1936/2000 [1:54:53<03:46,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  97%|█████████▋| 1937/2000 [1:54:56<03:43,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  97%|█████████▋| 1938/2000 [1:55:00<03:41,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  97%|█████████▋| 1939/2000 [1:55:03<03:38,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  97%|█████████▋| 1940/2000 [1:55:07<03:35,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  97%|█████████▋| 1941/2000 [1:55:11<03:32,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  97%|█████████▋| 1942/2000 [1:55:14<03:29,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  97%|█████████▋| 1943/2000 [1:55:18<03:25,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  97%|█████████▋| 1944/2000 [1:55:21<03:21,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  97%|█████████▋| 1945/2000 [1:55:25<03:18,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  97%|█████████▋| 1946/2000 [1:55:29<03:13,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  97%|█████████▋| 1947/2000 [1:55:32<03:11,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  97%|█████████▋| 1948/2000 [1:55:36<03:07,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  97%|█████████▋| 1949/2000 [1:55:39<03:03,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  98%|█████████▊| 1950/2000 [1:55:43<02:59,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  98%|█████████▊| 1951/2000 [1:55:47<02:55,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  98%|█████████▊| 1952/2000 [1:55:50<02:51,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  98%|█████████▊| 1953/2000 [1:55:54<02:47,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  98%|█████████▊| 1954/2000 [1:55:57<02:43,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  98%|█████████▊| 1955/2000 [1:56:01<02:39,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  98%|█████████▊| 1956/2000 [1:56:04<02:36,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  98%|█████████▊| 1957/2000 [1:56:08<02:32,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  98%|█████████▊| 1958/2000 [1:56:11<02:29,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  98%|█████████▊| 1959/2000 [1:56:15<02:25,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  98%|█████████▊| 1960/2000 [1:56:19<02:22,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  98%|█████████▊| 1961/2000 [1:56:22<02:18,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  98%|█████████▊| 1962/2000 [1:56:26<02:15,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  98%|█████████▊| 1963/2000 [1:56:29<02:11,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  98%|█████████▊| 1964/2000 [1:56:33<02:08,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  98%|█████████▊| 1965/2000 [1:56:36<02:04,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  98%|█████████▊| 1966/2000 [1:56:40<02:01,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  98%|█████████▊| 1967/2000 [1:56:44<01:57,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  98%|█████████▊| 1968/2000 [1:56:47<01:53,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  98%|█████████▊| 1969/2000 [1:56:51<01:50,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  98%|█████████▊| 1970/2000 [1:56:54<01:46,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  99%|█████████▊| 1971/2000 [1:56:58<01:43,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  99%|█████████▊| 1972/2000 [1:57:01<01:40,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  99%|█████████▊| 1973/2000 [1:57:05<01:36,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  99%|█████████▊| 1974/2000 [1:57:09<01:33,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  99%|█████████▉| 1975/2000 [1:57:12<01:29,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  99%|█████████▉| 1976/2000 [1:57:16<01:26,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  99%|█████████▉| 1977/2000 [1:57:19<01:22,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  99%|█████████▉| 1978/2000 [1:57:23<01:18,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  99%|█████████▉| 1979/2000 [1:57:26<01:15,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  99%|█████████▉| 1980/2000 [1:57:30<01:13,  3.67s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  99%|█████████▉| 1981/2000 [1:57:34<01:08,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  99%|█████████▉| 1982/2000 [1:57:37<01:04,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  99%|█████████▉| 1983/2000 [1:57:41<01:00,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  99%|█████████▉| 1984/2000 [1:57:44<00:56,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  99%|█████████▉| 1985/2000 [1:57:48<00:52,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  99%|█████████▉| 1986/2000 [1:57:51<00:49,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  99%|█████████▉| 1987/2000 [1:57:55<00:45,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  99%|█████████▉| 1988/2000 [1:57:58<00:42,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:  99%|█████████▉| 1989/2000 [1:58:02<00:38,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate: 100%|█████████▉| 1990/2000 [1:58:05<00:34,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate: 100%|█████████▉| 1991/2000 [1:58:09<00:31,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate: 100%|█████████▉| 1992/2000 [1:58:12<00:27,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate: 100%|█████████▉| 1993/2000 [1:58:16<00:24,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate: 100%|█████████▉| 1994/2000 [1:58:19<00:20,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate: 100%|█████████▉| 1995/2000 [1:58:23<00:17,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate: 100%|█████████▉| 1996/2000 [1:58:26<00:13,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate: 100%|█████████▉| 1997/2000 [1:58:30<00:10,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate: 100%|█████████▉| 1998/2000 [1:58:33<00:06,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate: 100%|█████████▉| 1999/2000 [1:58:37<00:03,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate: 100%|██████████| 2000/2000 [1:58:40<00:00,  3.56s/it]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PPL: 100%|██████████| 2000/2000 [00:16<00:00, 120.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EVALUATION RESULTS ===\n",
      "BERTScore F1: 0.7721 ↑ (higher = more semantically similar)\n",
      "BERTScore Precision: 0.7183 ↑\n",
      "BERTScore Recall: 0.8356 ↑\n",
      "BLEU Score: 0.0031 ↑ (higher = more phrase overlap)\n",
      "ROUGE-1 F1: 0.0470 ↑\n",
      "ROUGE-2 F1: 0.0098 ↑\n",
      "ROUGE-L F1: 0.0346 ↑ (longest common subsequence)\n",
      "Perplexity (output-only): 23.3598 ↓ (lower = more confident model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>bertscore_precision</th>\n",
       "      <th>bertscore_recall</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t5_small_only_title</th>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.247088</td>\n",
       "      <td>0.098434</td>\n",
       "      <td>0.223263</td>\n",
       "      <td>0.315411</td>\n",
       "      <td>0.450722</td>\n",
       "      <td>0.188689</td>\n",
       "      <td>15.403170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5_small_baseline</th>\n",
       "      <td>0.009406</td>\n",
       "      <td>0.160242</td>\n",
       "      <td>0.042990</td>\n",
       "      <td>0.130303</td>\n",
       "      <td>-0.058683</td>\n",
       "      <td>-0.181792</td>\n",
       "      <td>0.070558</td>\n",
       "      <td>75.238684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2_only_title</th>\n",
       "      <td>0.003058</td>\n",
       "      <td>0.046986</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>0.034573</td>\n",
       "      <td>0.772086</td>\n",
       "      <td>0.718331</td>\n",
       "      <td>0.835581</td>\n",
       "      <td>23.359847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         bleu    rouge1    rouge2    rougeL  bertscore_f1  \\\n",
       "t5_small_only_title  0.004914  0.247088  0.098434  0.223263      0.315411   \n",
       "t5_small_baseline    0.009406  0.160242  0.042990  0.130303     -0.058683   \n",
       "gpt2_only_title      0.003058  0.046986  0.009768  0.034573      0.772086   \n",
       "\n",
       "                     bertscore_precision  bertscore_recall  perplexity  \n",
       "t5_small_only_title             0.450722          0.188689   15.403170  \n",
       "t5_small_baseline              -0.181792          0.070558   75.238684  \n",
       "gpt2_only_title                 0.718331          0.835581   23.359847  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\n",
    "# Run comprehensive evaluation on GPT2\n",
    "results_gpt2 = evaluate_gpt2_on_raw(train_data, gpt2_model, gpt2_tokenizer, num_examples=3000, max_new_tokens=512)  # none means take all\n",
    "eval_df = pd.concat([eval_df, pd.DataFrame([results_gpt2], index=[\"gpt2_only_title\"])])\n",
    "# save df\n",
    "eval_df.to_csv(\"results_including_gpt2.csv\")\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a59bca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 37964/37964 [00:17<00:00, 2157.78 examples/s]\n",
      "/tmp/ipykernel_1333253/727615717.py:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  flan_trainer = Trainer(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5697' max='5697' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5697/5697 19:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.220500</td>\n",
       "      <td>2.948676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.031000</td>\n",
       "      <td>2.878431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.934900</td>\n",
       "      <td>2.855180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on 3000 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [10:35<00:00,  4.72it/s] \n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 50/50 [00:00<00:00, 56.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EVALUATION RESULTS ===\n",
      "BERTScore F1: 0.3093 ↑ (higher = more semantically similar)\n",
      "BERTScore Precision: 0.4405 ↑\n",
      "BERTScore Recall: 0.1873 ↑\n",
      "BLEU Score: 0.0103 ↑ (higher = more phrase overlap)\n",
      "ROUGE-1 F1: 0.2473 ↑\n",
      "ROUGE-2 F1: 0.0985 ↑\n",
      "ROUGE-L F1: 0.2237 ↑ (longest common subsequence)\n",
      "Perplexity: 10.3077 ↓ (lower = more confident model)\n",
      "\n",
      "=== SAMPLE PREDICTIONS ===\n",
      "\n",
      "Example 1:\n",
      "Input: What question was asked by the user if this t>How does colorblindness work? | Scienceline (scienceline.org) ; How Color Blindness Works (www.colour-blindness.com) ; What Is Color Blindness? (www.webmd.com)/t>\n",
      "Expected output: How does color-blindness work?\n",
      "Generated output: How does color blindness work?\n",
      "\n",
      "Example 2:\n",
      "Input: What question was asked by the user if this t>A New Methodology for Calculating Launch Vehicle Ascent Loads (sbir.nasa.gov) ; 1985008580.pdf (ntrs.nasa.gov) ; Space Shuttle Orbiter Structures & Thermal Protection System (TPS) | Alan Tatourian (tatourian.blog)/t>\n",
      "Expected output: What is a “squatcheloid” and how is it used to compute the ascent load on a space vehicle (like the shuttle) during launch. I figure it’s some sort of generalization equation but I can’t figure out exactly what forces are being described and why the heck there would call it a “squatcheloid” of all things. Dammit Jim! I’m a Doctor, not an engineer.\n",
      "Generated output: How does a rocket launcher calculate the mass of the space shuttle?\n",
      "\n",
      "Example 3:\n",
      "Input: What question was asked by the user if this t>The Safest Seat On A Plane, According To Studies Of Crash Data | HuffPost Life (www.huffpost.com) ; This Is the Safest Part of the Plane (www.smartertravel.com)/t>\n",
      "Expected output: In the event of a plane crash, which section of the plane would be the safest to be seated in?\n",
      "Generated output: Why is it that the plane is so sassy and sassy?\n",
      "\n",
      "Example 4:\n",
      "Input: What question was asked by the user if this t>How can life emerge from nonliving matter? UNC scientists find new evidence. - CSMonitor.com (www.csmonitor.com) ; Abiogenesis - Wikipedia (en.wikipedia.org) ; Abiogenesis - Wikipedia (en.wikipedia.org) ; How did life begin? | New Scientist (www.newscientist.com) ; How Did Life on Earth Begin? » Science ABC (www.scienceabc.com)/t>\n",
      "Expected output: How can organic life begin from non-organic material?\n",
      "Generated output: How did life start?\n",
      "\n",
      "Example 5:\n",
      "Input: What question was asked by the user if this t>Psychedelic drugs could treat depression, and other mental illnesses | University of California (www.universityofcalifornia.edu) ; Psychedelic drugs could treat depression, and other mental illnesses | University of California (www.universityofcalifornia.edu) ; Psychedelic drugs may reduce depression and anxiety by increasing psychological flexibility (www.psypost.org)/t>\n",
      "Expected output: The use of Psychedelic drugs to aid depression/anxiety? Why does this actually work, and what are the risks/concerns with pursuing such a treatment?\n",
      "Generated output: Why do people with depression get psychedelic drugs?\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'eval_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Run comprehensive evaluation\u001b[39;00m\n\u001b[1;32m     55\u001b[0m flan_results \u001b[38;5;241m=\u001b[39m comprehensive_evaluation(flan_eval_ds, flan_model, num_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3000\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m eval_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43meval_df\u001b[49m, pd\u001b[38;5;241m.\u001b[39mDataFrame([flan_results], index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflan_t5_small_only_title\u001b[39m\u001b[38;5;124m\"\u001b[39m])])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_df' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    T5TokenizerFast,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "\n",
    "# Load Flan-T5 small model and tokenizer\n",
    "flan_tokenizer = T5TokenizerFast.from_pretrained(\"google/flan-t5-small\")\n",
    "flan_model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\")\n",
    "flan_model.config.use_cache = False\n",
    "if hasattr(flan_model, \"generation_config\"):\n",
    "    flan_model.generation_config.use_cache = False\n",
    "\n",
    "# Tokenize data for Flan-T5\n",
    "def tokenize_flan(row):\n",
    "    return flan_tokenizer(row[\"input\"], text_target=row[\"output\"], truncation=True)\n",
    "\n",
    "flan_tokenized_data = train_data.map(tokenize_flan, remove_columns=[\"input\", \"output\"])\n",
    "\n",
    "# Split the data\n",
    "flan_train_ds, flan_eval_ds = flan_tokenized_data.train_test_split(test_size=0.2, seed=42).values()\n",
    "\n",
    "# Training arguments for Flan-T5\n",
    "flan_training_args = TrainingArguments(\n",
    "    output_dir=\"flan-t5-question-generator\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\",\n",
    "    save_total_limit=1,\n",
    "    eval_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "# Data collator\n",
    "flan_data_collator = DataCollatorForSeq2Seq(flan_tokenizer, model=flan_model)\n",
    "\n",
    "# Create trainer\n",
    "flan_trainer = Trainer(\n",
    "    model=flan_model,\n",
    "    args=flan_training_args,\n",
    "    train_dataset=flan_train_ds,\n",
    "    eval_dataset=flan_eval_ds,\n",
    "    tokenizer=flan_tokenizer,\n",
    "    data_collator=flan_data_collator,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "flan_trainer.train()\n",
    "\n",
    "# Run comprehensive evaluation\n",
    "flan_results = comprehensive_evaluation(flan_eval_ds, flan_model, flan_tokenizer, num_examples=3000)\n",
    "eval_df = pd.read_csv(\"results_including_gpt2.csv\", index_col=0)\n",
    "eval_df = pd.concat([eval_df, pd.DataFrame([flan_results], index=[\"flan_t5_small_only_title\"])])\n",
    "eval_df.to_csv(\"results_including_flan_t5_small_only_title.csv\")\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741b3176",
   "metadata": {},
   "source": [
    "### Now try to train with extract as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1390069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19578/19578 [00:12<00:00, 1529.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deduped 4 duplicates (kept 38161).\n",
      "\n",
      "Total rows: 19578\n",
      "Kept rows: 19471\n",
      "Filtered counts:\n",
      " - no_titles: 106\n",
      " - empty_question: 1\n",
      "38161\n",
      "Loaded 38161 training samples.\n",
      "Sample data:\n",
      "Input: What question was asked by the user if this <t>Kent Brockman (en.wikipedia.org)</t> <c>Kent Brockman is a fictional character in the animated television series The Simpsons. He is voiced by Harry Shearer and first appeared in the episode \"Krusty Gets Busted\". He is a grumpy, self-centered local Springfield news anchor.</c> <t>Krusty the Clown (en.wikipedia.org)</t> <c>Krusty was created by cartoonist Matt Groening and partially inspired by Rusty Nails, a television clown from Groening's hometown of Portland, Oregon.</c> <t>Kent Brockman (en.wikipedia.org) ; Krusty the Clown (en.wikipedia.org)</t> <c>Kent Brockman is a fictional character in the animated television series The Simpsons. He is voiced by Harry Shearer and first appeared in the episode \"Krusty Gets Busted\". He is a grumpy, self-centered local Springfield news anchor. ; Krusty was created by cartoonist Matt Groening and partially inspired by Rusty Nails, a television clown from Groening's hometown of Portland, Oregon.</c>\n",
      "Output: Voiced by Harry Shearer, what Simpsons character was modeled after Ted Koppel?\n"
     ]
    }
   ],
   "source": [
    "train_data_extract = get_dataset(use_extract=True, min_question_len=5, verbose=True)\n",
    "print(len(train_data_extract))\n",
    "print(f\"Loaded {len(train_data_extract)} training samples.\")\n",
    "print(\"Sample data:\")\n",
    "print(f\"Input: {train_data_extract[0]['input']}\")\n",
    "print(f\"Output: {train_data_extract[0]['output']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8179b9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average input length:  1130.21 tokens\n",
      "Average output length: 47.34 tokens\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/long-t5-tglobal-base\")\n",
    "\n",
    "# Sample 1000 rows from Huggingface Dataset\n",
    "random.seed(42)\n",
    "sampled_rows = random.sample(list(train_data_extract), 2000)\n",
    "\n",
    "# Tokenize inputs and outputs\n",
    "input_lengths = [len(tokenizer(row[\"input\"]).input_ids) for row in sampled_rows]\n",
    "output_lengths = [len(tokenizer(row[\"output\"]).input_ids) for row in sampled_rows]\n",
    "\n",
    "# Print averages\n",
    "print(f\"Average input length:  {np.mean(input_lengths):.2f} tokens\")\n",
    "print(f\"Average output length: {np.mean(output_lengths):.2f} tokens\")\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(input_lengths, bins=50, alpha=0.7, label=\"Input Lengths\", color='blue')\n",
    "plt.hist(output_lengths, bins=50, alpha=0.7, label=\"Output Lengths\", color='orange')\n",
    "plt.axvline(np.mean(input_lengths), color='blue', linestyle='--', label=\"Avg Input\")\n",
    "plt.axvline(np.mean(output_lengths), color='orange', linestyle='--', label=\"Avg Output\")\n",
    "plt.xlabel(\"Number of Tokens\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Token Length Distribution (Input vs Output)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c09c82e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected index: 16155\n",
      "Input: What question was asked by the user if this <t>Curious Kids: How did some animals evolve wings to fly? (theconversation.com)</t> <c>Perhaps the first thing you notice when you see a bird is its amazing ability to fly. Modern birds fly using their “arms”, which have feathers and very strong flight muscles.</c> <t>Curious Kids: How did some animals evolve wings to fly? (theconversation.com)</t> <c>Many species of birds can run up very steep slopes or even vertical surfaces. Young birds do it by furiously flapping their wings in order to push them against the incline. Otherwise they fall or slide off. This may have been another use for the stubby wings of some small, feathered dinosaurs. These wings then gradually became more powerful and covered in feathers and were eventually used to fly.</c> <t>Curious Kids: How did some animals evolve wings to fly? (theconversation.com)</t> <c>But the first animals to fly by flapping are very much older than birds, pterosaurs or bats, and first took to the air about 400 million years ago: insects. Unlike birds and bats, insect wings didn’t evolve from existing “arms”. Precisely how insects got their wings is something that scientists are still working out today.</c> <t>How Did Dinosaurs Start to Fly? Scientists Have Decoded the Evolution of the Pterosaurs (www.news18.com)</t> <c>Paleontologists are still piecing together details of the lives of these winged reptiles -- neither dinosaurs nor birds -- which soared above T-rex, Triceratops and other dinosaurs of the late Cretaceous period. In one of two studies published in Nature on pterosaurs, researchers in Britain found the creatures were initially ungainly fliers. But the study, which used statistical methods, biophysical models and fossil records, said that pterosaurs spent 150 million years perfecting their flying skills. \"Pterosaurs really were incredible animals,\" co-author Joanna Baker of Reading University told AFP, adding that by the end they could likely have travelled \"incredible distances\". \"As pterosaurs became more efficient at flight, they could soar for longer and longer distances before they would need to land,\" she said.</c> <t>Curious Kids: How did some animals evolve wings to fly? (theconversation.com) ; Curious Kids: How did some animals evolve wings to fly? (theconversation.com) ; Curious Kids: How did some animals evolve wings to fly? (theconversation.com) ; How Did Dinosaurs Start to Fly? Scientists Have Decoded the Evolution of the Pterosaurs (www.news18.com)</t> <c>Perhaps the first thing you notice when you see a bird is its amazing ability to fly. Modern birds fly using their “arms”, which have feathers and very strong flight muscles. ; Many species of birds can run up very steep slopes or even vertical surfaces. Young birds do it by furiously flapping their wings in order to push them against the incline. Otherwise they fall or slide off. This may have been another use for the stubby wings of some small, feathered dinosaurs. These wings then gradually became more powerful and covered in feathers and were eventually used to fly. ; But the first animals to fly by flapping are very much older than birds, pterosaurs or bats, and first took to the air about 400 million years ago: insects. Unlike birds and bats, insect wings didn’t evolve from existing “arms”. Precisely how insects got their wings is something that scientists are still working out today. ; Paleontologists are still piecing together details of the lives of these winged reptiles -- neither dinosaurs nor birds -- which soared above T-rex, Triceratops and other dinosaurs of the late Cretaceous period. In one of two studies published in Nature on pterosaurs, researchers in Britain found the creatures were initially ungainly fliers. But the study, which used statistical methods, biophysical models and fossil records, said that pterosaurs spent 150 million years perfecting their flying skills. \"Pterosaurs really were incredible animals,\" co-author Joanna Baker of Reading University told AFP, adding that by the end they could likely have travelled \"incredible distances\". \"As pterosaurs became more efficient at flight, they could soar for longer and longer distances before they would need to land,\" she said.</c>\n",
      "Output: How did animals become able to fly? At what point in animal history did animals become able to fly? How did this process take place?\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random_int = random.randint(0, len(train_data_extract) - 1)\n",
    "print(f\"Randomly selected index: {random_int}\")\n",
    "print(f\"Input: {train_data_extract[random_int]['input']}\")\n",
    "print(f\"Output: {train_data_extract[random_int]['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da80038",
   "metadata": {},
   "source": [
    "### Now try to train with extract as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b538c44",
   "metadata": {},
   "source": [
    "### This is without extract\n",
    "* We use a model with a bigger context. To ensure apples-to-apples, we first run a \"baseline\" with that new model without extract, to understand if it's really the extract that improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468d7504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 37964/37964 [00:18<00:00, 1998.50 examples/s]\n",
      "/tmp/ipykernel_984269/2724876185.py:43: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  longt5_trainer = Trainer(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5697' max='5697' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5697/5697 1:41:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.970800</td>\n",
       "      <td>2.516858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.656700</td>\n",
       "      <td>2.414845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.477300</td>\n",
       "      <td>2.380436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on 3000 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [12:19<00:00,  4.06it/s] \n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 50/50 [00:02<00:00, 17.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EVALUATION RESULTS ===\n",
      "BERTScore F1: 0.3384 ↑ (higher = more semantically similar)\n",
      "BERTScore Precision: 0.4778 ↑\n",
      "BERTScore Recall: 0.2078 ↑\n",
      "BLEU Score: 0.0055 ↑ (higher = more phrase overlap)\n",
      "ROUGE-1 F1: 0.2617 ↑\n",
      "ROUGE-2 F1: 0.1109 ↑\n",
      "ROUGE-L F1: 0.2371 ↑ (longest common subsequence)\n",
      "Perplexity: 7.0716 ↓ (lower = more confident model)\n",
      "\n",
      "=== SAMPLE PREDICTIONS ===\n",
      "\n",
      "Example 1:\n",
      "Input: What question was asked by the user if this t>How does colorblindness work? | Scienceline (scienceline.org) ; How Color Blindness Works (www.colour-blindness.com) ; What Is Color Blindness? (www.webmd.com)/t>\n",
      "Expected output: How does color-blindness work?\n",
      "Generated output: How does colorblindness work?\n",
      "\n",
      "Example 2:\n",
      "Input: What question was asked by the user if this t>A New Methodology for Calculating Launch Vehicle Ascent Loads (sbir.nasa.gov) ; 1985008580.pdf (ntrs.nasa.gov) ; Space Shuttle Orbiter Structures & Thermal Protection System (TPS) | Alan Tatourian (tatourian.blog)/t>\n",
      "Expected output: What is a “squatcheloid” and how is it used to compute the ascent load on a space vehicle (like the shuttle) during launch. I figure it’s some sort of generalization equation but I can’t figure out exactly what forces are being described and why the heck there would call it a “squatcheloid” of all things. Dammit Jim! I’m a Doctor, not an engineer.\n",
      "Generated output: How do space shuttles know how much fuel to burn?\n",
      "\n",
      "Example 3:\n",
      "Input: What question was asked by the user if this t>The Safest Seat On A Plane, According To Studies Of Crash Data | HuffPost Life (www.huffpost.com) ; This Is the Safest Part of the Plane (www.smartertravel.com)/t>\n",
      "Expected output: In the event of a plane crash, which section of the plane would be the safest to be seated in?\n",
      "Generated output: Why is the seat of a plane so much safer than the rest of the plane?\n",
      "\n",
      "Example 4:\n",
      "Input: What question was asked by the user if this t>How can life emerge from nonliving matter? UNC scientists find new evidence. - CSMonitor.com (www.csmonitor.com) ; Abiogenesis - Wikipedia (en.wikipedia.org) ; Abiogenesis - Wikipedia (en.wikipedia.org) ; How did life begin? | New Scientist (www.newscientist.com) ; How Did Life on Earth Begin? » Science ABC (www.scienceabc.com)/t>\n",
      "Expected output: How can organic life begin from non-organic material?\n",
      "Generated output: How did life come to be?\n",
      "\n",
      "Example 5:\n",
      "Input: What question was asked by the user if this t>Psychedelic drugs could treat depression, and other mental illnesses | University of California (www.universityofcalifornia.edu) ; Psychedelic drugs could treat depression, and other mental illnesses | University of California (www.universityofcalifornia.edu) ; Psychedelic drugs may reduce depression and anxiety by increasing psychological flexibility (www.psypost.org)/t>\n",
      "Expected output: The use of Psychedelic drugs to aid depression/anxiety? Why does this actually work, and what are the risks/concerns with pursuing such a treatment?\n",
      "Generated output: Why do psychedelic drugs help with depression?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    LongT5ForConditionalGeneration,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "\n",
    "# Load FLAN-T5 small model and tokenizer - now using with extract data\n",
    "flan_no_extract_tokenizer = AutoTokenizer.from_pretrained(\"google/long-t5-tglobal-base\")\n",
    "flan_no_extract_model = LongT5ForConditionalGeneration.from_pretrained(\"google/long-t5-tglobal-base\")\n",
    "flan_no_extract_model.config.use_cache = False\n",
    "if hasattr(flan_no_extract_model, \"generation_config\"):\n",
    "    flan_no_extract_model.generation_config.use_cache = False\n",
    "\n",
    "# Use train_data (without extract) for tokenization and training\n",
    "def tokenize_longt5_no_extract(row):\n",
    "    return flan_no_extract_tokenizer(row[\"input\"], text_target=row[\"output\"], truncation=True, max_length=1500)\n",
    "\n",
    "longt5_tokenized_data = train_data.map(tokenize_longt5_no_extract, remove_columns=[\"input\", \"output\"])\n",
    "\n",
    "# Split the data\n",
    "longt5_train_ds, longt5_eval_ds = longt5_tokenized_data.train_test_split(test_size=0.2, seed=42).values()\n",
    "\n",
    "# Training arguments (reuse or adjust as needed)\n",
    "longt5_training_args = TrainingArguments(\n",
    "    output_dir=\"long-t5-question-generator-no-extract\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\",\n",
    "    save_total_limit=1,\n",
    "    eval_strategy=\"epoch\",\n",
    "    gradient_accumulation_steps=2\n",
    ")\n",
    "\n",
    "# Data collator\n",
    "longt5_data_collator = DataCollatorForSeq2Seq(flan_no_extract_tokenizer, model=flan_no_extract_model)\n",
    "\n",
    "# Trainer\n",
    "longt5_trainer = Trainer(\n",
    "    model=flan_no_extract_model,\n",
    "    args=longt5_training_args,\n",
    "    train_dataset=longt5_train_ds,\n",
    "    eval_dataset=longt5_eval_ds,\n",
    "    tokenizer=flan_no_extract_tokenizer,\n",
    "    data_collator=longt5_data_collator,\n",
    ")\n",
    "\n",
    "# Train\n",
    "longt5_trainer.train()\n",
    "\n",
    "# Evaluate\n",
    "longt5_results = comprehensive_evaluation(longt5_eval_ds, flan_no_extract_model, flan_no_extract_tokenizer, num_examples=3000)\n",
    "eval_df = pd.read_csv(\"results_including_flan_t5_small_only_title.csv\", index_col=0)\n",
    "eval_df = pd.concat([eval_df, pd.DataFrame([longt5_results], index=[\"long_t5_tglobal_base_no_extract\"])])\n",
    "eval_df.to_csv(\"results_including_long_t5_tglobal_base_no_extract.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f96bf6f",
   "metadata": {},
   "source": [
    "### This is with extract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2caa8882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 38161/38161 [01:56<00:00, 327.57 examples/s]\n",
      "/tmp/ipykernel_4189864/3552005596.py:45: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  flan_extract_trainer = Trainer(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11448' max='11448' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11448/11448 4:03:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.739600</td>\n",
       "      <td>2.370589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.369100</td>\n",
       "      <td>2.236821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.143200</td>\n",
       "      <td>2.190469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'comprehensive_evaluation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m flan_extract_trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Run comprehensive evaluation\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m flan_extract_results \u001b[38;5;241m=\u001b[39m \u001b[43mcomprehensive_evaluation\u001b[49m(flan_extract_eval_ds, flan_extract_model, flan_extract_tokenizer, num_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3000\u001b[39m)\n\u001b[1;32m     59\u001b[0m eval_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults_including_long_t5_tglobal_base_no_extract.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     60\u001b[0m eval_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([eval_df, pd\u001b[38;5;241m.\u001b[39mDataFrame([flan_extract_results], index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong_t5_tglobal_base_with_extract\u001b[39m\u001b[38;5;124m\"\u001b[39m])])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'comprehensive_evaluation' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import LongT5ForConditionalGeneration\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    LongT5ForConditionalGeneration,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "\n",
    "# Load FLAN-T5 small model and tokenizer - now using with extract data\n",
    "flan_extract_tokenizer = AutoTokenizer.from_pretrained(\"google/long-t5-tglobal-base\")\n",
    "flan_extract_model = LongT5ForConditionalGeneration.from_pretrained(\"google/long-t5-tglobal-base\")\n",
    "flan_extract_model.config.use_cache = False\n",
    "if hasattr(flan_extract_model, \"generation_config\"):\n",
    "    flan_extract_model.generation_config.use_cache = False\n",
    "\n",
    "# Tokenize data for Long-T5 with extract\n",
    "def tokenize_flan_extract(row):\n",
    "    return flan_extract_tokenizer(row[\"input\"], text_target=row[\"output\"], truncation=True, max_length=1500)\n",
    "\n",
    "flan_extract_tokenized_data = train_data_extract.map(tokenize_flan_extract, remove_columns=[\"input\", \"output\"])\n",
    "\n",
    "# Split the data\n",
    "flan_extract_train_ds, flan_extract_eval_ds = flan_extract_tokenized_data.train_test_split(test_size=0.2, seed=42).values()\n",
    "\n",
    "# Training arguments for Long-T5 with extract\n",
    "flan_extract_training_args = TrainingArguments(\n",
    "    output_dir=\"long-t5-question-generator-extract\",\n",
    "    per_device_train_batch_size=2,  # Smaller batch size for larger model\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\",\n",
    "    save_total_limit=1,\n",
    "    eval_strategy=\"epoch\",\n",
    "    gradient_accumulation_steps=2  # Compensate for smaller batch size\n",
    ")\n",
    "\n",
    "# Data collator\n",
    "flan_extract_data_collator = DataCollatorForSeq2Seq(flan_extract_tokenizer, model=flan_extract_model)\n",
    "\n",
    "# Create trainer\n",
    "flan_extract_trainer = Trainer(\n",
    "    model=flan_extract_model,\n",
    "    args=flan_extract_training_args,\n",
    "    train_dataset=flan_extract_train_ds,\n",
    "    eval_dataset=flan_extract_eval_ds,\n",
    "    tokenizer=flan_extract_tokenizer,\n",
    "    data_collator=flan_extract_data_collator,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "flan_extract_trainer.train()\n",
    "\n",
    "# Run comprehensive evaluation\n",
    "flan_extract_results = comprehensive_evaluation(flan_extract_eval_ds, flan_extract_model, flan_extract_tokenizer, num_examples=3000)\n",
    "eval_df = pd.read_csv(\"results_including_long_t5_tglobal_base_no_extract.csv\", index_col=0)\n",
    "eval_df = pd.concat([eval_df, pd.DataFrame([flan_extract_results], index=[\"long_t5_tglobal_base_with_extract\"])])\n",
    "eval_df.to_csv(\"results_including_long_t5_tglobal_base_with_extract.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb2a36b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on 3000 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [13:00<00:00,  3.85it/s] \n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EVALUATION RESULTS ===\n",
      "BERTScore F1: 0.3452 ↑ (higher = more semantically similar)\n",
      "BERTScore Precision: 0.4772 ↑\n",
      "BERTScore Recall: 0.2212 ↑\n",
      "BLEU Score: 0.0072 ↑ (higher = more phrase overlap)\n",
      "ROUGE-1 F1: 0.2742 ↑\n",
      "ROUGE-2 F1: 0.1215 ↑\n",
      "ROUGE-L F1: 0.2463 ↑ (longest common subsequence)\n",
      "Perplexity: 7.0619 ↓ (lower = more confident model)\n",
      "\n",
      "=== SAMPLE PREDICTIONS ===\n",
      "\n",
      "Example 1:\n",
      "Input: What question was asked by the user if this t>Galvanic Cells (Voltaic Cell) - Definition, Working Principle & Examples with Videos (byjus.com)/t> c>An electrochemical cell that converts the chemical energy of spontaneous redox reactions into electrical energy is known as a galvanic cell or a voltaic cell. Galvanic cell Voltaic cell is an electrochemical cell that makes use of chemical reactions to generate electrical energy. Let us understand how a voltaic or galvanic cell is created. In oxidation-reduction reactions, electrons are moved from one species to another species. Energy is released if the reaction occurs spontaneously. Therefore, the released energy is used to do useful work. To tackle this energy,/c> t>Galvanic cell - Wikipedia (en.wikipedia.org)/t> c>A galvanic cell or voltaic cell, named after the scientists Luigi Galvani and Alessandro Volta, respectively, is an electrochemical cell in which an electric current is generated from spontaneous reactions. A common apparatus generally consists of two different metals, each immersed in separate beakers containing their respective metal ions in solution that are connected by a salt bridge (or separated by a porous membrane)./c> t>Galvanic Cells | Chemistry (courses.lumenlearning.com)/t> c>Galvanic cells, also known as voltaic cells, are electrochemical cells in which spontaneous oxidation-reduction reactions produce electrical energy. In writing the equations, it is often convenient to separate the oxidation-reduction reactions into half-reactions to facilitate balancing the overall equation and to emphasize the actual chemical transformations./c> t>Galvanic Cells | Chemistry (courses.lumenlearning.com)/t> c>Galvanic or voltaic cells involve spontaneous electrochemical reactions in which the half-reactions are separated (Figure 2) so that current can flow through an external wire. The beaker on the left side of the figure is called a half-cell, and contains a 1 M solution of copper(II) nitrate [Cu(NO_3)_2] with a piece of copper metal partially submerged in the solution. The copper metal is an electrode. The copper is undergoing oxidation; therefore, the copper electrode is the anode. The anode is connected to a voltmeter with a wire/c> t>Galvanic Cell: Equation, Construction, Working, Examples, Diagram (www.embibe.com)/t> c>A galvanic cell is constructed by combining an oxidation electrode with a suitable reduction electrode to convert chemical energy into electrical energy by a redox reaction. Two electrolytic solutions, in which electrodes are immersed are connected to each through a porous diaphragm or a salt bridge./c> t>Galvanic Cells (Voltaic Cell) - Definition, Working Principle & Examples with Videos (byjus.com) ; Galvanic cell - Wikipedia (en.wikipedia.org) ; Galvanic Cells | Chemistry (courses.lumenlearning.com) ; Galvanic Cells | Chemistry (courses.lumenlearning.com) ; Galvanic Cell: Equation, Construction, Working, Examples, Diagram (www.embibe.com)/t> c>An electrochemical cell that converts the chemical energy of spontaneous redox reactions into electrical energy is known as a galvanic cell or a voltaic cell. Galvanic cell Voltaic cell is an electrochemical cell that makes use of chemical reactions to generate electrical energy. Let us understand how a voltaic or galvanic cell is created. In oxidation-reduction reactions, electrons are moved from one species to another species. Energy is released if the reaction occurs spontaneously. Therefore, the released energy is used to do useful work. To tackle this energy, ; A galvanic cell or voltaic cell, named after the scientists Luigi Galvani and Alessandro Volta, respectively, is an electrochemical cell in which an electric current is generated from spontaneous reactions. A common apparatus generally consists of two different metals, each immersed in separate beakers containing their respective metal ions in solution that are connected by a salt bridge (or separated by a porous membrane). ; Galvanic cells, also known as voltaic cells, are electrochemical cells in which spontaneous oxidation-reduction reactions produce electrical energy. In writing the equations, it is often convenient to separate the oxidation-reduction reactions into half-reactions to facilitate balancing the overall equation and to emphasize the actual chemical transformations. ; Galvanic or voltaic cells involve spontaneous electrochemical reactions in which the half-reactions are separated (Figure 2) so that current can flow through an external wire. The beaker on the left side of the figure is called a half-cell, and contains a 1 M solution of copper(II) nitrate [Cu(NO_3)_2] with a piece of copper metal partially submerged in the solution. The copper metal is an electrode. The copper is undergoing oxidation; therefore, the copper electrode is the anode. The anode is connected to a voltmeter with a wire ; A galvanic cell is constructed by combining an oxidation electrode with a suitable reduction electrode to convert chemical energy into electrical energy by a redox reaction. Two electrolytic solutions, in which electrodes are immersed are connected to each through a porous diaphragm or a salt bridge./c>\n",
      "Expected output: Explain: A galvanic cell\n",
      "Generated output: Explain: A galvanic cell\n",
      "\n",
      "Example 2:\n",
      "Input: What question was asked by the user if this t>Flying on dense atmosphere planets & moons (space.stackexchange.com)/t> c>> \"When it comes to flying, Titan might be better than Earth. Its atmosphere is thick but its gravity is light, giving it a surface pressure only 50% higher than Earth’s with air four times as dense. Its gravity-lower than that of the Moon-means that flying is easy.\" Flight on Titan IS easy. A human could theoretically achieve flight with a wingsuit and mere muscle power. The problem is, Titan is cold, 72 Kelvin cold. Flight would require some major heating modifications but, barring the heat factor, Titan is the absolute best place to attempt flight in our solar system. It's even better than Earth. As an interesting note, Titan, thus far, has actually been too cold for even unmanned probes to explore./c> t>620: Wings - explain xkcd (www.explainxkcd.com)/t> c>The calculated figure of 9% is only correct if the temperature on Titan has been raised to be the same as Earth — which, for human-powered flight, would probably be necessary anyway. At Titan's normal temperature, you would only have to generate about 3% of your Earth body weight in lift, as the atmosphere is much denser./c> t>620: Wings - explain xkcd (www.explainxkcd.com)/t> c>Sufficient height and a sudden loss of one's wings could indeed result in death (and deliberately causing someone to lose their wings and die or be injured would indeed get one arrested)./c> t>If the gravity was half as strong, how would the enviroment change? (worldbuilding.stackexchange.com)/t> c>If the Earth had half the gravity it does now, it's possible that life would not have evolved, due to a thinner atmosphere, and a host of other consequences resulting from that one change alone./c> t>Flying on dense atmosphere planets & moons (space.stackexchange.com) ; 620: Wings - explain xkcd (www.explainxkcd.com) ; 620: Wings - explain xkcd (www.explainxkcd.com) ; If the gravity was half as strong, how would the enviroment change? (worldbuilding.stackexchange.com)/t> c>> \"When it comes to flying, Titan might be better than Earth. Its atmosphere is thick but its gravity is light, giving it a surface pressure only 50% higher than Earth’s with air four times as dense. Its gravity-lower than that of the Moon-means that flying is easy.\" Flight on Titan IS easy. A human could theoretically achieve flight with a wingsuit and mere muscle power. The problem is, Titan is cold, 72 Kelvin cold. Flight would require some major heating modifications but, barring the heat factor, Titan is the absolute best place to attempt flight in our solar system. It's even better than Earth. As an interesting note, Titan, thus far, has actually been too cold for even unmanned probes to explore. ; The calculated figure of 9% is only correct if the temperature on Titan has been raised to be the same as Earth — which, for human-powered flight, would probably be necessary anyway. At Titan's normal temperature, you would only have to generate about 3% of your Earth body weight in lift, as the atmosphere is much denser. ; Sufficient height and a sudden loss of one's wings could indeed result in death (and deliberately causing someone to lose their wings and die or be injured would indeed get one arrested). ; If the Earth had half the gravity it does now, it's possible that life would not have evolved, due to a thinner atmosphere, and a host of other consequences resulting from that one change alone./c>\n",
      "Expected output: On Saturn's moon Titan, the gravity is low enough and the atmosphere thick enough, that by attaching small wings to your arms, you could fly like a bird. How does a denser atmosphere help in flying with lower gravity? does not lower gravity itself will be responsible for the flight?\n",
      "Generated output: If the gravity on Earth was half as strong as on Titan, how would a human be able to fly?\n",
      "\n",
      "Example 3:\n",
      "Input: What question was asked by the user if this t>How Does Wireless Charging Work? (www.howtogeek.com)/t> c>Most wireless chargers use magnetic induction and magnetic resonance. They offer the promise of being able to place a device on a surface and have it charge automatically—no fiddling with cables required. RELATED: Is It Worth Upgrading to the iPhone 8 or iPhone X?/c> t>How Does Wireless Charging Work? (www.howtogeek.com)/t> c>Wireless chargers typically use magnetic induction. The short explanation is that they use magnetism to transmit energy. First, you place the device–like a smartphone—on the wireless charger. The current coming from the wall power outlet moves through the wire in the wireless charger, creating a magnetic field. The magnetic field creates a current in the coil inside the device sitting on the wireless charger./c> t>Here’s how wireless charging on the Samsung Galaxy S6 and S6 Edge works [VIDEO] – Phandroid (phandroid.com)/t> c>One of those cutting edge features is wireless charging. It’s not new in its own, per se, but Samsung is the first to be using a new dual-mode charging technology that lets you use two of the world’s top wireless charging standards simultaneously (that being WPC’s Qi and the technology made by the now-joint/c> t>Samsung Wireless Charger—How Does It Work (blog.easyacc.com)/t> c>the Samsung wireless charger works by transmitting low-power signals between itself and your smartphone. While the wireless charger has a transmitter coil, your phone has a receiver coil. When you put your smartphone on the charger, the charger will regularly send a signal out, and the receiver coil of your phone will recognize it, and then resonance or capacity change happens in the signal. The waveform of the signal is then modulated and thus inductive charging begins./c> t>How Does Wireless Charging Work? (www.howtogeek.com) ; How Does Wireless Charging Work? (www.howtogeek.com) ; Here’s how wireless charging on the Samsung Galaxy S6 and S6 Edge works [VIDEO] – Phandroid (phandroid.com) ; Samsung Wireless Charger—How Does It Work (blog.easyacc.com)/t> c>Most wireless chargers use magnetic induction and magnetic resonance. They offer the promise of being able to place a device on a surface and have it charge automatically—no fiddling with cables required. RELATED: Is It Worth Upgrading to the iPhone 8 or iPhone X? ; Wireless chargers typically use magnetic induction. The short explanation is that they use magnetism to transmit energy. First, you place the device–like a smartphone—on the wireless charger. The current coming from the wall power outlet moves through the wire in the wireless charger, creating a magnetic field. The magnetic field creates a current in the coil inside the device sitting on the wireless charger. ; One of those cutting edge features is wireless charging. It’s not new in its own, per se, but Samsung is the first to be using a new dual-mode charging technology that lets you use two of the world’s top wireless charging standards simultaneously (that being WPC’s Qi and the technology made by the now-joint ; the Samsung wireless charger works by transmitting low-power signals between itself and your smartphone. While the wireless charger has a transmitter coil, your phone has a receiver coil. When you put your smartphone on the charger, the charger will regularly send a signal out, and the receiver coil of your phone will recognize it, and then resonance or capacity change happens in the signal. The waveform of the signal is then modulated and thus inductive charging begins./c>\n",
      "Expected output: How does Samsung's wireless charging work?\n",
      "Generated output: How does Samsung's wireless charging work?\n",
      "\n",
      "Example 4:\n",
      "Input: What question was asked by the user if this t>What Is a DDoS Attack? Distributed Denial-of-Service Attack Explained | Norton (us.norton.com)/t> c>The theory behind a DDoS attack is simple, although attacks can range in their level of sophistication. Here’s the basic idea. A DDoS is a cyberattack on a server, service, website, or network floods it with Internet traffic. If the traffic overwhelms the target, its server, service, website, or network is rendered inoperable. Network connections on the Internet consist of different layers of the Open Systems Interconnection (OS) model. Different types of DDoS attacks focus on particular layers. A few examples: * Layer 3, the Network layer. Attacks are known as Smurf Attacks, ICMP Floods, and IP/ICMP Fragmentation. * Layer 4, the Transport layer. Attacks include SYN Floods, UDP Floods, and TCP Connection Exhaustion. * Layer 7, the Application layer. Mainly, HTTP-encrypted attacks. Botnets The primary way a DDoS is accomplished is through a network of remotely controlled, hacked computers or bots. These are often referred to as “zombie computers.” They form what is known as a “botnet” or network of bots. These are used to flood targeted websites, servers, and networks with more data than they can accommodate. The botnets may send more connection requests than a server can handle or send overwhelming amounts of data that exceed the bandwidth capabilities of the targeted victim. Botnets can range from thousands to millions/c> t>What Is a DDoS Attack and How Does It Work | Cybersecurity | CompTIA (www.comptia.org)/t> c>DDoS attacks occur when servers and networks are flooded with an excessive amount of traffic. The goal is to overwhelm the website or server with so many requests that the system becomes inoperable and ceases to function./c> t>What is a DDoS Attack? Types & Prevention Methods (sucuri.net)/t> c>These attacks use spoofing, reflection, and amplification, which means that a tiny query can be largely amplified in order to result in a much larger response in bytes. Botnets are used to send DNS requests. If the attacker wanted to target a DNS server, it would use all the botnet zombies in his network to issue DNS request messages for an amplification record from open recursive DNS servers that translate domain names into IP addresses. When it is a new request, the server promptly issues its own request to an infected server with/c> t>What Is a DDoS Attack? Distributed Denial-of-Service Attack Explained | Norton (us.norton.com) ; What Is a DDoS Attack and How Does It Work | Cybersecurity | CompTIA (www.comptia.org) ; What is a DDoS Attack? Types & Prevention Methods (sucuri.net)/t> c>The theory behind a DDoS attack is simple, although attacks can range in their level of sophistication. Here’s the basic idea. A DDoS is a cyberattack on a server, service, website, or network floods it with Internet traffic. If the traffic overwhelms the target, its server, service, website, or network is rendered inoperable. Network connections on the Internet consist of different layers of the Open Systems Interconnection (OS) model. Different types of DDoS attacks focus on particular layers. A few examples: * Layer 3, the Network layer. Attacks are known as Smurf Attacks, ICMP Floods, and IP/ICMP Fragmentation. * Layer 4, the Transport layer. Attacks include SYN Floods, UDP Floods, and TCP Connection Exhaustion. * Layer 7, the Application layer. Mainly, HTTP-encrypted attacks. Botnets The primary way a DDoS is accomplished is through a network of remotely controlled, hacked computers or bots. These are often referred to as “zombie computers.” They form what is known as a “botnet” or network of bots. These are used to flood targeted websites, servers, and networks with more data than they can accommodate. The botnets may send more connection requests than a server can handle or send overwhelming amounts of data that exceed the bandwidth capabilities of the targeted victim. Botnets can range from thousands to millions ; DDoS attacks occur when servers and networks are flooded with an excessive amount of traffic. The goal is to overwhelm the website or server with so many requests that the system becomes inoperable and ceases to function. ; These attacks use spoofing, reflection, and amplification, which means that a tiny query can be largely amplified in order to result in a much larger response in bytes. Botnets are used to send DNS requests. If the attacker wanted to target a DNS server, it would use all the botnet zombies in his network to issue DNS request messages for an amplification record from open recursive DNS servers that translate domain names into IP addresses. When it is a new request, the server promptly issues its own request to an infected server with/c>\n",
      "Expected output: What is a DDoS attack and what does it do?\n",
      "Generated output: What is a DDoS attack and how does it work?\n",
      "\n",
      "Example 5:\n",
      "Input: What question was asked by the user if this t>How does fluoride strengthen teeth and why add it to the public water supply? (now.tufts.edu)/t> c>When added to drinking water at a concentration of one part per million, fluoride ions bathe the teeth when they are secreted in the saliva./c> t>How does fluoride strengthen teeth and why add it to the public water supply? (now.tufts.edu)/t> c>Fluoride’s anti-decay mechanism is well established. Tooth decay occurs when certain types of bacteria found in dental plaque break down dietary sugars and produce acid. These acids can dissolve tooth enamel and dentin, which is directly below the enamel, by leaching calcium and phosphate minerals from these hard tooth tissues. This process—called demineralization—eventually causes cavities. When fluoride becomes chemically incorporated in the tooth, it makes the enamel more resistant to demineralization, thus preventing the decay process./c> t>How Does Fluoride Strengthen Teeth? | Sloan Dental (www.sloandental.co.uk)/t> c>Fluoride is very accessible and once in your mouth or absorbed by your body in drinking water, it’s readily utilised by the teeth to provide your enamel with superior protection./c> t>How does fluoride strengthen teeth and why add it to the public water supply? (now.tufts.edu) ; How does fluoride strengthen teeth and why add it to the public water supply? (now.tufts.edu) ; How Does Fluoride Strengthen Teeth? | Sloan Dental (www.sloandental.co.uk)/t> c>When added to drinking water at a concentration of one part per million, fluoride ions bathe the teeth when they are secreted in the saliva. ; Fluoride’s anti-decay mechanism is well established. Tooth decay occurs when certain types of bacteria found in dental plaque break down dietary sugars and produce acid. These acids can dissolve tooth enamel and dentin, which is directly below the enamel, by leaching calcium and phosphate minerals from these hard tooth tissues. This process—called demineralization—eventually causes cavities. When fluoride becomes chemically incorporated in the tooth, it makes the enamel more resistant to demineralization, thus preventing the decay process. ; Fluoride is very accessible and once in your mouth or absorbed by your body in drinking water, it’s readily utilised by the teeth to provide your enamel with superior protection./c>\n",
      "Expected output: How does fluoride strengthen teeth?\n",
      "Generated output: How does fluoride strengthen teeth?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run comprehensive evaluation\n",
    "flan_extract_results = comprehensive_evaluation(flan_extract_eval_ds, flan_extract_model, flan_extract_tokenizer, num_examples=3000)\n",
    "eval_df = pd.read_csv(\"results_including_long_t5_tglobal_base_no_extract.csv\", index_col=0)\n",
    "eval_df = pd.concat([eval_df, pd.DataFrame([flan_extract_results], index=[\"long_t5_tglobal_base_with_extract\"])])\n",
    "eval_df.to_csv(\"results_including_long_t5_tglobal_base_with_extract.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29d260c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 38161/38161 [01:31<00:00, 418.45 examples/s]\n",
      "/tmp/ipykernel_3411862/4201518520.py:45: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  gpt2_extract_trainer = Trainer(\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5724' max='5724' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5724/5724 1:44:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.794800</td>\n",
       "      <td>1.508719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.772000</td>\n",
       "      <td>1.493003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.754300</td>\n",
       "      <td>1.487664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/devel/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "Generate:   0%|          | 0/3000 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   0%|          | 1/3000 [00:03<3:04:55,  3.70s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   0%|          | 2/3000 [00:07<3:02:04,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (1024). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [2,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [1,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [5,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [3,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [0,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1369: indexSelectSmallIndex: block: [4,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "Generate:   0%|          | 2/3000 [00:10<4:20:51,  5.22s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m gpt2_extract_trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Run comprehensive evaluation on GPT2 with extract\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m results_gpt2_extract \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_gpt2_on_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_extract\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpt2_extract_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpt2_extract_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m eval_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults_including_long_t5_tglobal_base_with_extract.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     60\u001b[0m eval_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([eval_df, pd\u001b[38;5;241m.\u001b[39mDataFrame([results_gpt2_extract], index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2_with_extract\u001b[39m\u001b[38;5;124m\"\u001b[39m])])\n",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m, in \u001b[0;36mevaluate_gpt2_on_raw\u001b[0;34m(raw_dataset, model, tokenizer, num_examples, max_new_tokens)\u001b[0m\n\u001b[1;32m     16\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(input_text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 18\u001b[0m     out_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m pred \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(out_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     25\u001b[0m preds\u001b[38;5;241m.\u001b[39mappend(pred)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/generation/utils.py:2634\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2626\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2627\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2628\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2629\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2630\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2631\u001b[0m     )\n\u001b[1;32m   2633\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2634\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2635\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2639\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2641\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2642\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2644\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2645\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[1;32m   2646\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2647\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2648\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2649\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2650\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2651\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/generation/utils.py:3618\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3616\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3617\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3618\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3621\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3622\u001b[0m     outputs,\n\u001b[1;32m   3623\u001b[0m     model_kwargs,\n\u001b[1;32m   3624\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3625\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:1076\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;124;03minput_ids (`torch.LongTensor` of shape `(batch_size, input_ids_length)`):\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;124;03m    `input_ids_length` = `sequence_length` if `past_key_values` is `None` else\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1076\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1092\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:875\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m attention_mask\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m    873\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m attention_mask\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 875\u001b[0m causal_mask \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_causal_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;66;03m# If a 2D or 3D attention mask is provided for the cross-attention\u001b[39;00m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\u001b[39;00m\n\u001b[1;32m    886\u001b[0m _use_sdpa \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attn_implementation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msdpa\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m output_attentions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/masking_utils.py:805\u001b[0m, in \u001b[0;36mcreate_causal_mask\u001b[0;34m(config, input_embeds, attention_mask, cache_position, past_key_values, position_ids, or_mask_function, and_mask_function)\u001b[0m\n\u001b[1;32m    802\u001b[0m     allow_is_causal_skip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# We now create the mask\u001b[39;00m\n\u001b[0;32m--> 805\u001b[0m causal_mask \u001b[38;5;241m=\u001b[39m \u001b[43mmask_interface\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkv_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkv_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_factory_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_is_causal_skip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_is_causal_skip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# additional kwarg for sdpa\u001b[39;49;00m\n\u001b[1;32m    813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Additional kwarg for eager\u001b[39;49;00m\n\u001b[1;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass the config as well, in case someone wants to easily have their own mask_interface\u001b[39;49;00m\n\u001b[1;32m    815\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m causal_mask\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/masking_utils.py:357\u001b[0m, in \u001b[0;36msdpa_mask_recent_torch\u001b[0;34m(batch_size, cache_position, kv_length, kv_offset, mask_function, attention_mask, local_size, allow_is_causal_skip, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m padding_mask \u001b[38;5;241m=\u001b[39m prepare_padding_mask(attention_mask, kv_length, kv_offset, _slice\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# Under specific conditions, we can avoid materializing the mask, instead relying on the `is_causal` argument\u001b[39;00m\n\u001b[0;32m--> 357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_is_causal_skip \u001b[38;5;129;01mand\u001b[39;00m \u001b[43m_ignore_causal_mask_sdpa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_size\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;66;03m# Similar to `kv_arange = torch.arange(start=kv_offset, end=kv_offset + kv_length, device=cache_position.device)`\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;66;03m# but without data-dependent slicing (i.e. torch.compile friendly)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/masking_utils.py:237\u001b[0m, in \u001b[0;36m_ignore_causal_mask_sdpa\u001b[0;34m(padding_mask, query_length, kv_length, kv_offset, local_attention_size)\u001b[0m\n\u001b[1;32m    221\u001b[0m     padding_mask \u001b[38;5;241m=\u001b[39m padding_mask[:, mask_indices]\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m# When using `torch.export` or `torch.onnx.dynamo_export`, we must pass an example input, and `is_causal` behavior is\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;66;03m# hard-coded to the forward. If a user exports a model with query_length > 1, the exported model will hard-code `is_causal=True`\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# which is in general wrong (see https://github.com/pytorch/pytorch/issues/108108). Thus, we only set\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# `ignore_causal_mask = True` if we are not tracing\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m is_tracing\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m# only cases when lower and upper diags are the same, see https://github.com/pytorch/pytorch/issues/108108\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (query_length \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (kv_length \u001b[38;5;241m==\u001b[39m query_length \u001b[38;5;129;01mor\u001b[39;00m _is_torch_xpu_available))\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;66;03m# in this case we need to add special patterns to the mask so cannot be skipped otherwise\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (local_attention_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m kv_length \u001b[38;5;241m<\u001b[39m local_attention_size)\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;66;03m# In this case, we need to add padding to the mask, so cannot be skipped otherwise\u001b[39;00m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    235\u001b[0m         padding_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m--> 237\u001b[0m             padding_mask\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m    238\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_torch_xpu_available \u001b[38;5;129;01mor\u001b[39;00m query_length \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    239\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m padding_mask[:, :query_length]\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m    240\u001b[0m         )\n\u001b[1;32m    241\u001b[0m     )\n\u001b[1;32m    242\u001b[0m ):\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    GPT2LMHeadModel,\n",
    "    GPT2TokenizerFast,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling,\n",
    ")\n",
    "\n",
    "# Load GPT2 model and tokenizer for extract training\n",
    "gpt2_extract_tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "gpt2_extract_tokenizer.pad_token = gpt2_extract_tokenizer.eos_token\n",
    "gpt2_extract_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Tokenize data for GPT2 with extract (causal language modeling)\n",
    "def tokenize_gpt2_extract(row):\n",
    "    text = row[\"input\"] + \" \" + row[\"output\"] + gpt2_extract_tokenizer.eos_token\n",
    "    return gpt2_extract_tokenizer(text, truncation=True, max_length=1024)\n",
    "\n",
    "gpt2_extract_tokenized_data = train_data_extract.map(tokenize_gpt2_extract, remove_columns=[\"input\", \"output\"])\n",
    "\n",
    "# Split the data\n",
    "gpt2_extract_train_ds, gpt2_extract_eval_ds = gpt2_extract_tokenized_data.train_test_split(test_size=0.2, seed=42).values()\n",
    "\n",
    "# Training arguments for GPT2 with extract\n",
    "gpt2_extract_training_args = TrainingArguments(\n",
    "    output_dir=\"gpt2-question-generator-extract\",\n",
    "    per_device_train_batch_size=2,  # Smaller batch size due to longer sequences\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\",\n",
    "    save_total_limit=1,\n",
    "    eval_strategy=\"epoch\",\n",
    "    gradient_accumulation_steps=4  # Compensate for smaller batch size\n",
    ")\n",
    "\n",
    "# Data collator for language modeling\n",
    "gpt2_extract_data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=gpt2_extract_tokenizer,\n",
    "    mlm=False,  # Causal language modeling, not masked\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "gpt2_extract_trainer = Trainer(\n",
    "    model=gpt2_extract_model,\n",
    "    args=gpt2_extract_training_args,\n",
    "    train_dataset=gpt2_extract_train_ds,\n",
    "    eval_dataset=gpt2_extract_eval_ds,\n",
    "    tokenizer=gpt2_extract_tokenizer,\n",
    "    data_collator=gpt2_extract_data_collator,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "gpt2_extract_trainer.train()\n",
    "\n",
    "# Run comprehensive evaluation on GPT2 with extract\n",
    "results_gpt2_extract = evaluate_gpt2_on_raw(train_data_extract, gpt2_extract_model, gpt2_extract_tokenizer, num_examples=3000, max_new_tokens=512)\n",
    "eval_df = pd.read_csv(\"results_including_long_t5_tglobal_base_with_extract.csv\", index_col=0)\n",
    "eval_df = pd.concat([eval_df, pd.DataFrame([results_gpt2_extract], index=[\"gpt2_with_extract\"])])\n",
    "eval_df.to_csv(\"results_including_gpt2_with_extract.csv\")\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6303d67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate:   0%|          | 0/3000 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   0%|          | 1/3000 [00:10<8:23:28, 10.07s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   0%|          | 2/3000 [00:19<8:18:49,  9.98s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Generate:   0%|          | 2/3000 [00:29<12:14:01, 14.69s/it]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m gpt2_extract_model \u001b[38;5;241m=\u001b[39m GPT2LMHeadModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/devel/temp/school/nlp/project/gpt2-question-generator-extract/checkpoint-5724\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Run comprehensive evaluation on GPT2 with extract\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m results_gpt2_extract \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_gpt2_on_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_extract\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpt2_extract_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpt2_extract_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m eval_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults_including_long_t5_tglobal_base_with_extract.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     18\u001b[0m eval_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([eval_df, pd\u001b[38;5;241m.\u001b[39mDataFrame([results_gpt2_extract], index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2_with_extract\u001b[39m\u001b[38;5;124m\"\u001b[39m])])\n",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m, in \u001b[0;36mevaluate_gpt2_on_raw\u001b[0;34m(raw_dataset, model, tokenizer, num_examples, max_new_tokens)\u001b[0m\n\u001b[1;32m     16\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(input_text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 18\u001b[0m     out_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m pred \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(out_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     25\u001b[0m preds\u001b[38;5;241m.\u001b[39mappend(pred)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/generation/utils.py:2634\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2626\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2627\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2628\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2629\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2630\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2631\u001b[0m     )\n\u001b[1;32m   2633\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2634\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2635\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2639\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2641\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2642\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2644\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2645\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[1;32m   2646\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2647\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2648\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2649\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2650\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2651\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/generation/utils.py:3618\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3616\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3617\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3618\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3621\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3622\u001b[0m     outputs,\n\u001b[1;32m   3623\u001b[0m     model_kwargs,\n\u001b[1;32m   3624\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3625\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:1076\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;124;03minput_ids (`torch.LongTensor` of shape `(batch_size, input_ids_length)`):\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;124;03m    `input_ids_length` = `sequence_length` if `past_key_values` is `None` else\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1076\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1092\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:867\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m position_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    865\u001b[0m     position_ids \u001b[38;5;241m=\u001b[39m cache_position\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 867\u001b[0m position_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwpe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m position_embeds\u001b[38;5;241m.\u001b[39mto(inputs_embeds\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    870\u001b[0m \u001b[38;5;66;03m# Attention mask.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;66;03m# ._update_causal_mask() and ._prepare_4d_causal_attention_mask_with_cache_position() copied from LlamaModel\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    GPT2LMHeadModel,\n",
    "    GPT2TokenizerFast,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling,\n",
    ")\n",
    "\n",
    "# load model from\n",
    "gpt2_extract_tokenizer = GPT2TokenizerFast.from_pretrained(\"/home/devel/temp/school/nlp/project/gpt2-question-generator-extract/checkpoint-5724\")\n",
    "gpt2_extract_tokenizer.pad_token = gpt2_extract_tokenizer.eos_token\n",
    "gpt2_extract_model = GPT2LMHeadModel.from_pretrained(\"/home/devel/temp/school/nlp/project/gpt2-question-generator-extract/checkpoint-5724\")\n",
    "\n",
    "\n",
    "# Run comprehensive evaluation on GPT2 with extract\n",
    "results_gpt2_extract = evaluate_gpt2_on_raw(train_data_extract, gpt2_extract_model, gpt2_extract_tokenizer, num_examples=3000, max_new_tokens=512)\n",
    "eval_df = pd.read_csv(\"results_including_long_t5_tglobal_base_with_extract.csv\", index_col=0)\n",
    "eval_df = pd.concat([eval_df, pd.DataFrame([results_gpt2_extract], index=[\"gpt2_with_extract\"])])\n",
    "eval_df.to_csv(\"results_including_gpt2_with_extract.csv\")\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec713d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gpt2_on_raw_robust(raw_dataset, model, tokenizer, num_examples=1000, max_new_tokens=128, max_length=1024):\n",
    "    \"\"\"\n",
    "    More robust version of evaluate_gpt2_on_raw that handles problematic inputs\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    n = len(raw_dataset) if (num_examples is None) else min(num_examples, len(raw_dataset))\n",
    "    subset = raw_dataset.select(range(n))\n",
    "\n",
    "    preds, refs = [], []\n",
    "    skipped_count = 0\n",
    "\n",
    "    # 1) Generate predictions from INPUT only\n",
    "    for i, ex in enumerate(tqdm(subset, desc=\"Generate\")):\n",
    "        try:\n",
    "            input_text = ex[\"input\"]\n",
    "            ref_text = ex[\"output\"]\n",
    "            \n",
    "            # Skip if input is too long\n",
    "            if len(input_text) > max_length * 4:  # rough character limit\n",
    "                skipped_count += 1\n",
    "                continue\n",
    "                \n",
    "            # Tokenize with truncation\n",
    "            inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=max_length)\n",
    "            \n",
    "            # Check for out-of-bounds tokens\n",
    "            if inputs.input_ids.max().item() >= model.config.vocab_size:\n",
    "                print(f\"Skipping sample {i}: out-of-bounds token detected\")\n",
    "                skipped_count += 1\n",
    "                continue\n",
    "                \n",
    "            inputs = inputs.to(model.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                out_ids = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=max_new_tokens,\n",
    "                    do_sample=False,\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                    pad_token_id=tokenizer.pad_token_id,\n",
    "                )\n",
    "            pred = tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
    "            preds.append(pred)\n",
    "            refs.append(ref_text)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sample {i}: {e}\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "    print(f\"Processed {len(preds)} samples, skipped {skipped_count}\")\n",
    "    \n",
    "    if len(preds) == 0:\n",
    "        print(\"No valid predictions generated!\")\n",
    "        return None\n",
    "\n",
    "    # 2) Semantic & surface metrics\n",
    "    bertscore = evaluate.load(\"bertscore\").compute(predictions=preds, references=refs, lang=\"en\")\n",
    "    rouge     = evaluate.load(\"rouge\").compute(predictions=preds, references=refs)\n",
    "    bleu      = evaluate.load(\"bleu\").compute(predictions=preds, references=[[r] for r in refs])\n",
    "\n",
    "    b_f1 = float(np.mean(bertscore[\"f1\"]))\n",
    "    b_p  = float(np.mean(bertscore[\"precision\"]))\n",
    "    b_r  = float(np.mean(bertscore[\"recall\"]))\n",
    "\n",
    "    # 3) Perplexity on OUTPUT ONLY (mask prompt tokens) - use smaller subset for speed\n",
    "    losses = []\n",
    "    ppl_subset = subset.select(range(min(50, len(preds))))  # Use first 50 successful samples\n",
    "    \n",
    "    for i, ex in enumerate(tqdm(ppl_subset, desc=\"PPL\")):\n",
    "        try:\n",
    "            prompt_ids = tokenizer(ex[\"input\"], add_special_tokens=False, truncation=True, max_length=max_length//2)[\"input_ids\"]\n",
    "            target_ids = tokenizer(ex[\"output\"], add_special_tokens=False, truncation=True, max_length=max_length//2)[\"input_ids\"]\n",
    "            \n",
    "            full_ids = prompt_ids + target_ids + [tokenizer.eos_token_id]\n",
    "            if len(full_ids) > max_length:\n",
    "                continue  # Skip if too long\n",
    "                \n",
    "            ids = torch.tensor(full_ids).unsqueeze(0).to(model.device)\n",
    "            labels = ids.clone()\n",
    "            labels[:, :len(prompt_ids)] = -100  # ignore prompt\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                loss = model(input_ids=ids, labels=labels).loss.item()\n",
    "            losses.append(loss)\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating perplexity for sample {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if losses:\n",
    "        ppl = float(math.exp(np.mean(losses)))\n",
    "    else:\n",
    "        ppl = float('inf')  # If no perplexity could be calculated\n",
    "\n",
    "    print(\"\\n=== EVALUATION RESULTS ===\")\n",
    "    print(f\"BERTScore F1: {b_f1:.4f} ↑ (higher = more semantically similar)\")\n",
    "    print(f\"BERTScore Precision: {b_p:.4f} ↑\")\n",
    "    print(f\"BERTScore Recall: {b_r:.4f} ↑\")\n",
    "    print(f\"BLEU Score: {bleu['bleu']:.4f} ↑ (higher = more phrase overlap)\")\n",
    "    print(f\"ROUGE-1 F1: {rouge['rouge1']:.4f} ↑\")\n",
    "    print(f\"ROUGE-2 F1: {rouge['rouge2']:.4f} ↑\")\n",
    "    print(f\"ROUGE-L F1: {rouge['rougeL']:.4f} ↑ (longest common subsequence)\")\n",
    "    print(f\"Perplexity (output-only): {ppl:.4f} ↓ (lower = more confident model)\")\n",
    "\n",
    "    return {\n",
    "        \"bertscore_f1\": b_f1,\n",
    "        \"bertscore_precision\": b_p,\n",
    "        \"bertscore_recall\": b_r,\n",
    "        \"bleu\": bleu[\"bleu\"],\n",
    "        \"rouge1\": rouge[\"rouge1\"],\n",
    "        \"rouge2\": rouge[\"rouge2\"],\n",
    "        \"rougeL\": rouge[\"rougeL\"],\n",
    "        \"perplexity\": ppl,\n",
    "        \"samples_processed\": len(preds),\n",
    "        \"samples_skipped\": skipped_count\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eadccfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing robust evaluation function...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate: 100%|██████████| 100/100 [01:59<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 51 samples, skipped 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PPL:   0%|          | 0/50 [00:00<?, ?it/s]`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "PPL: 100%|██████████| 50/50 [00:04<00:00, 11.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EVALUATION RESULTS ===\n",
      "BERTScore F1: 0.7872 ↑ (higher = more semantically similar)\n",
      "BERTScore Precision: 0.7380 ↑\n",
      "BERTScore Recall: 0.8438 ↑\n",
      "BLEU Score: 0.0052 ↑ (higher = more phrase overlap)\n",
      "ROUGE-1 F1: 0.0517 ↑\n",
      "ROUGE-2 F1: 0.0192 ↑\n",
      "ROUGE-L F1: 0.0464 ↑ (longest common subsequence)\n",
      "Perplexity (output-only): 130.0749 ↓ (lower = more confident model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the robust evaluation function\n",
    "print(\"Testing robust evaluation function...\")\n",
    "results_gpt2_extract_robust = evaluate_gpt2_on_raw_robust(\n",
    "    train_data_extract, \n",
    "    gpt2_extract_model, \n",
    "    gpt2_extract_tokenizer, \n",
    "    num_examples=100,  # Start with smaller number\n",
    "    max_new_tokens=128,\n",
    "    max_length=512  # Smaller max length to avoid issues\n",
    ")\n",
    "\n",
    "eval_df = pd.read_csv(\"results_including_long_t5_tglobal_base_with_extract.csv\", index_col=0)\n",
    "eval_df = pd.concat([eval_df, pd.DataFrame([results_gpt2_extract_robust], index=[\"gpt2_with_extract\"])])\n",
    "eval_df.to_csv(\"results_including_gpt2_with_extract.csv\")\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7e6717",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5ecc59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>bertscore_precision</th>\n",
       "      <th>bertscore_recall</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>samples_processed</th>\n",
       "      <th>samples_skipped</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t5_small_only_title</th>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.247088</td>\n",
       "      <td>0.098434</td>\n",
       "      <td>0.223263</td>\n",
       "      <td>0.315411</td>\n",
       "      <td>0.450722</td>\n",
       "      <td>0.188689</td>\n",
       "      <td>15.403170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5_small_baseline</th>\n",
       "      <td>0.009406</td>\n",
       "      <td>0.160242</td>\n",
       "      <td>0.042990</td>\n",
       "      <td>0.130303</td>\n",
       "      <td>-0.058683</td>\n",
       "      <td>-0.181792</td>\n",
       "      <td>0.070558</td>\n",
       "      <td>75.238684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2_only_title</th>\n",
       "      <td>0.003058</td>\n",
       "      <td>0.046986</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>0.034573</td>\n",
       "      <td>0.772086</td>\n",
       "      <td>0.718331</td>\n",
       "      <td>0.835581</td>\n",
       "      <td>23.359847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flan_t5_small_only_title</th>\n",
       "      <td>0.010333</td>\n",
       "      <td>0.247322</td>\n",
       "      <td>0.098531</td>\n",
       "      <td>0.223712</td>\n",
       "      <td>0.309271</td>\n",
       "      <td>0.440461</td>\n",
       "      <td>0.187329</td>\n",
       "      <td>10.307720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_t5_tglobal_base_no_extract</th>\n",
       "      <td>0.005510</td>\n",
       "      <td>0.261654</td>\n",
       "      <td>0.110871</td>\n",
       "      <td>0.237065</td>\n",
       "      <td>0.338375</td>\n",
       "      <td>0.477757</td>\n",
       "      <td>0.207826</td>\n",
       "      <td>7.071643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_t5_tglobal_base_with_extract</th>\n",
       "      <td>0.007220</td>\n",
       "      <td>0.274203</td>\n",
       "      <td>0.121548</td>\n",
       "      <td>0.246307</td>\n",
       "      <td>0.345160</td>\n",
       "      <td>0.477222</td>\n",
       "      <td>0.221210</td>\n",
       "      <td>7.061938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2_with_extract</th>\n",
       "      <td>0.005217</td>\n",
       "      <td>0.051701</td>\n",
       "      <td>0.019227</td>\n",
       "      <td>0.046433</td>\n",
       "      <td>0.787217</td>\n",
       "      <td>0.737987</td>\n",
       "      <td>0.843794</td>\n",
       "      <td>130.074900</td>\n",
       "      <td>51.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       bleu    rouge1    rouge2    rougeL  \\\n",
       "Model                                                                       \n",
       "t5_small_only_title                0.004914  0.247088  0.098434  0.223263   \n",
       "t5_small_baseline                  0.009406  0.160242  0.042990  0.130303   \n",
       "gpt2_only_title                    0.003058  0.046986  0.009768  0.034573   \n",
       "flan_t5_small_only_title           0.010333  0.247322  0.098531  0.223712   \n",
       "long_t5_tglobal_base_no_extract    0.005510  0.261654  0.110871  0.237065   \n",
       "long_t5_tglobal_base_with_extract  0.007220  0.274203  0.121548  0.246307   \n",
       "gpt2_with_extract                  0.005217  0.051701  0.019227  0.046433   \n",
       "\n",
       "                                   bertscore_f1  bertscore_precision  \\\n",
       "Model                                                                  \n",
       "t5_small_only_title                    0.315411             0.450722   \n",
       "t5_small_baseline                     -0.058683            -0.181792   \n",
       "gpt2_only_title                        0.772086             0.718331   \n",
       "flan_t5_small_only_title               0.309271             0.440461   \n",
       "long_t5_tglobal_base_no_extract        0.338375             0.477757   \n",
       "long_t5_tglobal_base_with_extract      0.345160             0.477222   \n",
       "gpt2_with_extract                      0.787217             0.737987   \n",
       "\n",
       "                                   bertscore_recall  perplexity  \\\n",
       "Model                                                             \n",
       "t5_small_only_title                        0.188689   15.403170   \n",
       "t5_small_baseline                          0.070558   75.238684   \n",
       "gpt2_only_title                            0.835581   23.359847   \n",
       "flan_t5_small_only_title                   0.187329   10.307720   \n",
       "long_t5_tglobal_base_no_extract            0.207826    7.071643   \n",
       "long_t5_tglobal_base_with_extract          0.221210    7.061938   \n",
       "gpt2_with_extract                          0.843794  130.074900   \n",
       "\n",
       "                                   samples_processed  samples_skipped  \n",
       "Model                                                                  \n",
       "t5_small_only_title                              NaN              NaN  \n",
       "t5_small_baseline                                NaN              NaN  \n",
       "gpt2_only_title                                  NaN              NaN  \n",
       "flan_t5_small_only_title                         NaN              NaN  \n",
       "long_t5_tglobal_base_no_extract                  NaN              NaN  \n",
       "long_t5_tglobal_base_with_extract                NaN              NaN  \n",
       "gpt2_with_extract                               51.0             49.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3959220/1172212363.py:14: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model by BERTScore F1: gpt2_with_extract (0.7872)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>bertscore_precision</th>\n",
       "      <th>bertscore_recall</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>samples_processed</th>\n",
       "      <th>samples_skipped</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt2_with_extract</th>\n",
       "      <td>0.005217</td>\n",
       "      <td>0.051701</td>\n",
       "      <td>0.019227</td>\n",
       "      <td>0.046433</td>\n",
       "      <td>0.787217</td>\n",
       "      <td>0.737987</td>\n",
       "      <td>0.843794</td>\n",
       "      <td>130.074900</td>\n",
       "      <td>51.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2_only_title</th>\n",
       "      <td>0.003058</td>\n",
       "      <td>0.046986</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>0.034573</td>\n",
       "      <td>0.772086</td>\n",
       "      <td>0.718331</td>\n",
       "      <td>0.835581</td>\n",
       "      <td>23.359847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_t5_tglobal_base_with_extract</th>\n",
       "      <td>0.007220</td>\n",
       "      <td>0.274203</td>\n",
       "      <td>0.121548</td>\n",
       "      <td>0.246307</td>\n",
       "      <td>0.345160</td>\n",
       "      <td>0.477222</td>\n",
       "      <td>0.221210</td>\n",
       "      <td>7.061938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_t5_tglobal_base_no_extract</th>\n",
       "      <td>0.005510</td>\n",
       "      <td>0.261654</td>\n",
       "      <td>0.110871</td>\n",
       "      <td>0.237065</td>\n",
       "      <td>0.338375</td>\n",
       "      <td>0.477757</td>\n",
       "      <td>0.207826</td>\n",
       "      <td>7.071643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5_small_only_title</th>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.247088</td>\n",
       "      <td>0.098434</td>\n",
       "      <td>0.223263</td>\n",
       "      <td>0.315411</td>\n",
       "      <td>0.450722</td>\n",
       "      <td>0.188689</td>\n",
       "      <td>15.403170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flan_t5_small_only_title</th>\n",
       "      <td>0.010333</td>\n",
       "      <td>0.247322</td>\n",
       "      <td>0.098531</td>\n",
       "      <td>0.223712</td>\n",
       "      <td>0.309271</td>\n",
       "      <td>0.440461</td>\n",
       "      <td>0.187329</td>\n",
       "      <td>10.307720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5_small_baseline</th>\n",
       "      <td>0.009406</td>\n",
       "      <td>0.160242</td>\n",
       "      <td>0.042990</td>\n",
       "      <td>0.130303</td>\n",
       "      <td>-0.058683</td>\n",
       "      <td>-0.181792</td>\n",
       "      <td>0.070558</td>\n",
       "      <td>75.238684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       bleu    rouge1    rouge2    rougeL  \\\n",
       "Model                                                                       \n",
       "gpt2_with_extract                  0.005217  0.051701  0.019227  0.046433   \n",
       "gpt2_only_title                    0.003058  0.046986  0.009768  0.034573   \n",
       "long_t5_tglobal_base_with_extract  0.007220  0.274203  0.121548  0.246307   \n",
       "long_t5_tglobal_base_no_extract    0.005510  0.261654  0.110871  0.237065   \n",
       "t5_small_only_title                0.004914  0.247088  0.098434  0.223263   \n",
       "flan_t5_small_only_title           0.010333  0.247322  0.098531  0.223712   \n",
       "t5_small_baseline                  0.009406  0.160242  0.042990  0.130303   \n",
       "\n",
       "                                   bertscore_f1  bertscore_precision  \\\n",
       "Model                                                                  \n",
       "gpt2_with_extract                      0.787217             0.737987   \n",
       "gpt2_only_title                        0.772086             0.718331   \n",
       "long_t5_tglobal_base_with_extract      0.345160             0.477222   \n",
       "long_t5_tglobal_base_no_extract        0.338375             0.477757   \n",
       "t5_small_only_title                    0.315411             0.450722   \n",
       "flan_t5_small_only_title               0.309271             0.440461   \n",
       "t5_small_baseline                     -0.058683            -0.181792   \n",
       "\n",
       "                                   bertscore_recall  perplexity  \\\n",
       "Model                                                             \n",
       "gpt2_with_extract                          0.843794  130.074900   \n",
       "gpt2_only_title                            0.835581   23.359847   \n",
       "long_t5_tglobal_base_with_extract          0.221210    7.061938   \n",
       "long_t5_tglobal_base_no_extract            0.207826    7.071643   \n",
       "t5_small_only_title                        0.188689   15.403170   \n",
       "flan_t5_small_only_title                   0.187329   10.307720   \n",
       "t5_small_baseline                          0.070558   75.238684   \n",
       "\n",
       "                                   samples_processed  samples_skipped  \n",
       "Model                                                                  \n",
       "gpt2_with_extract                               51.0             49.0  \n",
       "gpt2_only_title                                  NaN              NaN  \n",
       "long_t5_tglobal_base_with_extract                NaN              NaN  \n",
       "long_t5_tglobal_base_no_extract                  NaN              NaN  \n",
       "t5_small_only_title                              NaN              NaN  \n",
       "flan_t5_small_only_title                         NaN              NaN  \n",
       "t5_small_baseline                                NaN              NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Ensure eval_df index is model names\n",
    "eval_df_plot = eval_df.copy()\n",
    "eval_df_plot.index.name = \"Model\"\n",
    "\n",
    "# Display the dataframe\n",
    "display(eval_df_plot)\n",
    "\n",
    "# Plot BERTScore F1 for all models\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    x=eval_df_plot.index,\n",
    "    y=\"bertscore_f1\",\n",
    "    data=eval_df_plot,\n",
    "    palette=\"viridis\"\n",
    ")\n",
    "plt.title(\"BERTScore F1 by Model\")\n",
    "plt.ylabel(\"BERTScore F1\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot all metrics for each model\n",
    "metrics = [\"bertscore_f1\", \"bleu\", \"rouge1\", \"rouge2\", \"rougeL\", \"perplexity\"]\n",
    "eval_df_plot[metrics].plot(\n",
    "    kind=\"bar\",\n",
    "    subplots=True,\n",
    "    layout=(2, 3),\n",
    "    figsize=(15, 8),\n",
    "    legend=False,\n",
    "    sharex=True,\n",
    "    title=[m.upper() for m in metrics]\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Highlight the best model by BERTScore F1\n",
    "best_model = eval_df_plot[\"bertscore_f1\"].idxmax()\n",
    "best_score = eval_df_plot.loc[best_model, \"bertscore_f1\"]\n",
    "print(f\"Best model by BERTScore F1: {best_model} ({best_score:.4f})\")\n",
    "\n",
    "# Print summary table sorted by BERTScore F1\n",
    "display(eval_df_plot.sort_values(\"bertscore_f1\", ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
